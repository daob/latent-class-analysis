[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latent class analysis",
    "section": "",
    "text": "This is a website containing some documents about latent class analysis."
  },
  {
    "objectID": "protest-ESS.html",
    "href": "protest-ESS.html",
    "title": "Political activism in Greece",
    "section": "",
    "text": "set.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(haven)\nlibrary(poLCA)\n\n\n\nRead the data from the European Social Survey, round 4 (Greece).\nFor each of these survey questions, 1=“Yes” and 2=“No”.\n\ncontplt - Contacted politician or government official last 12 months\nwrkprty - Worked in political party or action group last 12 months\nwrkorg - Worked in another organisation or association last 12 months\nbadge - Worn or displayed campaign badge/sticker last 12 months\nsgnptit - Signed petition last 12 months\npbldmn - Taken part in lawful public demonstration last 12 months\nbctprd - Boycotted certain products last 12 months\ngndr - Gender\nagea - Age of respondent, calculated\n\n\ness_greece <- read_csv(\"https://daob.nl/files/lca/ess_greece.csv.gz\") \n\ness_greece |> rmarkdown::paged_table()\n\n\n\n  \n\n\n\nShow the data as pattern frequencies.\n\ntable(ess_greece) %>% \n  as.data.frame() %>%\n  filter(Freq != 0) %>% \n  rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\n\n\nCreate a convenience function that will fit the K-class model to the political participation data.\n\nfitLCA <- function(k) {\n  f <- cbind(contplt, wrkprty, wrkorg, badge, \n           sgnptit, pbldmn, bctprd) ~ 1\n  \n  poLCA(formula = f, data = ess_greece, nclass = k, \n        nrep = 10, verbose = FALSE)\n}\n\nApply the function to successively increasingly classes K = 1, 2, 3, …, 6. (Note: this can take a while!)\n\nMK <- lapply(1:6, fitLCA)\n\n\n\n\nPossible to look at AIC, BIC, etc.\n\naic_values <- sapply(MK, `[[`, \"aic\")\nbic_values <- sapply(MK, `[[`, \"bic\")\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"AIC\", las = 2)\n\n\n\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"BIC\", las = 2)\n\n\n\n\n\n\n\nWe select the four-class model.\n\nform_activism <- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ 1\n\nfit <- poLCA(form_activism, \n             data = ess_greece, \n             nclass = 4, \n             nrep = 20, verbose = FALSE)\n\nHere is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %>% \n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\n\n\nlibrary(poLCA.extras)\n\nbvr(fit)\n\n          contplt   wrkprty    wrkorg     badge   sgnptit    pbldmn\nwrkprty  3.638214                                                  \nwrkorg   5.429334  5.555308                                        \nbadge    9.178927 11.571064  7.703614                              \nsgnptit  3.027135  4.637933  4.744867  5.003312                    \npbldmn   2.749737  5.233259  6.070114  5.148570  3.224048          \nbctprd   3.045449  4.718233  5.598461  5.955635  2.473200  3.292323\n\n\n\nbootstrap_bvr_pvals(form_activism, fit, ess_greece, R = 200)\n\n        contplt wrkprty wrkorg badge sgnptit pbldmn\nwrkprty       1                                    \nwrkorg        1       1                            \nbadge         1       1      1                     \nsgnptit       1       1      1     1               \npbldmn        1       1      1     1       1       \nbctprd        1       1      1     1       1      1\n\n\n\n\n\nCreate a data frame with the posterior class memberships and predicted class has the actual classification (predclass is the “modal assignment”)\nUse the four-class model as the selected model\n\nposteriors <- data.frame(post = fit$posterior,\n                         predclass = fit$predclass)\n\nclassification_table <- posteriors %>% \n  group_by(predclass) %>% \n  summarize(across(starts_with(\"post.\"), ~ sum(.x)))\n\nclassification_table <- classification_table[,-1] |> as.matrix()\n\n# Adopt the notation X=true latent class, W=assigned class\ncolnames(classification_table) <- paste0(\"X=\", 1:4)\nrownames(classification_table) <- paste0(\"W=\", 1:4)\n\nclassification_table %>% round(1)\n\n     X=1    X=2  X=3  X=4\nW=1 60.1    4.0  8.6  1.4\nW=2 11.1 1824.0 34.9  0.0\nW=3  3.0    7.5 87.4  1.1\nW=4  0.2    0.0  1.0 19.8\n\n\nWith column proportions:\n\nclassification_table |>\n  prop.table(2) |> \n  round(3)\n\n      X=1   X=2   X=3   X=4\nW=1 0.808 0.002 0.065 0.062\nW=2 0.150 0.994 0.264 0.000\nW=3 0.040 0.004 0.663 0.051\nW=4 0.003 0.000 0.008 0.887\n\n\n\n\nCalculate classification errors from classification table:\n\n1 - sum(diag(classification_table)) / sum(classification_table)\n\n[1] 0.035222\n\n\nEntropy \\(R^2\\):\n\nentropy <- function(p) sum(-p * log(p))\n\nerror_prior <- entropy(MK[[4]]$P) # Class proportions\nerror_post <- mean(apply(MK[[4]]$posterior, 1, entropy))\n(R2_entropy  <- (error_prior - error_post) / error_prior) # 0.741\n\n[1] 0.741126\n\n\n\n\n\n\nNow we fit the four-class model, but include covariates that predict the class membership. Class membership is predicted by gender and a quadratic age effect.\n\nform_activism <- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ \n  gndr + agea + I(agea^2)\n\nfit_covariates <- \n  poLCA(form_activism, \n        data = ess_greece, nclass = 4, \n        nrep = 50, verbose = FALSE)\n\nThe results now include multinomial regression coefficients in a model predicting class membership.\n\nfit_covariates\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$contplt\n           Pr(1)  Pr(2)\nclass 1:  0.7630 0.2370\nclass 2:  0.0521 0.9479\nclass 3:  0.7771 0.2229\nclass 4:  0.2330 0.7670\n\n$wrkprty\n           Pr(1)  Pr(2)\nclass 1:  0.9319 0.0681\nclass 2:  0.0011 0.9989\nclass 3:  0.5538 0.4462\nclass 4:  0.0999 0.9001\n\n$wrkorg\n           Pr(1)  Pr(2)\nclass 1:  1.0000 0.0000\nclass 2:  0.0056 0.9944\nclass 3:  0.1703 0.8297\nclass 4:  0.2177 0.7823\n\n$badge\n           Pr(1)  Pr(2)\nclass 1:  0.8668 0.1332\nclass 2:  0.0000 1.0000\nclass 3:  0.3829 0.6171\nclass 4:  0.0961 0.9039\n\n$sgnptit\n           Pr(1)  Pr(2)\nclass 1:  0.8334 0.1666\nclass 2:  0.0050 0.9950\nclass 3:  0.0005 0.9995\nclass 4:  0.4709 0.5291\n\n$pbldmn\n           Pr(1)  Pr(2)\nclass 1:  0.8192 0.1808\nclass 2:  0.0140 0.9860\nclass 3:  0.2360 0.7640\nclass 4:  0.3901 0.6099\n\n$bctprd\n           Pr(1)  Pr(2)\nclass 1:  0.7011 0.2989\nclass 2:  0.0981 0.9019\nclass 3:  0.2083 0.7917\nclass 4:  0.6862 0.3138\n\nEstimated class population shares \n 0.0117 0.8807 0.0367 0.0708 \n \nPredicted class memberships (by modal posterior prob.) \n 0.0116 0.904 0.032 0.0524 \n \n========================================================= \nFit for 4 latent classes: \n========================================================= \n2 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)     0.08850     0.00948    9.336      0.00\ngndr            0.57561     0.10201    5.643      0.00\nagea            0.12762     0.02368    5.389      0.00\nI(agea^2)      -0.00097     0.00049   -1.983      0.05\n========================================================= \n3 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)    -0.03157     0.00327   -9.651     0.000\ngndr           -0.23546     0.03185   -7.394     0.000\nagea            0.03882     0.02503    1.551     0.124\nI(agea^2)      -0.00004     0.00051   -0.080     0.936\n========================================================= \n4 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)    -0.01856     0.00598   -3.105     0.003\ngndr           -0.15456     0.06290   -2.457     0.016\nagea            0.09007     0.02435    3.699     0.000\nI(agea^2)      -0.00083     0.00051   -1.607     0.112\n========================================================= \nnumber of observations: 2062 \nnumber of estimated parameters: 40 \nresidual degrees of freedom: 87 \nmaximum log-likelihood: -2780.444 \n \nAIC(4): 5640.889\nBIC(4): 5866.146\nX^2(4): 128.9784 (Chi-square goodness of fit) \n \nALERT: estimation algorithm automatically restarted with new initial values \n \n\n\nThe solution may have changed now that covariates are included.\n\ntidy(fit_covariates) %>% \n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\nWe can easily plot the results of the multinomial model using the effects library.\n\nlibrary(effects)\n\n\neffect_age <- predictorEffects(fit_covariates, ~agea*gndr)\nplot(effect_age, lines=list(multiline=TRUE))"
  },
  {
    "objectID": "em-height.html",
    "href": "em-height.html",
    "title": "EM: simple example",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of univariate Gaussians, and estimate that mixture (LPA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job. You can copy code into your R environment by clicking the copy icon in the top right of each code block.\n\n\nAfter looking through the code below, do the exercises in this section. Your instructor will of course be around to help and collaboration among participants is encouraged.\nBelow the regular questions, you will find a few “BONUS” questions. These are for those among you who are looking for a serious challenge, and you will likely find the difficulty level of these questions considerably higher. Do not worry if you do not understand these BONUS questions. Their completion is not needed for an applied understanding of LCA!\nExercises\n\nRead the simulation code. Do you have any questions?\nRead the function runit. Do you understand all steps?\nCode understanding check:\n\nWhy is the function dnorm used? Why is it used twice?\nWhat is happening here: post <- pman / (pman + pwom)? What is the intuitive explanation of this formula?\nWhy is weighted.mean used rather than just mean?\nWhy are the weights chosen the way they are?\nWhat is the function of the for loop? When will it stop? Can you think of a different stopping rule?\n\nModel understanding check:\n\nHow does the EM algorithm know which group refers to men and which group refers to women? (Hint: this is a trick question)\nWhat is the height of the normal distribution curve (probability density) for:\n\nA 1.5 meter tall man\nA 1.8 meter tall man\nA 1.5 meter tall woman\nA 1.8 meter tall woman\n\nFrom part (b), calculate the posterior probability to belong to the “women” class for:\n\nA 1.5 meter tall person of unknown sex (That is, calculate \\(P(\\text{Sex}=\\text{Woman} | \\text{Height} = 1.5)\\))\nA 1.8 meter tall person of unknown sex (same as above)\n\nBelow, it states, “Guessing people’s sex based on their posterior probability is not perfect.” Why is this the case?\n\nBy changing the values of the relevant variables below, experiment with different settings for the means and standard deviations. Attempt to create a situation in which:\n\nThe cross-table between guessed class and true class is near-perfect;\nThe cross-table between guessed class and true class is near-useless. What do you conclude?\n\nChange the sample size to the following settings and report your findings: \\(n = 20, 50, 100, 500, 1000, 10000\\). (Be sure to re-set the parameter values for the means and standard deviations to their original values).\nBONUS: In this exercise, we completely ignored the fact that the “prior” probabilities \\(\\pi = P(\\text{Sex} = \\text{Woman})\\) and \\(1-\\pi\\), which determine the class sizes, are not really known in practice. In other words, we set \\(\\pi\\) to its true value, \\(\\pi = 0.5\\) in our implementation. In practice, \\(\\pi\\) will be a parameter to be estimated. Implement code that does this. (Hint: you will need to adjust the E-step by using Bayes rule. The M-step for \\(\\pi\\) is just pi_est = mean(post).) Check your code by setting n to a large value, changing prob=0.5 in the simulation code to some substantially different number, and checking that your estimate corresponds to the true value.\nBONUS: The log-likelihood for this model is \\[\n\\ell(\\mu_1, \\mu_2, \\sigma_1, \\sigma_2 ; y) = \\sum_{i = 1}^n \\ln \\left[\n  \\pi \\cdot \\text{Normal}(\\mu_1, \\sigma_1) +\n  (1-\\pi) \\text{Normal}(\\mu_2, \\sigma_2)\n\\right].\n\\] Write code that calculates this log-likelihood, loglik, at each iteration of the EM for-loop. Double-check your code against the output of flexmix (or another package that provides this output).\nBONUS: Using the result from (7), implement code that terminates the for loop when the absolute relative decrease in log-likelihood, abs((loglik_current - loglik_previous)/loglik_current), say, is less than a tolerance value such as 0.001.\n\n\n\n\nWe first simulate some data ourselves.\n\nset.seed(201505) # To reproduce the same \"random\" numbers\n# These are actual estimated values from the NHANES study.\n# We will take these as the true means and standard deviations \ntrue_mean_men <- 1.74#m\ntrue_mean_women <- 1.58#m\ntrue_sd_men <- 0.08#m\ntrue_sd_women <- 0.07#m\n\n# Generate fake data from the mixture distribution\nn <- 1000 # Sample size\ntrue_sex <- rbinom(n, size = 1, prob=0.5) + 1\n# Height is normally distributed but with different means and stdevs for men and women.\nheight <- rnorm(n, c(true_mean_men, true_mean_women)[true_sex], \n                c(true_sd_men, true_sd_women)[true_sex])\n\n# Look at the data\nhist(height)\n\n\n\n\n\n\n\nNow pretend we don’t know true_sex and try to estimate (guess) mean_men, mean_women, sd_men, and sd_women…\nDefine a function runit that will run the model when called. It will return the estimated posterior probabilities to belong to one of the classes.\n\nrunit <- function(maxit=3, sep_start=0.2) {\n  \n  # Choose some starting values. I choose inaccurate ones on purpose here\n  guess_mean_men <- mean(height) + sep_start # We need to start with differences\n  guess_mean_wom <- mean(height) - sep_start\n  guess_sd_men <- sd(height)\n  guess_sd_wom <- sd(height)\n  \n  cat(\"Iter:\\tM:\\tF:\\tsd(M):\\tsd(F):\\t\\n---------------------------------------\\n\")\n  cat(sprintf(\"Start\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", \n              guess_mean_men, guess_mean_wom, \n              guess_sd_men, guess_sd_wom))\n  \n  for(it in 1:maxit) {\n    # Posterior probability of being a man is the estimated proportion of the \n    #    overall height of the probability curve for men+women \n    #    that is made up by the probability curve for men:\n    pman <- dnorm(height, mean = guess_mean_men, sd = guess_sd_men)\n    pwom <- dnorm(height, mean = guess_mean_wom, sd = guess_sd_wom)\n    \n    post <- pman / (pman + pwom)\n    \n    # The means and standard deviations for the groups of men and women are\n    #    obtained simply by using the posterior probabilities as weights. \n    # E.g. somebody with posterior 0.8 of being a man is counted 80% towards\n    #    the mean of men, and 20% towards that of women.\n    guess_mean_men <- weighted.mean(height, w = post)\n    guess_mean_wom <- weighted.mean(height, w = 1-post)\n    \n    guess_sd_men <- sqrt(weighted.mean((height - guess_mean_men)^2, w = post))\n    guess_sd_wom <- sqrt(weighted.mean((height - guess_mean_wom)^2, w = 1-post))\n    \n    # Output some of the results\n    cat(sprintf(\"%d\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", it,\n                guess_mean_men, guess_mean_wom, \n                guess_sd_men, guess_sd_wom))\n  }\n  \n  return(post) # Return the posterior probability of being a man\n}\n\nNow run the EM algorithm using our very own runit function.\n\n## Run the model!\n\n# Use height data to run the EM algorithm that estimates the means and stdevs of\n#    interest. Some intermediate output will be written to the screen.\npost <- runit(maxit=5, sep_start=0.2)\n\nIter:   M:  F:  sd(M):  sd(F):  \n---------------------------------------\nStart   1.86    1.46    0.107   0.107\n1   1.74    1.58    0.072   0.066\n2   1.74    1.58    0.072   0.066\n3   1.74    1.58    0.073   0.066\n4   1.74    1.58    0.073   0.065\n5   1.74    1.58    0.073   0.065\n\n\n\n\nGuessing people’s sex based on their posterior probability is not perfect. We can see this by making a cross-table between the guessed class and the true class (which here we happen to know because we created that variable ourselves in the simulation). So we guess the class based on the posterior probability and then tabulate this against the true class.\n\nsex <- as.factor(true_sex)\n# Guess woman if posterior probability of being a man is less than 50%:\nguess_person_sex <- as.factor(post < 0.5) \nlevels(sex) <- levels(guess_person_sex) <- c(\"Man\", \"Woman\")\n\nknitr::kable(table(guess_person_sex, true_sex))\n\n\n\n\n\n1\n2\n\n\n\n\nMan\n436\n60\n\n\nWoman\n83\n421\n\n\n\n\n\nThis table gives the probability of being classified as a man/woman, given that you truly are one:\n\ntable(guess_person_sex, true_sex) |>\n  prop.table(2) |>\n  knitr::kable(digits = 4)\n\n\n\n\n\n1\n2\n\n\n\n\nMan\n0.8401\n0.1247\n\n\nWoman\n0.1599\n0.8753\n\n\n\n\n\nThis table is sometimes called the classification table. It is a measure of separation between the classes. In practice, it cannot be calculated because we do not have the true_sex. Instead, an estimate can be calculated using the posterior probabilities. If these are well-calibrated (correspond to the true uncertainty about class membership), then calculating the within-guess mean of the posterior should give the desired classification table.\n\ncount_guesses <- tabulate(guess_person_sex)\n\ntab <- rbind(\n  tapply(post, guess_person_sex, mean), \n  tapply(1 - post, guess_person_sex, mean))\n\n# The table now estimates the probability of true class given guess. \n# We first recalculate this to a simple crosstable with counts.\nt(tab * count_guesses) |> knitr::kable(digits = 1)\n\n\n\n\nMan\n439.5\n57.4\n\n\nWoman\n60.6\n442.4\n\n\n\n\n\nAgain we can show the table using column proportions, to give an estimate of the chance of correct classification given true class membership.\n\nt(tab * count_guesses) |> \n  prop.table(2) |>\n  knitr::kable(digits = 4)\n\n\n\n\nMan\n0.8788\n0.1148\n\n\nWoman\n0.1212\n0.8852\n\n\n\n\n\n\n\n\n\nUsing flexmix, we can run the same model.\n\n# Do the same as above with the flexmix library:\nlibrary(flexmix)\n\nLoading required package: lattice\n\nheight_fit_flexmix <- flexmix(height ~ 1, k = 2)\nparameters(height_fit_flexmix)\n\n                    Comp.1    Comp.2\ncoef.(Intercept) 1.6619860 1.6578146\nsigma            0.1078282 0.1070786\n\n\nSometimes flexmix converges to a local optimum. To solve this problem,we use multiple random starts (nrep = 100):\n\nheight_fit_flexmix <- stepFlexmix(height ~ 1, k = 2, nrep = 100)\n\n2 : * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\nparameters(height_fit_flexmix)\n\n                     Comp.1     Comp.2\ncoef.(Intercept) 1.73242753 1.56980509\nsigma            0.07715975 0.06194694\n\n\nWe can also use mclust.\n\n# Or using the mclust library\nlibrary(mclust)\n\nPackage 'mclust' version 6.0.0\nType 'citation(\"mclust\")' for citing this R package in publications.\n\nheight_fit_mclust <- Mclust(height)\nsummary(height_fit_mclust, parameters = TRUE)\n\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust E (univariate, equal variance) model with 2 components: \n\n log-likelihood    n df      BIC      ICL\n       835.7496 1000  4 1643.868 1367.668\n\nClustering table:\n  1   2 \n542 458 \n\nMixing probabilities:\n        1         2 \n0.5365927 0.4634073 \n\nMeans:\n       1        2 \n1.583406 1.748475 \n\nVariances:\n          1           2 \n0.004763713 0.004763713"
  },
  {
    "objectID": "local-dependence.html",
    "href": "local-dependence.html",
    "title": "Local dependence LCA in R",
    "section": "",
    "text": "The standard latent class “cluster” model specifies that the indicators \\(Y_1, Y_2, \\ldots, Y_p\\) should be conditionally independent, given the latent variable \\(X\\), say, \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = \\prod_{j = 1}^p P(Y_j | X).\n\\] The product on the right-hand side indicates this conditional independence.\nFor example, suppose four diagnostic tests \\(Y_j\\), for \\(j = 1, \\ldots, p = 4\\), have been used to test for a disease \\(X \\in \\{0, 1\\}\\). Then for all people within the “healthy” class (\\(X=0\\), say), the four diagnostic tests should be like four independent biased coin flips, and the same should apply in the “diseased” class. This would be violated, for instance, when on diagnostic test depends on the results of another (e.g. the results of one are used to determine another), or when two tests use the same biological technique, thus giving similar errors. The same concern can be found in the SEM literature under the term “error correlation”.\nLocal dependence is a violation of the assumptions. Instead of the model given above, if, say, indicators \\(Y_1\\) and \\(Y_2\\) are locally dependent, we cannot use the simple form given on the right-hand side in that equation, and we are forced to write \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = P(Y_1, Y_2 | X) \\prod_{j = 3}^p P(Y_j | X),\n\\] so we have to have a separate model for the conditional “cross-table” \\(P(Y_1, Y_2 | X)\\). Ignoring this can have consequences for the solution and your subsequent conclusions. In the first, locally independent, equation above, the sensitivity (\\(P(Y_j = 1 | X = 1)\\)) and specificity (\\(P(Y_j = 0 | X = 0)\\)) of two indicators will look high to the model if the indicators are strongly dependent. But when this dependence was due to an error correlation, the sensitivity and specificity will be overestimated. In the extreme case, imagine including the same completely random coin flip under two different names, with two excellent indicators of the latent variable. The latent class model will then output the exact opposite of the truth: the coin flips will look reliable, while the excellent indicators will look worthless, as you can verify for yourself below.\n\n\nShow the code\noptions(warn = 1)\nlibrary(poLCA)\nset.seed(202302)\n\n\n\n\nShow the code\nn <- 2*50L # Ensure sample size is even\nsensitivity <- 0.8\nspecificity <- 0.9\n\ntrue_x <- rep(1:2, each = n/2) # Create true classes\nprobs_indicators <- c(1 - specificity, sensitivity)[true_x]\n\n# The following is a single completely useless noise variable\n# (adding 1 is necessary because poLCA expects Y ∈ {1,2})\ngarbage_coinflip <- rbinom(n, 1, prob = 0.5) + 1\n\n# Here are two excellent indicators of true_x, both with Se=0.8, Sp=0.9\ngreat_indicator1 <- rbinom(n, 1, prob = probs_indicators) + 1\ngreat_indicator2 <- rbinom(n, 1, prob = probs_indicators) + 1\n\n# The data contain two completely worthless indicators, which \n#   are completely dependent (in fact they are identical)\n# and two excellent indicators, which do have some small amount of error\nmade_up_data <- data.frame(noise1 = garbage_coinflip, \n                noise2 = garbage_coinflip, \n                good1 = great_indicator1, \n                good2 = great_indicator2)\n\n# Run the latent class model using poLCA\nfit_polca <- poLCA(cbind(noise1, noise2, good1, good2) ~ 1, nclass = 2, data = made_up_data)\n\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$noise1\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$noise2\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$good1\n           Pr(1)  Pr(2)\nclass 1:  0.5000 0.5000\nclass 2:  0.6042 0.3958\n\n$good2\n           Pr(1)  Pr(2)\nclass 1:  0.5192 0.4808\nclass 2:  0.5417 0.4583\n\nEstimated class population shares \n 0.52 0.48 \n \nPredicted class memberships (by modal posterior prob.) \n 0.52 0.48 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 100 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -206.6095 \n \nAIC(2): 431.2189\nBIC(2): 454.6655\nG^2(2): 44.2938 (Likelihood ratio/deviance statistic) \nX^2(2): 40.92018 (Chi-square goodness of fit) \n \n\n\n\n\nShow the code\nlibrary(flexmix)\n\n\nLoading required package: lattice\n\n\nShow the code\nfit_fm_ld_direct <- \n  flexmix(~1, data = made_up_data-1, \n          k = 2, \n          model = list(\n            FLXMCmvbinary(noise1 ~ 1),\n            FLXMRglmfix(formula = cbind(noise2, 1-noise2) ~ 1, \n                        nested = list(k = 2, formula = ~ noise1),\n                        family = \"binomial\"), \n            FLXMCmvbinary(good1 ~ 1),\n            FLXMCmvbinary(good2 ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\n\nCall:\nflexmix(formula = ~1, data = made_up_data - 1, k = 2, model = list(FLXMCmvbinary(noise1 ~ \n    1), FLXMRglmfix(formula = cbind(noise2, 1 - noise2) ~ 1, \n    nested = list(k = 2, formula = ~noise1), family = \"binomial\"), \n    FLXMCmvbinary(good1 ~ 1), FLXMCmvbinary(good2 ~ 1)))\n\n       prior size post>0 ratio\nComp.1  0.55   55    100  0.55\nComp.2  0.45   45    100  0.45\n\n'log Lik.' -184.6463 (df=10)\nAIC: 389.2926   BIC: 415.3443 \n\n\nShow the code\nparameters(fit_fm_ld_direct)\n\n\n[[1]]\nComp.1.center Comp.2.center \n    0.5273048     0.4222115 \n\n[[2]]\n                    Comp.1    Comp.2\ncoef.noise1       53.13213  53.13213\ncoef.(Intercept) -26.56607 -26.56607\n\n[[3]]\nComp.1.center Comp.2.center \n  0.003545498   0.995397964 \n\n[[4]]\nComp.1.center Comp.2.center \n    0.1794210     0.8249772 \n\n\nAs you can see, according to LCA, the locally dependent random noise items are perfect, while the very good indicators are almost worthless – exactly opposite to the truth. If you were so inclined, you could play around with the following elements to see how results might change:\n\nsensitivity and specificity values (currently \\(\\text{Se}=0.8\\), \\(\\text{Sp}=0.9\\));\nnumber of “good” indicators (currently two);\nnumber of dependent noise items (currently two);\nthe amount of local dependence (currently perfect dependence).\n\nIncluding an additional class can model this dependence. You can verify this by changing nclass = 2 to nclass = 3 above to see how results change. This may be a satisfactory solution there is no strong substantive reason to prefer a specific number of classes. For example, when mixture modeling is used as a density estimation technique, or when the analysis is exploratory. But you may not want to increase the number of classes when the latent classes are intended to have some predefined meaning, as is the case for our diagnostic testing example. In that case, we would like the two classes to signify “no disease” and “disease”, while possibly accounting for any local dependence.\n\n\nData from Uebersax (2009), https://www.john-uebersax.com/stat/condep.htm. These are data on four diagnostic tests for human HIV virus (Table 1) reported by Alvord et al. (1988).\n\n\nShow the code\nlibrary(tidyverse)\n\n# https://www.john-uebersax.com/stat/condep.htm\nuebersax <- read_table(\"../Examples/uebersax.tab\")\n\nuebersax_01 <- uebersax %>% \n  mutate(across(A:D, `-`, 1)) %>% \n  mutate(Freq = as.integer(Freq))\n\n# Convenience function to convert frequency data to full data \n#.  by replicating rows. This is necessary because poLCA does\n#.  not handle frequency data directly.\nfrequencies_to_fulldata <- function(df_freq) {\n  vnames <- names(df_freq)[-which(names(df_freq) == \"Freq\")]\n  \n  fulldata <- apply(df_freq, 1, function(row) {\n    if(row['Freq'] != 0)\n      t(replicate(row['Freq'], row[vnames], simplify = TRUE))\n    }) %>% Reduce(rbind, .) %>% as.data.frame\n  \n  names(fulldata) <- vnames\n\n  fulldata\n}\n\n# A dataset in which each row is replicated Freq number of \n#   times. Doing as.data.frame(table(uebersax_fulldata)) should\n#.  give back the orginal, uebersax again\nuebersax_fulldata <- frequencies_to_fulldata(uebersax)\n\n\n\n\n\nTest\nDescription\n\n\n\n\nA\nRadioimmunoassay of antigen ag121\n\n\nB\nRadioimmunoassay of HIV p24\n\n\nC\nRadioimmunoassay of HIV gp120\n\n\nD\nEnzyme-linked immunosorbent assay\n\n\n\n\n\nShow the code\nknitr::kable(uebersax_01)\n\n\n\n\n\nA\nB\nC\nD\nFreq\n\n\n\n\n0\n0\n0\n0\n170\n\n\n0\n0\n0\n1\n15\n\n\n0\n0\n1\n0\n0\n\n\n0\n0\n1\n1\n0\n\n\n0\n1\n0\n0\n6\n\n\n0\n1\n0\n1\n0\n\n\n0\n1\n1\n0\n0\n\n\n0\n1\n1\n1\n0\n\n\n1\n0\n0\n0\n4\n\n\n1\n0\n0\n1\n17\n\n\n1\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n83\n\n\n1\n1\n0\n0\n1\n\n\n1\n1\n0\n1\n4\n\n\n1\n1\n1\n0\n0\n\n\n1\n1\n1\n1\n128\n\n\n\n\n\nFit the model using poLCA.\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n\n\n\n\n\n\n\n\n\n\nShow the code\nf_ueber <- cbind(A, B, C, D) ~ 1\nfit_ueber_polca <- poLCA(f_ueber, data = uebersax_fulldata)\n\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$A\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.9703 0.0297\n\n$B\n           Pr(1)  Pr(2)\nclass 1:  0.4290 0.5710\nclass 2:  0.9644 0.0356\n\n$C\n           Pr(1)  Pr(2)\nclass 1:  0.0871 0.9129\nclass 2:  1.0000 0.0000\n\n$D\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.9195 0.0805\n\nEstimated class population shares \n 0.5401 0.4599 \n \nPredicted class memberships (by modal posterior prob.) \n 0.5421 0.4579 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 428 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -629.8827 \n \nAIC(2): 1277.765\nBIC(2): 1314.297\nG^2(2): 16.22724 (Likelihood ratio/deviance statistic) \nX^2(2): 17.1146 (Chi-square goodness of fit)"
  },
  {
    "objectID": "local-dependence.html#detecting-local-dependence",
    "href": "local-dependence.html#detecting-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Detecting local dependence",
    "text": "Detecting local dependence\n\nBivariate residuals\nWe first load a few convenience functions that work with poLCA objects from the poLCA.extras package. You may need to install this using remotes::install_github(\"daob/poLCA.extras\").\n\n\nShow the code\n# remotes::install_github(\"daob/poLCA.extras\")\n\nlibrary(poLCA.extras)\n\n\n\n\nShow the code\nbvr_ueber <- bvr(fit_ueber_polca) \nbvr_ueber |> round(4) \n\n\n       A      B      C\nB 0.0243              \nC 0.0026 4.0734       \nD 0.0308 0.0528 0.0094\n\n\nIndicators B and C appear to exhibit local dependence. That is the same conclusion reached by Uebersax. However, the BVRs are only approximately chi-square distributed, so they cannot be directly referred to a chi-square distribution. Instead we use a parametric bootstrap. The resulting bootstrapped \\(p\\)-values are:\n\n\nShow the code\npvals_boot <- bootstrap_bvr_pvals(f_ueber, \n                                  data = uebersax_fulldata,\n                                  fit_polca = fit_ueber_polca,\n                                  nclass = 2, nrep = 3)\n\npvals_boot\n\n\n      A     B     C\nB 0.610            \nC 0.520 0.000      \nD 0.265 0.560 0.240\n\n\nSo, the parametric bootstrap of our BVR values confirms there appears to be a local dependence between indicators B and C.\nNow let’s look at the bivariate residuals for our extreme earlier example, with perfect error dependence of two noise variables.\n\n\nShow the code\nbvr(fit_polca)\n\n\n         noise1   noise2    good1\nnoise2  0.00200                  \ngood1   0.00000  0.00000         \ngood2   0.00000  0.00000 40.44858\n\n\nShow the code\n# The bootstrap is not really necessary, and gives the \n#   expected result. If you wished to confirm this, you could \n#   uncomment the code below:\n#bootstrap_bvr_pvals(cbind(noise1, noise2, good1, good2) ~ 1, \n#                                  data = made_up_data,\n#                                  fit_polca = fit_polca,\n#                                  nclass = 2, nrep = 5)\n\n\nNote that the BVR detects local dependence, but the wrong pair of variables is singled out! This is because the latent class variable in the above, extreme, solution has taken over the role of the error dependence, while the “error dependence” is actually the substantively interesting disease status. While this is probably an extreme situation that is not particularly plausible in many applications. Still, it serves as an important warning that error dependencies found might not correspond to the “true” dependencies."
  },
  {
    "objectID": "local-dependence.html#modeling-local-dependence",
    "href": "local-dependence.html#modeling-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Modeling local dependence",
    "text": "Modeling local dependence\nNow that we know:\n\nThere is strong local dependence, and\nThe local dependence can make a large difference to the results;\n\nwhat can we do about it? As mentioned above, the simplest solution is always to increase the number of classes. But when this is not desired there are some ways of keeping the number of classes the same, but allowing for dependence within those classes.\n\n\nShow the code\nlibrary(flexmix)\n\n\n\nJoint item method\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> BC\n  X --> D\n\n\n\n\n\n\n\n\nFirst we reproduce the independence model, this time using flexmix.\n\n\nShow the code\nfit_fm <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax_01, \n                  model = FLXMCmvbinary())\n\nround(parameters(fit_fm), 4)\n\n\n         Comp.1 Comp.2\ncenter.A 1.0000 0.0297\ncenter.B 0.5710 0.0356\ncenter.C 0.9128 0.0000\ncenter.D 1.0000 0.0805\n\n\nShow the code\nBIC(fit_fm)\n\n\n[1] 1314.298\n\n\nNext, we model the indicators B and C jointly, using a multinomial model. The same could be achieved by combining the two items into a single indicator, but here we have done that using the interaction() function within the model formula.\n\n\nShow the code\nfit_fm_ld <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax_01, \n                  model = list(\n                    FLXMCmvbinary(A ~ 1),\n                    FLXMRmultinom(I(interaction(B, C)) ~ .),\n                    FLXMCmvbinary(D ~ 1))\n)\n\nparameters(fit_fm_ld)\n\n\n[[1]]\nComp.1.center Comp.2.center \n   0.02762408    1.00000000 \n\n[[2]]\n          Comp.1    Comp.2\ncoef1  -3.295787 -1.426241\ncoef2 -13.344558  1.610088\ncoef3 -13.344558  2.043280\n\n[[3]]\nComp.1.center Comp.2.center \n   0.07853393    0.99999989 \n\n\nShow the code\nBIC(fit_fm_ld)\n\n\n[1] 1313.246\n\n\nItem conditional probabilities can still be calculated by summing over the joint crosstable.\n\n\nShow the code\nest <- fitted(fit_fm_ld)\n\nindices <- with(uebersax_01, \n     str_split(levels(interaction(B, C)), \"\\\\.\", \n               simplify = TRUE) |>\n       apply(2, as.numeric))\n\ncbind(\n  B1 = tapply(est$Comp.1[1, 2:5], indices[, 1], sum),\n  B2 = tapply(est$Comp.2[1, 2:5], indices[, 1], sum),\n  C1 = tapply(est$Comp.1[1, 2:5], indices[, 2], sum),\n  C2 = tapply(est$Comp.2[1, 2:5], indices[, 2], sum)\n) |> round(4)\n\n\n      B1     B2 C1     C2\n0 0.9643 0.4301  1 0.0888\n1 0.0357 0.5699  0 0.9112\n\n\n\n\nDirect effect method\nWith local dependence as a direct effect (Hagenaars), equal across classes\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n  C --> B\n\n\n\n\n\n\n\n\n\n\nShow the code\nfit_fm_ld_direct <- \n  flexmix(~1, data = uebersax_01, k = 2, \n          weights = ~Freq,\n          model = list(\n            FLXMCmvbinary(A ~ 1),\n            FLXMRglmfix(formula = cbind(B, 1-B) ~ 1, \n                        nested = list(k = 2, formula = ~ C),\n                        family = \"binomial\"), \n            FLXMCmvbinary(C ~ 1),\n            FLXMCmvbinary(D ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\n\nCall:\nflexmix(formula = ~1, data = uebersax_01, k = 2, model = list(FLXMCmvbinary(A ~ \n    1), FLXMRglmfix(formula = cbind(B, 1 - B) ~ 1, nested = list(k = 2, \n    formula = ~C), family = \"binomial\"), FLXMCmvbinary(C ~ 1), \n    FLXMCmvbinary(D ~ 1)), weights = ~Freq)\n\n       prior size post>0 ratio\nComp.1 0.459  196    217 0.903\nComp.2 0.541  232    232 1.000\n\n'log Lik.' -623.2972 (df=10)\nAIC: 1266.594   BIC: 1307.186 \n\n\nShow the code\nparameters(fit_fm_ld_direct) |> lapply(round, 4)\n\n\n[[1]]\nComp.1.center Comp.2.center \n       0.0276        1.0000 \n\n[[2]]\n                  Comp.1  Comp.2\ncoef.C            1.8594  1.8594\ncoef.(Intercept) -3.2958 -1.4263\n\n[[3]]\nComp.1.center Comp.2.center \n       0.0000        0.9112 \n\n[[4]]\nComp.1.center Comp.2.center \n       0.0785        1.0000 \n\n\nWe can again calculate a conditional probability in each class for B, this time by summing over values of C. Because the model is conditional on C, this time we weight by the marginal of C, i.e. \\(P(B | X) = \\sum_C P(B | X, C) P(C)\\).\n\n\nShow the code\nP_B_given_XC <- predict(fit_fm_ld_direct, \n                        newdata = data.frame(C=0:1))\n\nP_C <- xtabs(Freq~C, data = uebersax_01) |> prop.table()\n\nc(Comp.1.avg=sum(P_B_given_XC[[1]][, 2] * P_C), \n  Comp.2.avg=sum(P_B_given_XC[[2]][, 2] * P_C))\n\n\nComp.1.avg Comp.2.avg \n 0.1128125  0.3972642 \n\n\n\n\nLoglinear formulation\nWe can use the excellent cvam package to create a loglinear latent class model. This allows for full flexibility, including the addition of local dependence parameters that do not require an arbitrary choice of “dependent” observed variable.\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n  C <--> B\n\n\n\n\n\n\n\n\nThis is probably the best solution, if you can make it work. It only tends to work for smaller examples since cvam has trouble with larger complete data cross-tables.\nIt works great for the small uebersax example.\n\n\nShow the code\nlibrary(cvam)\n\noptions(contrasts = c(\"contr.sum\", \"contr.linear\"))\n\ndf_freq <- uebersax %>% mutate_at(1:4, as.factor)\ndf_freq$X <- latentFactor(NROW(df_freq), 2)\n\nformula <- \n  paste(names(df_freq)[!names(df_freq) %in% c(\"Freq\", \"X\")],\n        collapse = \" + \") %>% \n  sprintf(\"~ X * (%s)\", .) %>%\n  as.formula()\n\nsystem.time(\n  fit_cvam <- cvam(formula, data = df_freq,\n                   freq = Freq,\n                   control = list(startValJitter = 0.1)\n))\n\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.029   0.001   0.031 \n\n\nShow the code\nsummary(fit_cvam)\n\n\n~ X * (A + B + C + D)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 428\nN from supplied data used in model fit = 428\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 16\n  cells in complete-data table = 32\ncells without latent variables = 16\n         structural zero cells =  0\n   parameters in Poisson model = 10\n                            df =  6\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 17\nGradient length = 0.000002\n\n  Final logP = 1535.422\nFinal loglik = 1535.422\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -12.8057 604.0550 -0.02 0.9831\nX1           -3.3879 604.0550 -0.01 0.9955\nA1           -4.0673 326.4914 -0.01 0.9901\nB1            0.7533   0.1018  7.40 0.0000\nC1            4.3829 370.1195  0.01 0.9906\nD1           -4.2866 348.2777 -0.01 0.9902\nX1:A1        -5.8097 326.4914 -0.02 0.9858\nX1:B1        -0.8964   0.1019 -8.80 0.0000\nX1:C1        -5.5574 370.1195 -0.02 0.9880\nX1:D1        -5.5040 348.2777 -0.02 0.9874\n\n\nShow the code\nwhat <- paste0(\"~\", LETTERS[1:4], \"|X\") |> sapply(as.formula)\nest_indep <- cvamEstimate(c(~X, what), fit_cvam)\nest_indep\n\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.5401 0.0242     0.4924     0.5870\n2 2 0.4599 0.0242     0.4130     0.5076\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.9703 0.0131     0.9304     0.9876\n4 2 2 0.0297 0.0131     0.0124     0.0696\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.4290 0.0327     0.3665     0.4938\n2 1 2 0.5710 0.0327     0.5062     0.6335\n3 2 1 0.9644 0.0132     0.9272     0.9829\n4 2 2 0.0356 0.0132     0.0171     0.0728\n~ C | X\n  X C   prob    SE prob.lower prob.upper\n1 1 1 0.0871 0.019     0.0564     0.1323\n2 1 2 0.9129 0.019     0.8677     0.9436\n3 2 1 1.0000 0.000     0.0000     1.0000\n4 2 2 0.0000 0.000     0.0000     1.0000\n~ D | X\n  X D   prob   SE prob.lower prob.upper\n1 1 1 0.0000 0.00     0.0000     1.0000\n2 1 2 1.0000 0.00     0.0000     1.0000\n3 2 1 0.9195 0.02     0.8706     0.9509\n4 2 2 0.0805 0.02     0.0491     0.1294\n\n\n(Note that the Hessian-based se’s cannot be trusted. We can look at the estimated se’s in the marginal probability tables above, or use cvam’s MCMC option to obtain standard errors on the loglinear parmeters.)\nNow we update the model with the local dependence \\(B \\times C\\), held equal across classes.\n\n\nShow the code\nformula_ld <- update(formula, ~ . + B:C)\n\nsystem.time(\n  fit_cvam_ld <- \n    cvam(formula_ld, data = df_freq, freq = Freq,\n         control = list(startValJitter = 0.05)\n))\n\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.014   0.000   0.016 \n\n\nShow the code\nsummary(fit_cvam_ld)\n\n\n~ X + A + B + C + D + X:A + X:B + X:C + X:D + B:C\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 428\nN from supplied data used in model fit = 428\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 16\n  cells in complete-data table = 32\ncells without latent variables = 16\n         structural zero cells =  0\n   parameters in Poisson model = 11\n                            df =  5\n\nStarting values:\ndefault, center\njitter SD = 0.050000\n\nEM algorithm:\nConverged at iteration 15\nGradient length = 0.000003\n\n  Final logP = 1542.008\nFinal loglik = 1542.008\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -12.6997 590.7805 -0.02 0.9828\nX1            3.6793 590.7805  0.01 0.9950\nA1           -4.0579 339.0420 -0.01 0.9905\nB1            0.7157   0.1025  6.98 0.0000\nC1            4.1125 345.8069  0.01 0.9905\nD1           -4.3085 338.3633 -0.01 0.9898\nX1:A1         5.8384 339.0420  0.02 0.9863\nX1:B1         0.4674   0.1702  2.75 0.0060\nX1:C1         5.3824 345.8069  0.02 0.9876\nX1:D1         5.5397 338.3633  0.02 0.9869\nB1:C1         0.4649   0.1444  3.22 0.0013\n\n\nShow the code\nest_locdep <- cvamEstimate(c(~X, what), fit_cvam_ld)\nest_locdep\n\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4589 0.0241     0.4121     0.5065\n2 2 0.5411 0.0241     0.4935     0.5879\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.9724 0.0122     0.9354     0.9885\n2 1 2 0.0276 0.0122     0.0115     0.0646\n3 2 1 0.0000 0.0000     0.0000     1.0000\n4 2 2 1.0000 0.0000     0.0000     1.0000\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.9643 0.0133     0.9270     0.9829\n2 1 2 0.0357 0.0133     0.0171     0.0730\n3 2 1 0.4301 0.0326     0.3677     0.4947\n4 2 2 0.5699 0.0326     0.5053     0.6323\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 1.0000 0.0000     0.0000     1.0000\n2 1 2 0.0000 0.0000     0.0000     1.0000\n3 2 1 0.0888 0.0189     0.0581     0.1335\n4 2 2 0.9112 0.0189     0.8665     0.9419\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.9215 0.0195     0.8738     0.9521\n2 1 2 0.0785 0.0195     0.0479     0.1262\n3 2 1 0.0000 0.0000     0.0000     1.0000\n4 2 2 1.0000 0.0000     0.0000     1.0000\n\n\nShow the code\nanova(fit_cvam, fit_cvam_ld)\n\n\nModel 1: ~ X * (A + B + C + D)\nModel 2: ~ X + A + B + C + D + X:A + X:B + X:C + X:D + B:C\n  resid.df -2*loglik df change\n1        6   -3070.8          \n2        5   -3084.0  1 13.171\n\n\nThe local dependence model fits better, but the estimated (conditional) probabilities do not change much."
  },
  {
    "objectID": "loglinear-LCA.html",
    "href": "loglinear-LCA.html",
    "title": "Loglinear LCA",
    "section": "",
    "text": "The loglinear formulation of LCA is very powerful. It only works for categorical data, but, in addition to the “plain vanilla” kind of locally independent LCA, it allows for:\n\nBuilt-in handling of missing data (everything is a missing data problem);\nNMAR (“unseen data-dependent”) models;\nMultiple latent class variables, unlocking arbitrary modelling with latent variables, i.e. “categorical SEM”;\n“Linear by linear” and “linear by nominal” effects, making for more parsimonious models, unlocking:\nDiscretized, “nonparametric” versions of IRT models (“DFactor models” in Latent Gold)\nCovariates/concomitant variables, including “measurement invariance” models;\nFacilities for complex sampling designs, i.e. weighting, clustering, and stratification;\nand more.\n\nThe largest drawback is that, as implemented in most software (including the excellent cvam package in R), it is extremely intensive on computer memory. This means that most models that run easily in other software will likely refuse to run on your laptop, giving an “out of memory” error.\nThe loglinear formulation of LCA is the basis of the powerful Latent Gold software, as well as its predecessor, the still-popular LEM program (https://jeroenvermunt.nl/). Latent Gold uses many optimizations, which mostly allow it to circumvent the “small models only” problem. Here, we will use cvam, whose implementation is very similar to LEM.\nTo demonstrate the uses of loglinear LCA, we use the carcinoma data from the poLCA package.\n\n\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(poLCA)\nlibrary(poLCA.extras)\n\nset.seed(202303)\n\ndata(carcinoma)\nhead(carcinoma %>% sample_n(10))\n\n\n  A B C D E F G\n1 1 1 1 1 1 1 1\n2 2 2 2 2 2 2 2\n3 1 1 1 1 1 1 1\n4 2 2 1 1 2 1 2\n5 2 2 2 2 2 2 2\n6 1 1 1 1 1 1 1\n\n\n\n\nShow the code\nf_carcinoma <- cbind(A, B, C, D, E, F, G) ~ 1\nfit_polca <- poLCA(f_carcinoma, \n                   nclass = 2,\n                   data = carcinoma, \n                   nrep = 10,\n                   verbose = FALSE)\n\nfit_polca\n\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$A\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.8835 0.1165\n\n$B\n           Pr(1)  Pr(2)\nclass 1:  0.0169 0.9831\nclass 2:  0.6456 0.3544\n\n$C\n           Pr(1)  Pr(2)\nclass 1:  0.2391 0.7609\nclass 2:  1.0000 0.0000\n\n$D\n           Pr(1)  Pr(2)\nclass 1:  0.4589 0.5411\nclass 2:  1.0000 0.0000\n\n$E\n           Pr(1)  Pr(2)\nclass 1:  0.0214 0.9786\nclass 2:  0.7771 0.2229\n\n$F\n           Pr(1)  Pr(2)\nclass 1:  0.5773 0.4227\nclass 2:  1.0000 0.0000\n\n$G\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.8835 0.1165\n\nEstimated class population shares \n 0.5012 0.4988 \n \nPredicted class memberships (by modal posterior prob.) \n 0.5 0.5 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 118 \nnumber of estimated parameters: 15 \nresidual degrees of freedom: 103 \nmaximum log-likelihood: -317.2568 \n \nAIC(2): 664.5137\nBIC(2): 706.0739\nG^2(2): 62.36543 (Likelihood ratio/deviance statistic) \nX^2(2): 92.64814 (Chi-square goodness of fit) \n \n\n\nFrom the poLCA model, using the bivariate residual (BVR) functionality in the poLCA.extras package, we can see that there are some considerable local dependencies.\n\n\nShow the code\nbvr(fit_polca) |> round(1)\n\n\n    A   B   C   D   E   F\nB 1.9                    \nC 0.5 4.1                \nD 0.5 1.2 1.5            \nE 0.6 8.3 0.6 9.3        \nF 0.5 1.2 1.9 8.2 0.6    \nG 7.1 5.7 1.5 1.0 1.9 0.9\n\n\nShow the code\nbootstrap_bvr_pvals(f_carcinoma, \n                    fit_polca = fit_polca, \n                    data = carcinoma, R = 200)\n\n\n      A     B     C     D     E     F\nB 0.205                              \nC 0.190 0.090                        \nD 0.105 0.360 0.150                  \nE 0.645 0.000 0.590 0.065            \nF 0.080 0.290 0.095 0.000 0.450      \nG 0.005 0.010 0.035 0.020 0.170 0.015\n\n\n\n\n\n\n\nShow the code\nlibrary(cvam)\n\noptions(contrasts = rep(\"contr.sum\", 2))\n\ndat <- carcinoma %>% mutate_all(as.factor)\ndf_freq <- table(dat, useNA = \"ifany\") |> as.data.frame()\n\n# Create a new variable that is completely missing (and has 2 cats)\ndf_freq$X <- latentFactor(NROW(df_freq), 2)\n\n# Create formula\nformula <- \n  paste(names(df_freq)[!names(df_freq) %in% c(\"Freq\", \"X\")],\n        collapse = \" + \") %>% \n  sprintf(\"~ X * (%s)\", .) %>%\n  as.formula()\n\nsystem.time(\n  fit_cvam <- cvam(formula, data = df_freq,\n                   freq = Freq,\n                   control = list(startValJitter = 0.1)\n))\n\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.127   0.006   0.142 \n\n\nShow the code\nsummary(fit_cvam)\n\n\n~ X * (A + B + C + D + E + F + G)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 118\nN from supplied data used in model fit = 118\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 128\n  cells in complete-data table = 256\ncells without latent variables = 128\n         structural zero cells =   0\n   parameters in Poisson model =  16\n                            df = 112\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 42\nGradient length = 0.000007\n\n  Final logP = 127.6839\nFinal loglik = 127.6839\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -23.4100 669.5679 -0.03 0.9721\nX1            3.3833 669.5680  0.01 0.9960\nA1           -3.8298 315.4106 -0.01 0.9903\nB1           -0.8658   0.2612 -3.31 0.0009\nC1            4.2032 261.6161  0.02 0.9872\nD1            4.4529 266.4354  0.02 0.9867\nE1           -0.6439   0.2572 -2.50 0.0123\nF1            4.5816 266.0340  0.02 0.9863\nG1           -4.0925 372.3337 -0.01 0.9912\nX1:A1        -4.8428 315.4106 -0.02 0.9877\nX1:B1        -1.1657   0.2614 -4.46 0.0000\nX1:C1        -4.7819 261.6161 -0.02 0.9854\nX1:D1        -4.5352 266.4354 -0.02 0.9864\nX1:E1        -1.2683   0.2590 -4.90 0.0000\nX1:F1        -4.4257 266.0340 -0.02 0.9867\nX1:G1        -5.1055 372.3337 -0.01 0.9891\n\n\nShow the code\nwhat <- paste0(\"~\", LETTERS[1:7], \"|X\") |> sapply(as.formula)\nest_indep <- cvamEstimate(c(~X, what), fit_cvam)\nest_indep\n\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.5012 0.0463     0.4113     0.5910\n2 2 0.4988 0.0463     0.4090     0.5887\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.8835 0.0429     0.7702     0.9449\n4 2 2 0.1165 0.0429     0.0551     0.2298\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.0169 0.0168     0.0024     0.1105\n2 1 2 0.9831 0.0168     0.8895     0.9976\n3 2 1 0.6456 0.0627     0.5156     0.7572\n4 2 2 0.3544 0.0627     0.2428     0.4844\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 0.2391 0.0561     0.1466     0.3650\n2 1 2 0.7609 0.0561     0.6350     0.8534\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.4589 0.0651     0.3367     0.5863\n2 1 2 0.5411 0.0651     0.4137     0.6633\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ E | X\n  X E   prob     SE prob.lower prob.upper\n1 1 1 0.0214 0.0206     0.0032     0.1305\n2 1 2 0.9786 0.0206     0.8695     0.9968\n3 2 1 0.7771 0.0545     0.6530     0.8659\n4 2 2 0.2229 0.0545     0.1341     0.3470\n~ F | X\n  X F   prob     SE prob.lower prob.upper\n1 1 1 0.5773 0.0644     0.4488     0.6961\n2 1 2 0.4227 0.0644     0.3039     0.5512\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ G | X\n  X G   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.8835 0.0429     0.7702     0.9449\n4 2 2 0.1165 0.0429     0.0551     0.2298\n\n\n(Note that the Hessian-based se’s cannot be trusted. We can look at the estimated se’s in the marginal probability tables above, or use cvam’s MCMC option to obtain standard errors on the loglinear parmeters.)\nNow we update the model with the local dependences, held equal across classes.\n\n\nShow the code\n# formula_ld <- update(formula, ~ . + D:F + A:G + B:E)\nformula_ld <- update(formula, ~ . + (A+B+D+E+F+G)^2)\n\nsystem.time(\n  fit_cvam_ld <- \n    cvam(formula_ld, data = df_freq, freq = Freq,\n         control = list(startValJitter = 0.05, iterMaxEM = 1000),\n         prior = cvam::cvamPrior(ridge = 0.1)\n))\n\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.189   0.003   0.195 \n\n\nShow the code\nsummary(fit_cvam_ld)\n\n\n~ X + A + B + C + D + E + F + G + X:A + X:B + X:C + X:D + X:E + X:F + X:G + A:B + A:D + A:E + A:F + A:G + B:D + B:E + B:F + B:G + D:E + D:F + D:G + E:F + E:G + F:G\n\nPrior:\n      Flattening frequency = 0.0\nTotal nuggets + flattening = 0.0\n              Ridge factor = 0.1\n          Intensity factor = 1.0\n\nSample size:\n              total N in supplied data = 118\nN from supplied data used in model fit = 118\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 128\n  cells in complete-data table = 256\ncells without latent variables = 128\n         structural zero cells =   0\n   parameters in Poisson model =  31\n                            df =  97\n\nStarting values:\ndefault, center\njitter SD = 0.050000\n\nEM algorithm:\nConverged at iteration 48\nGradient length = 0.000007\n\n  Final logP = 156.3212\nFinal loglik = 156.3619\n\nEstimates from EM, with Hessian-based SEs\n                coef     SE zstat   pval\n(Intercept) -7.44766 1.2413 -6.00 0.0000\nX1           0.05773 1.1782  0.05 0.9609\nA1          -1.07054 0.8586 -1.25 0.2124\nB1          -0.99729 0.6410 -1.56 0.1198\nC1           0.91826 0.4892  1.88 0.0605\nD1           1.37380 0.6926  1.98 0.0473\nE1          -0.63117 0.6675 -0.95 0.3444\nF1           1.44479 0.6807  2.12 0.0338\nG1          -0.61377 0.9487 -0.65 0.5177\nX1:A1       -1.15492 0.5704 -2.02 0.0429\nX1:B1        0.86834 0.5993  1.45 0.1473\nX1:C1       -1.80735 0.4922 -3.67 0.0002\nX1:D1       -0.43269 0.4615 -0.94 0.3484\nX1:E1       -1.20903 0.6867 -1.76 0.0783\nX1:F1       -0.90714 0.9970 -0.91 0.3629\nX1:G1       -1.15465 0.6863 -1.68 0.0925\nA1:B1        0.46370 0.2411  1.92 0.0544\nA1:D1        0.54873 0.5507  1.00 0.3190\nA1:E1        0.02503 0.2238  0.11 0.9109\nA1:F1        0.05476 0.7841  0.07 0.9443\nA1:G1        0.26642 0.2274  1.17 0.2413\nB1:D1        0.39565 0.5548  0.71 0.4758\nB1:E1        0.63904 0.2244  2.85 0.0044\nB1:F1        0.27186 0.5824  0.47 0.6407\nB1:G1        0.97343 0.5155  1.89 0.0590\nD1:E1       -0.42058 0.4911 -0.86 0.3917\nD1:F1        0.37588 0.1552  2.42 0.0154\nD1:G1        0.64085 0.5849  1.10 0.2732\nE1:F1        0.15256 0.7192  0.21 0.8320\nE1:G1        0.47018 0.2358  1.99 0.0462\nF1:G1       -0.05171 0.8287 -0.06 0.9502\n\n\nShow the code\nest_locdep <- cvamEstimate(c(~X, what), fit_cvam_ld)\nest_locdep\n\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4443 0.0502     0.3493     0.5436\n2 2 0.5557 0.0502     0.4564     0.6507\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0050 0.0097     0.0001     0.1889\n2 1 2 0.9950 0.0097     0.8111     0.9999\n3 2 1 0.7905 0.0582     0.6545     0.8826\n4 2 2 0.2095 0.0582     0.1174     0.3455\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.0226 0.0203     0.0038     0.1232\n2 1 2 0.9774 0.0203     0.8768     0.9962\n3 2 1 0.5794 0.0646     0.4503     0.6984\n4 2 2 0.4206 0.0646     0.3016     0.5497\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 0.1445 0.0629     0.0587     0.3141\n2 1 2 0.8555 0.0629     0.6859     0.9413\n3 2 1 0.9957 0.0081     0.8501     0.9999\n4 2 2 0.0043 0.0081     0.0001     0.1499\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.4202 0.0710     0.2905     0.5619\n2 1 2 0.5798 0.0710     0.4381     0.7095\n3 2 1 0.9720 0.0263     0.8391     0.9957\n4 2 2 0.0280 0.0263     0.0043     0.1609\n~ E | X\n  X E   prob     SE prob.lower prob.upper\n1 1 1 0.0048 0.0096     0.0001     0.1938\n2 1 2 0.9952 0.0096     0.8062     0.9999\n3 2 1 0.7146 0.0617     0.5805     0.8192\n4 2 2 0.2854 0.0617     0.1808     0.4195\n~ F | X\n  X F   prob     SE prob.lower prob.upper\n1 1 1 0.5242 0.0718     0.3852     0.6596\n2 1 2 0.4758 0.0718     0.3404     0.6148\n3 2 1 0.9948 0.0108     0.7542     0.9999\n4 2 2 0.0052 0.0108     0.0001     0.2458\n~ G | X\n  X G   prob     SE prob.lower prob.upper\n1 1 1 0.0046 0.0091     0.0001     0.1882\n2 1 2 0.9954 0.0091     0.8118     0.9999\n3 2 1 0.7905 0.0583     0.6543     0.8827\n4 2 2 0.2095 0.0583     0.1173     0.3457\n\n\nShow the code\nanova(fit_cvam, fit_cvam_ld, method = \"BIC\")\n\n\nModel 1: ~ X * (A + B + C + D + E + F + G)\nModel 2: ~ X + A + B + C + D + E + F + G + X:A + X:B + X:C + X:D + X:E + X:F + X:G + A:B + A:D + A:E + A:F + A:G + B:D + B:E + B:F + B:G + D:E + D:F + D:G + E:F + E:G + F:G\n  resid.df -2*loglik     BIC rank\n1      112   -255.37 -179.04    1\n2       97   -312.72 -164.83    2\n\n\nThe local dependence model fits better.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\noptions(contrasts = rep(\"contr.sum\", 2))\n\nvarnames <- LETTERS[1:5]\nsum_vars <- paste(varnames, collapse = \"+\")\n\nformula <- sprintf(\"Freq ~ X * (%s)\", sum_vars)\n# formula <- sprintf(\"Freq ~ X * (%s) + B:E + G:A + D:F + B:G + G:D\", sum_vars)\n\ndf_freq <- carcinoma[, varnames] |> table() |> as.data.frame()\nn <- nrow(df_freq)\ndf_freq$patnum <- 1:n\n\ndf_expanded <- rbind(df_freq, df_freq)\ndf_expanded$X <- rep(0:1, each = n)\npost_start <- runif(n)\ndf_expanded$post <- c(post_start, 1-post_start)\n\nsuppressWarnings( # LCAs often have boundary values within classes\n  for(i in 1:200) {\n    # M-step\n    # Loglinear model\n    fit_glm <- glm(formula, \n                   data = df_expanded, weights = post, \n                   family = \"poisson\")\n    \n    # E-step\n    eta.X <- predict(fit_glm) # Linear predictor given X\n    eta.X <- matrix(eta.X, nrow = n) |> t()\n    n.X <- sum(exp(eta.X)) # Sample size given X \n    P_YX <- exp(eta.X)/n.X # Probability of each pattern, joint (X, Y)\n    \n    P_Y <- colSums(P_YX)\n    P_X.Y <- t(P_YX) / P_Y # Posterior of X given Y\n    \n    df_expanded$post <- as.vector(P_X.Y)\n})\n\nsummary(fit_glm)\n\n\n\nCall:\nglm(formula = formula, family = \"poisson\", data = df_expanded, \n    weights = post)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.27223  -0.00021   0.00000   0.00006   2.32773  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -11.23256  966.27719  -0.012 0.990725    \nX             -9.51928 3997.51532  -0.002 0.998100    \nA1            -9.96178  966.27696  -0.010 0.991774    \nB1            -1.99081    0.50381  -3.952 7.77e-05 ***\nC1            -0.50214    0.14637  -3.431 0.000602 ***\nD1            -0.04095    0.12850  -0.319 0.749972    \nE1            -1.84747    0.44044  -4.195 2.73e-05 ***\nX:A1          11.05046  966.27699   0.011 0.990875    \nX:B1           2.31906    0.52293   4.435 9.22e-06 ***\nX:C1          11.51978 2854.03271   0.004 0.996779    \nX:D1          10.98989 2626.96297   0.004 0.996662    \nX:E1           2.51604    0.47035   5.349 8.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 346.375  on 63  degrees of freedom\nResidual deviance:  31.418  on 52  degrees of freedom\nAIC: 98.345\n\nNumber of Fisher Scoring iterations: 17\n\n\nShow the code\nP_X <- rowSums(P_YX) # Prior\nP_Y.X <- P_YX/P_X    # Conditional of Y given X\n\nP_Y.X_marginal <- sapply(varnames, function(v) {\n  apply(P_Y.X, 1, function(x) tapply(x, df_freq[, v], sum))\n})\n\nP_Y.X_marginal |> round(3)\n\n\n         A     B     C    D     E\n[1,] 0.000 0.018 0.268 0.48 0.024\n[2,] 1.000 0.982 0.732 0.52 0.976\n[3,] 0.898 0.658 1.000 1.00 0.792\n[4,] 0.102 0.342 0.000 0.00 0.208\n\n\nShow the code\n# fit_polca$probs |> lapply(round, 3)\n\nN <- sum(df_freq$Freq)\n\nexpected <- P_Y * N\nobserved <- df_freq$Freq\n\nloglik <- sum(observed * log(P_Y))\ndeviance <- -2*loglik\np <- length(coef(fit_glm))\nbic_deviance <- deviance + p*log(N)\nbic_deviance\n\n\n[1] 556.776\n\n\nShow the code\nX2 <- sum((observed - expected)^2/expected)\nG2 <- 2*sum(observed * log(observed/expected), na.rm = TRUE)\n\ndata.frame(Chisq=c(X2, fit_polca$Chisq), Gsqp=c(G2, fit_polca$Gsq), method=c(\"loglinear\", \"poLCA\"))\n\n\n     Chisq     Gsqp    method\n1 27.48417 27.98881 loglinear\n2 92.64814 62.36543     poLCA\n\n\n\n\nThis does appear to work as well. It requires more hand-holding than cvam.\n\n\nShow the code\nlibrary(gllm)\n\noptions(contrasts = rep(\"contr.treatment\", 2))\n\nK <- 3\n\ndf_expanded <- Reduce(rbind, replicate(K, df_freq, simplify = FALSE))\ndf_expanded$X <- factor(rep(seq(K), each = n))\n\nformula_gllm <- ~ X * (A + B + C + D + E)\nX <- model.matrix(formula_gllm, data = df_expanded)\ns <- replicate(K, 1:nrow(df_freq))\n\nres <- emgllm(y = df_freq$Freq, s = s, X = X)\nres\n\n\n$deviance\n[1] 28.16023\n\n$observed.values\n [1] 34  2  7  3  0  0  0  0  0  0  0  1  0  0  0  0  2  0  9 10  0  1  0 18  0\n[26]  0  0  5  0  0  0 26\n\n$fitted.values\n [1] 2.755131e+01 2.760242e+00 1.386034e+01 1.558156e+00 1.409730e-02\n [6] 9.989355e-03 8.454280e-03 4.817056e-01 1.084389e-02 4.451493e-03\n[11] 5.989757e-03 1.892922e-01 3.258625e-05 9.464652e-03 1.519161e-03\n[16] 5.304967e-01 6.896560e+00 8.201101e-01 3.489994e+00 7.632804e+00\n[21] 4.566682e-03 3.656668e-01 6.030415e-02 2.047734e+01 3.121613e-03\n[26] 1.436234e-01 2.433266e-02 8.035526e+00 1.153064e-03 4.029088e-01\n[31] 6.455638e-02 2.258447e+01\n\n$full.table\n [1] 2.755131e+01 2.757187e+00 1.385986e+01 1.387020e+00 1.407245e-02\n [6] 1.408294e-03 7.079230e-03 7.084511e-04 1.083403e-02 1.084211e-03\n[11] 5.450125e-03 5.454192e-04 5.533722e-06 5.537851e-07 2.783773e-06\n[16] 2.785850e-07 6.896190e+00 6.901336e-01 3.469171e+00 3.471759e-01\n[21] 3.522383e-03 3.525011e-04 1.771956e-03 1.773278e-04 2.711796e-03\n[26] 2.713819e-04 1.364186e-03 1.365203e-04 1.385110e-06 1.386144e-07\n[31] 6.967882e-07 6.973081e-08 4.363061e-06 1.526518e-03 2.445662e-04\n[36] 8.556714e-02 1.226294e-05 4.290473e-03 6.873842e-04 2.404973e-01\n[41] 4.812064e-06 1.683612e-03 2.697345e-04 9.437287e-02 1.352492e-05\n[46] 4.732006e-03 7.581231e-04 2.652469e-01 1.857467e-04 6.498778e-02\n[51] 1.041181e-02 3.642812e+00 5.220646e-04 1.826564e-01 2.926371e-02\n[56] 1.023859e+01 2.048619e-04 7.167568e-02 1.148329e-02 4.017695e+00\n[61] 5.757904e-04 2.014536e-01 3.227524e-02 1.129224e+01 4.363061e-06\n[66] 1.526518e-03 2.445662e-04 8.556714e-02 1.226294e-05 4.290473e-03\n[71] 6.873842e-04 2.404973e-01 4.812064e-06 1.683612e-03 2.697345e-04\n[76] 9.437287e-02 1.352492e-05 4.732006e-03 7.581231e-04 2.652469e-01\n[81] 1.857467e-04 6.498778e-02 1.041181e-02 3.642812e+00 5.220646e-04\n[86] 1.826564e-01 2.926371e-02 1.023859e+01 2.048619e-04 7.167568e-02\n[91] 1.148329e-02 4.017695e+00 5.757904e-04 2.014536e-01 3.227524e-02\n[96] 1.129224e+01\n\n\nShow the code\nwith(res, sum((fitted.values - observed.values)^2/fitted.values))\n\n\n[1] 28.49572\n\n\nShow the code\nwith(res, 2*sum(observed.values * log(observed.values/fitted.values), na.rm = TRUE))\n\n\n[1] 28.16023"
  },
  {
    "objectID": "project-reproduce-LCA.html",
    "href": "project-reproduce-LCA.html",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "",
    "text": "In this project, you will work on reading and reproducing the following paper:\n  Beller, J. (2021). Morbidity profiles in Europe and Israel: International comparisons\n          from 20 countries using biopsychosocial indicators of health via latent class analysis.\n          Journal of Public Health. https://doi.org/10.1007/s10389-021-01673-0\nYou can download a copy of the paper here: https://daob.nl/files/lca/beller-2021.pdf\nThe data used in this study were from the European Social Survey, round 7 (2014). You can find these (and more recent) data here: https://www.europeansocialsurvey.org/data/. You will need to register to download the data. Registration is free and should be instantaneous."
  },
  {
    "objectID": "project-reproduce-LCA.html#assignment",
    "href": "project-reproduce-LCA.html#assignment",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "Assignment",
    "text": "Assignment\n\nObtain the data\nCreate the dataset as indicated in the article. You should end up with 16 indicators, (excluding any covariates such as country, age, gender, or education)\n\nWhich steps taken in the paper could you criticize? Do you think they will have a large impact on the final conclusions?\nCreate two different versions of the data, one of which is as close as possible to the paper, the other differing only on the aspect of data wrangling that you believe will be the most influential.\nCreate a smaller dataset, selecting only one country of your choice. You will use this smaller dataset to initially debug the subsequent analyses. From the list of covariates in table 4, select a maximum of two or three that you find of interest.\nFor each recode, double-check your recode by creating a before/after cross-table, or by calculating means within categories for dichotomized variables. Did everything go according to your plan?\nPerform a sanity check on your data. Pay attention to Roger Peng’s EDA advice:\n\nRead in your data : Are the names of the variables correct, concise, and unambiguous?\nCheck the packaging : Are the number of rows and columns as expected? Are the types of your variables as expected? Do your variables contain weird values (such as -99)? Are some variables all-missing or constant?\nLook at the top and the bottom of your data : use head() and tail() or some other method to check the top and bottom.\nCheck your “n”s : do the sample sizes correspond to the documentation? To the paper?\n\nValidate with at least one external data source : check descriptives of your data against those in the paper (small differences may occur). Are distributions of study variables (e.g. depression) and background variables (e.g. age, gender, education) plausible? (you may want to look at official statistics for your chosen country)\nMake a plot, look at descriptives : you are free to make sensible choices of “checks” here. Examples could include checking that correlations between closely related variables are not negative, scatterplots of continuous variables or dotplots/boxplots of continuous/categorical variabels to check for outliers, etc.\n\n\nUse poLCA to estimate the LCA with 1, 2, 3, 4, 5, and 6 classes on your small dataset. (hint: it is always a good idea to start off with a small number of indicators to check that things are going OK, before increasing the model size)\n\nCheck: Did you specify everything correctly?\n\nDo a sanity check on the results. Pay attention to:\n\nReported sample sizes\nUnexpected direction of associations\nForgotten indicators, or inadvertently included covariates as indicators\n\nRerun your analysis with multiple random starts, and compare the best log-likelihood, ensuring your solution did not end up in a local maximum\nModel evaluation:\n\nCompare loglikelihood, BIC and AIC among the 6 models. Use a scree plot to select the number of classes.\nLook at bivariate residuals (BVRs). Are there any local dependencies? Is it better to increase the number of classes, or fit a model with fewer classes but local dependence?\n(BONUS) Perform a parametric bootstrap-likelihood ration test of your selected model. (hint: package flexmix allows parametric bootstrapping of the LRT via the function LR_test.)\n\nModel interpretation:\n\nLook at probability profiles. Without looking at the Beller (2021) paper, create a description for yourself of the profiles you have created.\nCreate a table of the estimated class sizes. Are any classes too small to be of interest?\nCreate a classification table and calculate the entropy \\(R^2\\). Which classes are well-separated?\nLook at the results for the prediction of class membership from covariates. Are the effects in the expected direction? What are the confidence intervals of the parameter estimates? (BONUS:) Create a plot of each covariate versus the probability to belong to each class.\n\n\nRepeat the analysis and interpretation steps with a larger model, using all countries.\nCompare the results from your two datasets from part 2(c) above.\nHow does your analysis compare to the results in Beller (2021)? Go through each of the steps in the previous question and report any similarities/differences.\nWhat do you conclude about profiles of health status in the ESS?\nBONUS: Bootstrap (empirically) the standard errors of the model and compare with the standard se’s given in poCLA (hint: packages flexmix and BayesLCA allow bootstrapping. To get bootstrap se’s using blca, use argument method = “em”, and blca.boot\nBONUS: Do the analysis with a newer ESS dataset and compare the results."
  },
  {
    "objectID": "EM-categorical.html",
    "href": "EM-categorical.html",
    "title": "EM: categorical indicators",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of conditionally independent binary indicators, and to estimate that mixture (LCA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job. You can copy code into your R environment by clicking the copy icon in the top right of each code block."
  },
  {
    "objectID": "EM-categorical.html#exercises",
    "href": "EM-categorical.html#exercises",
    "title": "EM: categorical indicators",
    "section": "Exercises",
    "text": "Exercises\n\nRead the simulation code. Do you have any questions?\nRead the EM loop. Do you understand all steps?\nCode understanding check:\n\nIn the simulation code, explain why the subscripts 1 and 2 are used respectively in P_Y.X_true[[1]][2, X].\nWhich values would you change if you wanted to implement random starts?\nSuppose the model said that the variables do not come from a binomial (Bernoulli) distribution, but from some other distribution (for example a Beta one). Which lines would you need to change?\n\nTry reversing the starting values, so, Y1 = c(0.4, 0.6) becomes Y1 = c(0.6, 0.4), and similarly for the other two variables. What happens to the estimates? How do these compare to the true values now?\nSet the number of iterations of the EM algorithm to a large number, such as maxiter = 200. What happens to the estimates?\nTry out different values of the prior, the profile probabilities, and the sample size. Report any interesting observations.\nFit the same model using poLCA (or otherwise). (Remember that you can directly analyze df_samp.) Do the results agree with our own EM implementation?\nBONUS: Calculate the log-likelihood of the model.\nBONUS: Investigate the entropy \\(R^2\\) of the posterior classification as a function of (a) the profile probabilities and (b) prior.\n\n\nSimulate data\n\nset.seed(202303)\n\nn <- 1000L # Sample size\n\nP_X_true <- 0.4 # True pi (will be class size of X=2)\n\n# Sample class memberships:\nX <- sample(1:2, size = n, replace = TRUE, \n            prob = c(1 - P_X_true, P_X_true))\n\n# True profiles:\nP_Y.X_true <- list(\n  Y1 = matrix(c(0.9, 0.2,\n                0.1, 0.8), byrow = TRUE, nrow = 2),\n  Y2 = matrix(c(0.7, 0.2,\n                0.3, 0.8), byrow = TRUE, nrow = 2),\n  Y3 = matrix(c(0.95, 0.4,\n                0.05, 0.6), byrow = TRUE, nrow = 2)\n)\n\nThe conditional (profile) probabilities \\(P(Y_j | X)\\) are:\n\nprint(P_Y.X_true)\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nWe now sample some data using the conditional probabilities and the values of X.\n\n# Sample observed indicators from binomials (Bernoullis):\nY1 <- rbinom(n, size = 1, prob = P_Y.X_true[[1]][2, X])\nY2 <- rbinom(n, size = 1, prob = P_Y.X_true[[2]][2, X])\nY3 <- rbinom(n, size = 1, prob = P_Y.X_true[[3]][2, X])\n\ndf_samp <- data.frame(Y1, Y2, Y3) # For other analyses\n\n\n\nFitting the model with our very EM algorithm\nWe will take as parameters the probabilities of a “1” response on each of the three indicators, given \\(X=1\\) or \\(X=2\\), respectively. And of course the class size \\(\\pi = P(X = 2)\\). So there are 7 parameters in total. Since there are \\(2^3 = 8\\) observeed patterns, but only 7 independent ones, the degrees of freedom for this model equals zero.\n\n# As usual, we start by guessing parameter values\nguess_PY.X <- list(\n  Y1 = c(0.4, 0.6),\n  Y2 = c(0.4, 0.6),\n  Y3 = c(0.4, 0.6)\n)\n# We will take PX (pi) to be P(X = 2)\nguess_PX <- 0.5\n\n# Number of EM iterations\nmaxiter <- 15\n\n# Start the EM algorithm!\nfor(it in 1:maxiter) {\n  # Just some output \n  if(it == 1) # A trick to make Quarto output this line correctly\n    cat(\"It:\\t(X=2)\\tY1|X=1\\tY1|X=2\\tY2|X=1\\tY2|X=2\\tY3|X=1\\tY3|X=2\\n\")\n  cat(sprintf(\"%03d\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\n\", it,\n      guess_PX, \n      guess_PY.X$Y1[1], guess_PY.X$Y1[2],\n      guess_PY.X$Y2[1], guess_PY.X$Y2[2],\n      guess_PY.X$Y3[1], guess_PY.X$Y3[2]))\n\n  # E-step\n  # ------------------\n  # For clarity purposes I am not using a loop over the three variables. \n  #  In practice, you will probably want to do that. \n\n  # The probability of observing that value if X were X=1 or X=2\n  \n  # Here we use the assumption that each value is ~ Bernoulli\n  #. In practice you would work with logs, but here we ignore that\n  P_Y1.X1 <- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[1])\n  P_Y1.X2 <- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[2])\n  \n  P_Y2.X1 <- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[1])\n  P_Y2.X2 <- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[2])\n  \n  P_Y3.X1 <- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[1])\n  P_Y3.X2 <- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[2])\n  \n  # Now we use the conditional independence assumption \n  #.  to get the probability of the whole pattern (df_samp[i, ])\n  # (In practice you will want to takes a sum of logs instead)\n  P_Y_X1 <-  P_Y1.X1 * P_Y2.X1 * P_Y3.X1\n  P_Y_X2 <-  P_Y1.X2 * P_Y2.X2 * P_Y3.X2\n  \n  # Now we use the mixture assumption to get the marginal probability of the pattern:\n  P_Y <- (1 - guess_PX)*P_Y_X1 + guess_PX*P_Y_X2\n  \n  # Finally we are ready to apply Bayes rule to get the posterior \n  #. P(X = 2 | Y = y)\n  post_X2 <- guess_PX*P_Y_X2 / P_Y\n  \n  # M-step \n  # ------------------\n  # Now we have the posterior it is easy to calculate the probabilities we need\n  \n  # M-step for 'priors' / class size of X=2\n  guess_PX <- mean(post_X2)\n  \n  # M-step for profiles\n  guess_PY.X$Y1[1] <- weighted.mean(Y1, w = (1 - post_X2))\n  guess_PY.X$Y1[2] <- weighted.mean(Y1, w = post_X2)\n  \n  guess_PY.X$Y2[1] <- weighted.mean(Y2, w = (1 - post_X2))\n  guess_PY.X$Y2[2] <- weighted.mean(Y2, w = post_X2)\n  \n  guess_PY.X$Y3[1] <- weighted.mean(Y3, w = (1 - post_X2))\n  guess_PY.X$Y3[2] <- weighted.mean(Y3, w = post_X2)\n}\n\nIt: (X=2)   Y1|X=1  Y1|X=2  Y2|X=1  Y2|X=2  Y3|X=1  Y3|X=2\n001 0.500   0.400   0.600   0.400   0.600   0.400   0.600\n002 0.426   0.228   0.538   0.341   0.647   0.145   0.420\n003 0.423   0.167   0.623   0.289   0.720   0.092   0.495\n004 0.415   0.125   0.692   0.256   0.775   0.057   0.552\n005 0.406   0.106   0.732   0.247   0.798   0.042   0.584\n006 0.399   0.099   0.753   0.250   0.804   0.037   0.601\n007 0.393   0.098   0.765   0.255   0.804   0.036   0.611\n008 0.389   0.098   0.773   0.259   0.804   0.035   0.618\n009 0.385   0.099   0.778   0.262   0.805   0.036   0.624\n010 0.381   0.100   0.782   0.264   0.806   0.037   0.628\n011 0.378   0.101   0.785   0.266   0.808   0.037   0.631\n012 0.376   0.102   0.788   0.267   0.810   0.038   0.633\n013 0.374   0.103   0.790   0.268   0.811   0.039   0.636\n014 0.371   0.105   0.792   0.269   0.813   0.040   0.638\n015 0.370   0.106   0.794   0.270   0.814   0.041   0.640\n\n\n\n\nResults\nHere are the resulting estimates of the conditional probabilities (profiles).\n\nguess_PY.X |> \n  lapply(function(x) rbind(1-x, x)) |>\n  print(digits = 3)\n\n$Y1\n   [,1]  [,2]\n  0.894 0.204\nx 0.106 0.796\n\n$Y2\n  [,1]  [,2]\n  0.73 0.184\nx 0.27 0.816\n\n$Y3\n    [,1]  [,2]\n  0.9588 0.359\nx 0.0412 0.641\n\n\nCompare these to the true profiles, which were:\n\nP_Y.X_true\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nThe estimated class sizes are\n\nc(1 - guess_PX, guess_PX) |> \n  print(digits = 3)\n\n[1] 0.632 0.368\n\n\nCompare these to the “priors” (class sizes), which were:\n\nc(1 - P_X_true, P_X_true) |> \n  print(digits = 3)\n\n[1] 0.6 0.4"
  },
  {
    "objectID": "antireli.html",
    "href": "antireli.html",
    "title": "Anti-religious speech",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(poLCA)\n\nRead the data from the General Social Survey 1987. It’s not old, it’s a classic!\n\nantireli <- read.csv(\"https://daob.nl/files/lca/antireli_data.csv\")\n\nhead(antireli)\n\n  Y1 Y2 Y3\n1  1  1  1\n2  1  1  1\n3  1  1  1\n4  1  1  1\n5  1  1  1\n6  1  1  1\n\n\nShow the data as pattern frequencies.\n\ntable(antireli) |> knitr::kable()\n\n\n\n\nY1\nY2\nY3\nFreq\n\n\n\n\n1\n1\n1\n696\n\n\n2\n1\n1\n34\n\n\n1\n2\n1\n275\n\n\n2\n2\n1\n125\n\n\n1\n1\n2\n68\n\n\n2\n1\n2\n19\n\n\n1\n2\n2\n130\n\n\n2\n2\n2\n366\n\n\n\n\n\nFit the model using poLCA.\n\nfit <- poLCA(cbind(Y1, Y2, Y3) ~ 1, data = antireli, nclass = 2)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$Y1\n           Pr(1)  Pr(2)\nclass 1:  0.2284 0.7716\nclass 2:  0.9601 0.0399\n\n$Y2\n           Pr(1)  Pr(2)\nclass 1:  0.0429 0.9571\nclass 2:  0.7424 0.2576\n\n$Y3\n           Pr(1)  Pr(2)\nclass 1:  0.2395 0.7605\nclass 2:  0.9166 0.0834\n\nEstimated class population shares \n 0.3795 0.6205 \n \nPredicted class memberships (by modal posterior prob.) \n 0.3736 0.6264 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 1713 \nnumber of estimated parameters: 7 \nresidual degrees of freedom: 0 \nmaximum log-likelihood: -2795.376 \n \nAIC(2): 5604.751\nBIC(2): 5642.873\nG^2(2): 5.926297e-10 (Likelihood ratio/deviance statistic) \nX^2(2): 5.553752e-10 (Chi-square goodness of fit) \n \n\n\nHere is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %>% \n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() +  scale_color_brewer(palette = \"Set2\")\n\n\n\n\nYou can play around with the implied probabilities in the Excel file https://daob.nl/files/lca/antirel2.xlsx (thanks to Jeroen Vermunt)."
  }
]