[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Latent class analysis",
    "section": "",
    "text": "This is a website containing some documents about latent class analysis.\nIt is intended to accompany the course “Latent Class Analysis”.\nSlides for part 1:\n\n00-Introduction\n01-LPA-and-EM-basic\n02-LCA-basic\n\nFurther slides will be posted later."
  },
  {
    "objectID": "protest-ESS.html",
    "href": "protest-ESS.html",
    "title": "Political activism in Greece",
    "section": "",
    "text": "set.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(haven)\nlibrary(poLCA)\n\n\nRead the data from the European Social Survey, round 4 (Greece).\nFor each of these survey questions, 1=“Yes” and 2=“No”.\n\n\ncontplt - Contacted politician or government official last 12 months\n\nwrkprty - Worked in political party or action group last 12 months\n\nwrkorg - Worked in another organisation or association last 12 months\n\nbadge - Worn or displayed campaign badge/sticker last 12 months\n\nsgnptit - Signed petition last 12 months\n\npbldmn - Taken part in lawful public demonstration last 12 months\n\nbctprd - Boycotted certain products last 12 months\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\n\ness_greece <- read_csv(\"https://daob.nl/files/lca/ess_greece.csv.gz\") \n\ness_greece |> rmarkdown::paged_table()\n\n\n\n  \n\n\n\nSadly, poLCA has no way of dealing with missing values other than “listwise deletion” (na.omit). For later comparability of models with different sets of variables, we create a single dataset without missings.\n\ness_greece <- na.omit(ess_greece)\n\nShow the data as pattern frequencies.\n\ntable(ess_greece) %>% \n  as.data.frame() %>%\n  filter(Freq != 0) %>% \n  rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\nCreate a convenience function that will fit the K-class model to the political participation data.\n\nfitLCA <- function(k) {\n  f <- cbind(contplt, wrkprty, wrkorg, badge, \n           sgnptit, pbldmn, bctprd) ~ 1\n  \n  poLCA(formula = f, data = ess_greece, nclass = k, \n        nrep = 10, verbose = FALSE)\n}\n\nApply the function to successively increasingly classes K = 1, 2, 3, …, 6. (Note: this can take a while!)\n\nMK <- lapply(1:6, fitLCA)\n\n\nPossible to look at AIC, BIC, etc.\n\naic_values <- sapply(MK, `[[`, \"aic\")\nbic_values <- sapply(MK, `[[`, \"bic\")\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"AIC\", las = 2)\n\n\n\n\n\nplot(seq_along(aic_values), aic_values, type = \"b\", xlab = \"Number of classes\", ylab = \"BIC\", las = 2)\n\n\n\n\n\nWe select the four-class model.\n\nform_activism <- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ 1\n\nfit <- poLCA(form_activism, \n             data = ess_greece, \n             nclass = 4, \n             nrep = 20, verbose = FALSE)\n\nHere is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %>% # from `broom` package\n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\n\nlibrary(poLCA.extras)\n\nbvr(fit)\n\n          contplt   wrkprty    wrkorg     badge   sgnptit    pbldmn\nwrkprty  3.636971                                                  \nwrkorg   5.427425  5.554144                                        \nbadge    9.174424 11.568911  7.702777                              \nsgnptit  3.027574  4.637158  4.743767  5.002371                    \npbldmn   2.748862  5.232943  6.068687  5.147027  3.224378          \nbctprd   3.042264  4.717105  5.596894  5.953936  2.472958  3.292210\n\n\n\nbootstrap_bvr_pvals(form_activism, fit, ess_greece, R = 200)\n\n        contplt wrkprty wrkorg badge sgnptit pbldmn\nwrkprty       1                                    \nwrkorg        1       1                            \nbadge         1       1      1                     \nsgnptit       1       1      1     1               \npbldmn        1       1      1     1       1       \nbctprd        1       1      1     1       1      1\n\n\n\nCreate a data frame with the posterior class memberships and predicted class has the actual classification (predclass is the “modal assignment”)\nUse the four-class model as the selected model\n\nposteriors <- data.frame(post = fit$posterior,\n                         predclass = fit$predclass)\n\nclassification_table <- posteriors %>% \n  group_by(predclass) %>% \n  summarize(across(starts_with(\"post.\"), ~ sum(.x)))\n\nclassification_table <- classification_table[,-1] |> as.matrix()\n\n# Adopt the notation X=true latent class, W=assigned class\ncolnames(classification_table) <- paste0(\"X=\", 1:4)\nrownames(classification_table) <- paste0(\"W=\", 1:4)\n\nclassification_table %>% round(1)\n\n     X=1    X=2  X=3  X=4\nW=1 19.8    0.0  1.0  0.2\nW=2  0.0 1822.0 34.8 11.1\nW=3  1.1    7.5 87.4  3.0\nW=4  1.4    4.0  8.6 60.1\n\n\nWith column proportions:\n\nclassification_table |>\n  prop.table(2) |> \n  round(3)\n\n      X=1   X=2   X=3   X=4\nW=1 0.887 0.000 0.008 0.003\nW=2 0.000 0.994 0.264 0.149\nW=3 0.051 0.004 0.663 0.040\nW=4 0.062 0.002 0.065 0.808\n\n\n\nCalculate classification errors from classification table:\n\n1 - sum(diag(classification_table)) / sum(classification_table)\n\n[1] 0.03524703\n\n\nEntropy \\(R^2\\):\n\nentropy <- function(p) sum(-p * log(p))\n\nerror_prior <- entropy(fit$P) # Class proportions\nerror_post <- mean(apply(fit$posterior, 1, entropy))\n(R2_entropy  <- (error_prior - error_post) / error_prior) # 0.741\n\n[1] 0.7410987\n\n\n\nNow we fit the four-class model, but include covariates that predict the class membership. Class membership is predicted by gender and a quadratic age effect.\nWe also use the results from the model without covariates as starting values for the solution.\nThis is where the analyzed data would have been different if we had not already deleted all cases with at least one missing value above using na.omit. In practice this may lead to trouble, especially when there are many variables.\n\nform_activism <- cbind(contplt, wrkprty, wrkorg, \n                       badge, sgnptit, pbldmn, bctprd) ~ \n  gndr + agea + I(agea^2)\n\nfit_covariates <- \n  poLCA(form_activism, \n        data = ess_greece, nclass = 4, \n        probs.start = fit$probs, \n        verbose = FALSE, nrep = 50)\n\nThe results now include multinomial regression coefficients in a model predicting class membership.\n\nfit_covariates\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$contplt\n           Pr(1)  Pr(2)\nclass 1:  0.0521 0.9479\nclass 2:  0.5629 0.4371\nclass 3:  0.0857 0.9143\nclass 4:  0.7123 0.2877\n\n$wrkprty\n           Pr(1)  Pr(2)\nclass 1:  0.0011 0.9989\nclass 2:  0.5189 0.4811\nclass 3:  0.0046 0.9954\nclass 4:  0.5283 0.4717\n\n$wrkorg\n           Pr(1)  Pr(2)\nclass 1:  0.0041 0.9959\nclass 2:  0.6616 0.3384\nclass 3:  0.0537 0.9463\nclass 4:  0.2031 0.7969\n\n$badge\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.4844 0.5156\nclass 3:  0.0000 1.0000\nclass 4:  0.3946 0.6054\n\n$sgnptit\n           Pr(1)  Pr(2)\nclass 1:  0.0009 0.9991\nclass 2:  0.8837 0.1163\nclass 3:  0.1589 0.8411\nclass 4:  0.0000 1.0000\n\n$pbldmn\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.6053 0.3947\nclass 3:  0.2215 0.7785\nclass 4:  0.2538 0.7462\n\n$bctprd\n           Pr(1)  Pr(2)\nclass 1:  0.0686 0.9314\nclass 2:  0.7581 0.2419\nclass 3:  0.4770 0.5230\nclass 4:  0.2418 0.7582\n\nEstimated class population shares \n 0.7934 0.0288 0.1345 0.0433 \n \nPredicted class memberships (by modal posterior prob.) \n 0.8589 0.0262 0.0776 0.0373 \n \n========================================================= \nFit for 4 latent classes: \n========================================================= \n2 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)    -0.66285     0.02401  -27.605     0.000\ngndr           -0.69438     0.22021   -3.153     0.002\nagea           -0.04689     0.01964   -2.387     0.019\nI(agea^2)       0.00020     0.00029    0.701     0.485\n========================================================= \n3 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)     0.40334     0.02398   16.816     0.000\ngndr           -0.41884     0.20307   -2.063     0.042\nagea           -0.04345     0.01840   -2.361     0.020\nI(agea^2)       0.00016     0.00025    0.624     0.534\n========================================================= \n4 / 1 \n            Coefficient  Std. error  t value  Pr(>|t|)\n(Intercept)    -0.17721     0.04648   -3.813     0.000\ngndr           -0.84495     0.24730   -3.417     0.001\nagea           -0.06649     0.01986   -3.349     0.001\nI(agea^2)       0.00066     0.00024    2.730     0.008\n========================================================= \nnumber of observations: 2062 \nnumber of estimated parameters: 40 \nresidual degrees of freedom: 87 \nmaximum log-likelihood: -2784.601 \n \nAIC(4): 5649.201\nBIC(4): 5874.459\nX^2(4): 148.8383 (Chi-square goodness of fit) \n \nALERT: iterations finished, MAXIMUM LIKELIHOOD NOT FOUND \n \nALERT: estimation algorithm automatically restarted with new initial values \n \n\n\nThe solution may have changed now that covariates are included.\n\ntidy(fit_covariates) %>% \n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() + scale_color_brewer(palette = \"Set2\")\n\n\n\n\n\nWe can easily plot the results of the multinomial model using the effects library.\n\nlibrary(effects)\n\n\neffect_age <- predictorEffects(fit_covariates, ~agea*gndr)\nplot(effect_age, lines=list(multiline=TRUE))\n\n\n\n\n\n\nM <- prop.table(classification_table, 2) \nMi <- solve(M) # Weight matrix\nK <- ncol(M) # Number of classes \n\n# The data used by poLCA (may differ from raw due to missings):\ndat_used_by_fit <- ess_greece\n# Assigned class membership (by default uses modal assignment):\ndat_used_by_fit$W <- fit$predclass \ndat_used_by_fit$id_obs <- seq(NROW(dat_used_by_fit))\n\n# Create expanded dataset with K rows for each observation:\ness_greece_expanded <- replicate(K, dat_used_by_fit, simplify = FALSE) |> \n  reduce(rbind)\n\n# Each of the replicated rows will correspond to one possible\n#.  value of the true latent class:\ness_greece_expanded$X <- rep(1:K, each = NROW(dat_used_by_fit))\n\n# Now we assign the BCH weights based on the \n#.   inverse- misclassification matrix Mi\ness_greece_expanded <- ess_greece_expanded %>%\n  mutate(w_bch = Mi[cbind(X, W)]) \n\n# Show a few rows of our constructed data:\ness_greece_expanded %>% arrange(id_obs) %>% head()\n\n# A tibble: 6 × 13\n  contplt wrkprty wrkorg badge sgnptit pbldmn bctprd  gndr  agea     W id_obs\n    <dbl>   <dbl>  <dbl> <dbl>   <dbl>  <dbl>  <dbl> <dbl> <dbl> <int>  <int>\n1       2       2      2     2       2      2      1     2    37     2      1\n2       2       2      2     2       2      2      1     2    37     2      1\n3       2       2      2     2       2      2      1     2    37     2      1\n4       2       2      2     2       2      2      1     2    37     2      1\n5       2       2      2     2       2      2      1     2    26     2      2\n6       2       2      2     2       2      2      1     2    26     2      2\n# … with 2 more variables: X <int>, w_bch <dbl>\n\n\nThe only library I was able to find that is both reliable and also does multinomial regression allowing negative weights is glmnet.\n\nlibrary(glmnet)\n\n# We use glmnet with our BCH weights, w_bch, pretending X\n#.  is observed. Set alpha and lambda =\nfit_glmnet <- with(ess_greece_expanded %>% \n                     mutate(age_sq = agea^2),\n     glmnet(cbind(gndr, agea, age_sq), X, weights =w_bch, \n            family = \"multinomial\", alpha = 0, lambda = 0))\n\n# The estimted coefficients\nfit_glmnet |> \n  coef() |> \n  reduce(cbind) |>\n  round(4)\n\n4 x 4 sparse Matrix of class \"dgCMatrix\"\n            s0      s0      s0      s0\n       -0.8129  2.2496 -1.1247 -0.3119\ngndr    0.0634  0.2132 -0.0632 -0.2134\nagea   -0.0081 -0.0256  0.0566 -0.0228\nage_sq  0.0001  0.0003 -0.0008  0.0004\n\n# effects library does not work with glmnet so we have to roll\n#.  our own (again)\nef <- ess_greece %>% \n  summarize(agea = sort(unique(agea)), \n            age_sq = agea^2,\n            gndr = 1.5) %>% \n  bind_cols(predict(fit_glmnet, newx=as.matrix(.), \n                   type = \"response\")[,,1])\n\nnames(ef)[4:7] <- paste0(\"X\", 1:4)\n\n# Show the effects plot\nef %>% \n  pivot_longer(X1:X4, names_to = \"Class\", values_to = \"Prob\") %>%\n  ggplot(aes(agea, Prob, colour = Class, group = Class)) +\n  geom_line() + theme_bw() + \n  scale_color_brewer(palette = \"Set2\")\n\n\n\n\nIt gives results similar to those obtained with the one-step method.\n\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] glmnet_4.1-4         Matrix_1.5-1         effects_4.2-2       \n [4] carData_3.0-5        poLCA.extras_0.1.0   poLCA_1.6.0.1       \n [7] MASS_7.3-58.1        scatterplot3d_0.3-42 haven_2.5.1         \n[10] broom_1.0.1          forcats_0.5.2        stringr_1.5.0       \n[13] dplyr_1.0.9          purrr_0.3.4          readr_2.1.2         \n[16] tidyr_1.2.0          tibble_3.1.8         ggplot2_3.3.6       \n[19] tidyverse_1.3.2     \n\nloaded via a namespace (and not attached):\n [1] nlme_3.1-160        fs_1.6.1            lubridate_1.8.0    \n [4] insight_0.19.0      RColorBrewer_1.1-3  httr_1.4.5         \n [7] tools_4.2.2         backports_1.4.1     utf8_1.2.3         \n[10] R6_2.5.1            DBI_1.1.3           colorspace_2.0-3   \n[13] nnet_7.3-18         withr_2.5.0         tidyselect_1.1.2   \n[16] compiler_4.2.2      cli_3.6.0           rvest_1.0.3        \n[19] xml2_1.3.3          labeling_0.4.2      scales_1.2.1       \n[22] digest_0.6.31       minqa_1.2.4         rmarkdown_2.16     \n[25] pkgconfig_2.0.3     htmltools_0.5.4     lme4_1.1-30        \n[28] dbplyr_2.2.1        fastmap_1.1.0       htmlwidgets_1.6.1  \n[31] rlang_1.0.6         readxl_1.4.1        rstudioapi_0.14    \n[34] shape_1.4.6         farver_2.1.1        generics_0.1.3     \n[37] jsonlite_1.8.4      googlesheets4_1.0.1 magrittr_2.0.3     \n[40] Rcpp_1.0.10         munsell_0.5.0       fansi_1.0.4        \n[43] lifecycle_1.0.3     stringi_1.7.12      yaml_2.3.7         \n[46] grid_4.2.2          crayon_1.5.1        lattice_0.20-45    \n[49] splines_4.2.2       hms_1.1.2           knitr_1.40         \n[52] pillar_1.8.1        boot_1.3-28         codetools_0.2-18   \n[55] reprex_2.0.2        glue_1.6.2          evaluate_0.16      \n[58] mitools_2.4         modelr_0.1.9        vctrs_0.5.2        \n[61] nloptr_2.0.3        tzdb_0.3.0          foreach_1.5.2      \n[64] cellranger_1.1.0    gtable_0.3.0        assertthat_0.2.1   \n[67] xfun_0.32           survey_4.1-1        survival_3.4-0     \n[70] googledrive_2.0.0   gargle_1.2.0        iterators_1.0.14   \n[73] ellipsis_0.3.2"
  },
  {
    "objectID": "em-height.html",
    "href": "em-height.html",
    "title": "EM: simple example",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of univariate Gaussians, and estimate that mixture (LPA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job.\nYou can copy code into your R environment by clicking the copy icon in the top right of each code block. You can also obtain the source code for this entire document by clicking “Code” at the top-right of this page.\n\nAfter looking through the code below, do the exercises in this section. Your instructor will of course be around to help and collaboration among participants is encouraged.\nBelow the regular questions, you will find a few “BONUS” questions. These are for those among you who are looking for a serious challenge, and you will likely find the difficulty level of these questions considerably higher. Do not worry if you do not understand these BONUS questions. Their completion is not needed for an applied understanding of LCA!\nExercises\n\nRead the simulation code. Do you have any questions?\nRead the function runit. Do you understand all steps?\n\nCode understanding check:\n\nWhy is the function dnorm used? Why is it used twice?\nWhat is happening here: post <- pman / (pman + pwom)? What is the intuitive explanation of this formula?\nWhy is weighted.mean used rather than just mean?\nWhy are the weights chosen the way they are?\nWhat is the function of the for loop? When will it stop? Can you think of a different stopping rule?\n\n\n\nModel understanding check:\n\nHow does the EM algorithm know which group refers to men and which group refers to women? (Hint: this is a trick question)\nWhat is the height of the normal distribution curve (probability density) for:\n\nA 1.5 meter tall man\nA 1.8 meter tall man\nA 1.5 meter tall woman\nA 1.8 meter tall woman\n\n\nFrom part (b), calculate the posterior probability to belong to the “women” class for:\n\nA 1.5 meter tall person of unknown sex (That is, calculate \\(P(\\text{Sex}=\\text{Woman} | \\text{Height} = 1.5)\\))\nA 1.8 meter tall person of unknown sex (same as above)\n\n\nBelow, it states, “Guessing people’s sex based on their posterior probability is not perfect.” Why is this the case?\n\n\nBy changing the values of the relevant variables below, experiment with different settings for the means and standard deviations. Attempt to create a situation in which:\n\nThe cross-table between guessed class and true class is near-perfect;\nThe cross-table between guessed class and true class is near-useless. What do you conclude?\n\n\nChange the sample size to the following settings and report your findings: \\(n = 20, 50, 100, 500, 1000, 10000\\). (Be sure to re-set the parameter values for the means and standard deviations to their original values).\n\nBONUS: In this exercise, we completely ignored the fact that the “prior” probabilities \\(\\pi = P(\\text{Sex} = \\text{Woman})\\) and \\(1-\\pi\\), which determine the class sizes, are not really known in practice. In other words, we set \\(\\pi\\) to its true value, \\(\\pi = 0.5\\) in our implementation. In practice, \\(\\pi\\) will be a parameter to be estimated. Implement code that does this. (Hint: you will need to adjust the E-step by using Bayes rule. The M-step for \\(\\pi\\) is just pi_est = mean(post).) Check your code by setting n to a large value, changing prob=0.5 in the simulation code to some substantially different number, and checking that your estimate corresponds to the true value.\n\nBONUS: The log-likelihood for this model is \\[\n\\ell(\\mu_1, \\mu_2, \\sigma_1, \\sigma_2 ; y) = \\sum_{i = 1}^n \\ln \\left[\n  \\pi \\cdot \\text{Normal}(\\mu_1, \\sigma_1) +\n  (1-\\pi) \\text{Normal}(\\mu_2, \\sigma_2)\n\\right].\n\\] Write code that calculates this log-likelihood, loglik, at each iteration of the EM for-loop. Double-check your code against the output of flexmix (or another package that provides this output).\n\nBONUS: Using the result from (7), implement code that terminates the for loop when the absolute relative decrease in log-likelihood, abs((loglik_current - loglik_previous)/loglik_current), say, is less than a tolerance value such as 0.001.\n\nWe first simulate some data ourselves.\n\nset.seed(201505) # To reproduce the same \"random\" numbers\n# These are actual estimated values from the NHANES study.\n# We will take these as the true means and standard deviations \ntrue_mean_men <- 1.74#m\ntrue_mean_women <- 1.58#m\ntrue_sd_men <- 0.08#m\ntrue_sd_women <- 0.07#m\n\n# Generate fake data from the mixture distribution\nn <- 1000 # Sample size\ntrue_sex <- rbinom(n, size = 1, prob=0.5) + 1\n# Height is normally distributed but with different means and stdevs for men and women.\nheight <- rnorm(n, c(true_mean_men, true_mean_women)[true_sex], \n                c(true_sd_men, true_sd_women)[true_sex])\n\n# Look at the data\nhist(height)\n\n\n\n\n\nNow pretend we don’t know true_sex and try to estimate (guess) mean_men, mean_women, sd_men, and sd_women…\nDefine a function runit that will run the model when called. It will return the estimated posterior probabilities to belong to one of the classes.\n\nrunit <- function(maxit=3, sep_start=0.2) {\n  \n  # Choose some starting values. I choose inaccurate ones on purpose here\n  guess_mean_men <- mean(height) + sep_start # We need to start with differences\n  guess_mean_wom <- mean(height) - sep_start\n  guess_sd_men <- sd(height)\n  guess_sd_wom <- sd(height)\n  \n  cat(\"Iter:\\tM:\\tF:\\tsd(M):\\tsd(F):\\t\\n---------------------------------------\\n\")\n  cat(sprintf(\"Start\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", \n              guess_mean_men, guess_mean_wom, \n              guess_sd_men, guess_sd_wom))\n  \n  for(it in 1:maxit) {\n    # Posterior probability of being a man is the estimated proportion of the \n    #    overall height of the probability curve for men+women \n    #    that is made up by the probability curve for men:\n    pman <- dnorm(height, mean = guess_mean_men, sd = guess_sd_men)\n    pwom <- dnorm(height, mean = guess_mean_wom, sd = guess_sd_wom)\n    \n    post <- pman / (pman + pwom)\n    \n    # The means and standard deviations for the groups of men and women are\n    #    obtained simply by using the posterior probabilities as weights. \n    # E.g. somebody with posterior 0.8 of being a man is counted 80% towards\n    #    the mean of men, and 20% towards that of women.\n    guess_mean_men <- weighted.mean(height, w = post)\n    guess_mean_wom <- weighted.mean(height, w = 1-post)\n    \n    guess_sd_men <- sqrt(weighted.mean((height - guess_mean_men)^2, w = post))\n    guess_sd_wom <- sqrt(weighted.mean((height - guess_mean_wom)^2, w = 1-post))\n    \n    # Output some of the results\n    cat(sprintf(\"%d\\t%1.2f\\t%1.2f\\t%1.3f\\t%1.3f\\n\", it,\n                guess_mean_men, guess_mean_wom, \n                guess_sd_men, guess_sd_wom))\n  }\n  \n  return(post) # Return the posterior probability of being a man\n}\n\nNow run the EM algorithm using our very own runit function.\n\n## Run the model!\n\n# Use height data to run the EM algorithm that estimates the means and stdevs of\n#    interest. Some intermediate output will be written to the screen.\npost <- runit(maxit=5, sep_start=0.2)\n\nIter:   M:  F:  sd(M):  sd(F):  \n---------------------------------------\nStart   1.86    1.46    0.107   0.107\n1   1.74    1.58    0.072   0.066\n2   1.74    1.58    0.072   0.066\n3   1.74    1.58    0.073   0.066\n4   1.74    1.58    0.073   0.065\n5   1.74    1.58    0.073   0.065\n\n\n\nGuessing people’s sex based on their posterior probability is not perfect. We can see this by making a cross-table between the guessed class and the true class (which here we happen to know because we created that variable ourselves in the simulation). So we guess the class based on the posterior probability and then tabulate this against the true class.\n\nsex <- as.factor(true_sex)\n# Guess woman if posterior probability of being a man is less than 50%:\nguess_person_sex <- as.factor(post < 0.5) \nlevels(sex) <- levels(guess_person_sex) <- c(\"Man\", \"Woman\")\n\nknitr::kable(table(guess_person_sex, true_sex))\n\n\n\n\n1\n2\n\n\n\nMan\n436\n60\n\n\nWoman\n83\n421\n\n\n\n\n\nThis table gives the probability of being classified as a man/woman, given that you truly are one:\n\ntable(guess_person_sex, true_sex) |>\n  prop.table(2) |>\n  knitr::kable(digits = 4)\n\n\n\n\n1\n2\n\n\n\nMan\n0.8401\n0.1247\n\n\nWoman\n0.1599\n0.8753\n\n\n\n\n\nThis table is sometimes called the classification table. It is a measure of separation between the classes, and plays an important role when you want to use the classifications for some subsequent analysis. In practice, it cannot be calculated because we do not have the true_sex. Instead, an estimate can be calculated using the posterior probabilities. If these are well-calibrated (correspond to the true uncertainty about class membership), then calculating the within-guess mean of the posterior should give the desired classification table.\n\ncount_guesses <- tabulate(guess_person_sex)\n\ntab <- rbind(\n  tapply(post, guess_person_sex, mean), \n  tapply(1 - post, guess_person_sex, mean))\n\n# The table now estimates the probability of true class given guess. \n# We first recalculate this to a simple crosstable with counts.\nt(tab * count_guesses) |> knitr::kable(digits = 1)\n\n\n\nMan\n439.5\n57.4\n\n\nWoman\n60.6\n442.4\n\n\n\n\nAgain we can show the table using column proportions, to give an estimate of the chance of correct classification given true class membership.\n\nt(tab * count_guesses) |> \n  prop.table(2) |>\n  knitr::kable(digits = 4)\n\n\n\nMan\n0.8788\n0.1148\n\n\nWoman\n0.1212\n0.8852\n\n\n\n\n\nUsing flexmix, we can run the same model.\n\n# Do the same as above with the flexmix library:\nlibrary(flexmix)\n\nLoading required package: lattice\n\nheight_fit_flexmix <- flexmix(height ~ 1, k = 2)\nparameters(height_fit_flexmix)\n\n                    Comp.1    Comp.2\ncoef.(Intercept) 1.6619860 1.6578146\nsigma            0.1078282 0.1070786\n\n\nSometimes flexmix converges to a local optimum. To solve this problem,we use multiple random starts (nrep = 100):\n\nheight_fit_flexmix <- stepFlexmix(height ~ 1, k = 2, nrep = 100)\n\n2 : * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n\nparameters(height_fit_flexmix)\n\n                     Comp.1     Comp.2\ncoef.(Intercept) 1.73242753 1.56980509\nsigma            0.07715975 0.06194694\n\n\nWe can also use mclust.\n\n# Or using the mclust library\nlibrary(mclust)\n\nPackage 'mclust' version 6.0.0\nType 'citation(\"mclust\")' for citing this R package in publications.\n\nheight_fit_mclust <- Mclust(height)\nsummary(height_fit_mclust, parameters = TRUE)\n\n---------------------------------------------------- \nGaussian finite mixture model fitted by EM algorithm \n---------------------------------------------------- \n\nMclust E (univariate, equal variance) model with 2 components: \n\n log-likelihood    n df      BIC      ICL\n       835.7496 1000  4 1643.868 1367.668\n\nClustering table:\n  1   2 \n542 458 \n\nMixing probabilities:\n        1         2 \n0.5365927 0.4634073 \n\nMeans:\n       1        2 \n1.583406 1.748475 \n\nVariances:\n          1           2 \n0.004763713 0.004763713"
  },
  {
    "objectID": "local-dependence.html",
    "href": "local-dependence.html",
    "title": "Local dependence LCA in R",
    "section": "",
    "text": "The standard latent class “cluster” model specifies that the indicators \\(Y_1, Y_2, \\ldots, Y_p\\) should be conditionally independent, given the latent variable \\(X\\), say, \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = \\prod_{j = 1}^p P(Y_j | X).\n\\] The product on the right-hand side indicates this conditional independence.\nFor example, suppose four diagnostic tests \\(Y_j\\), for \\(j = 1, \\ldots, p = 4\\), have been used to test for a disease \\(X \\in \\{0, 1\\}\\). Then for all people within the “healthy” class (\\(X=0\\), say), the four diagnostic tests should be like four independent biased coin flips, and the same should apply in the “diseased” class. This would be violated, for instance, when on diagnostic test depends on the results of another (e.g. the results of one are used to determine another), or when two tests use the same biological technique, thus giving similar errors. The same concern can be found in the SEM literature under the term “error correlation”.\nLocal dependence is a violation of the assumptions. Instead of the model given above, if, say, indicators \\(Y_1\\) and \\(Y_2\\) are locally dependent, we cannot use the simple form given on the right-hand side in that equation, and we are forced to write \\[\nP(Y_1, Y_2, \\ldots, Y_p | X) = P(Y_1, Y_2 | X) \\prod_{j = 3}^p P(Y_j | X),\n\\] so we have to have a separate model for the conditional “cross-table” \\(P(Y_1, Y_2 | X)\\). Ignoring this can have consequences for the solution and your subsequent conclusions. In the first, locally independent, equation above, the sensitivity (\\(P(Y_j = 1 | X = 1)\\)) and specificity (\\(P(Y_j = 0 | X = 0)\\)) of two indicators will look high to the model if the indicators are strongly dependent. But when this dependence was due to an error correlation, the sensitivity and specificity will be overestimated. In the extreme case, imagine including the same completely random coin flip under two different names, with two excellent indicators of the latent variable. The latent class model will then output the exact opposite of the truth: the coin flips will look reliable, while the excellent indicators will look worthless, as you can verify for yourself below.\n\noptions(warn = 1)\nlibrary(poLCA)\nset.seed(202302)\n\n\nn <- 2*50L # Ensure sample size is even\nsensitivity <- 0.8\nspecificity <- 0.9\n\ntrue_x <- rep(1:2, each = n/2) # Create true classes\nprobs_indicators <- c(1 - specificity, sensitivity)[true_x]\n\n# The following is a single completely useless noise variable\n# (adding 1 is necessary because poLCA expects Y ∈ {1,2})\ngarbage_coinflip <- rbinom(n, 1, prob = 0.5) + 1\n\n# Here are two excellent indicators of true_x, both with Se=0.8, Sp=0.9\ngreat_indicator1 <- rbinom(n, 1, prob = probs_indicators) + 1\ngreat_indicator2 <- rbinom(n, 1, prob = probs_indicators) + 1\n\n# The data contain two completely worthless indicators, which \n#   are completely dependent (in fact they are identical)\n# and two excellent indicators, which do have some small amount of error\nmade_up_data <- data.frame(noise1 = garbage_coinflip, \n                noise2 = garbage_coinflip, \n                good1 = great_indicator1, \n                good2 = great_indicator2)\n\n# Run the latent class model using poLCA\nfit_polca <- poLCA(cbind(noise1, noise2, good1, good2) ~ 1, nclass = 2, data = made_up_data)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$noise1\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$noise2\n          Pr(1) Pr(2)\nclass 1:      1     0\nclass 2:      0     1\n\n$good1\n           Pr(1)  Pr(2)\nclass 1:  0.5000 0.5000\nclass 2:  0.6042 0.3958\n\n$good2\n           Pr(1)  Pr(2)\nclass 1:  0.5192 0.4808\nclass 2:  0.5417 0.4583\n\nEstimated class population shares \n 0.52 0.48 \n \nPredicted class memberships (by modal posterior prob.) \n 0.52 0.48 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 100 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -206.6095 \n \nAIC(2): 431.2189\nBIC(2): 454.6655\nG^2(2): 44.2938 (Likelihood ratio/deviance statistic) \nX^2(2): 40.92018 (Chi-square goodness of fit) \n \n\n\n\nlibrary(flexmix)\n\nLoading required package: lattice\n\nfit_fm_ld_direct <- \n  flexmix(~1, data = made_up_data-1, \n          k = 2, \n          model = list(\n            FLXMCmvbinary(noise1 ~ 1),\n            FLXMRglmfix(formula = cbind(noise2, 1-noise2) ~ 1, \n                        nested = list(k = 2, formula = ~ noise1),\n                        family = \"binomial\"), \n            FLXMCmvbinary(good1 ~ 1),\n            FLXMCmvbinary(good2 ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\nCall:\nflexmix(formula = ~1, data = made_up_data - 1, k = 2, model = list(FLXMCmvbinary(noise1 ~ \n    1), FLXMRglmfix(formula = cbind(noise2, 1 - noise2) ~ 1, \n    nested = list(k = 2, formula = ~noise1), family = \"binomial\"), \n    FLXMCmvbinary(good1 ~ 1), FLXMCmvbinary(good2 ~ 1)))\n\n       prior size post>0 ratio\nComp.1  0.55   55    100  0.55\nComp.2  0.45   45    100  0.45\n\n'log Lik.' -184.6463 (df=10)\nAIC: 389.2926   BIC: 415.3443 \n\nparameters(fit_fm_ld_direct)\n\n[[1]]\nComp.1.center Comp.2.center \n    0.5273048     0.4222115 \n\n[[2]]\n                    Comp.1    Comp.2\ncoef.noise1       53.13213  53.13213\ncoef.(Intercept) -26.56607 -26.56607\n\n[[3]]\nComp.1.center Comp.2.center \n  0.003545498   0.995397964 \n\n[[4]]\nComp.1.center Comp.2.center \n    0.1794210     0.8249772 \n\n\nAs you can see, according to LCA, the locally dependent random noise items are perfect, while the very good indicators are almost worthless – exactly opposite to the truth. If you were so inclined, you could play around with the following elements to see how results might change:\n\nsensitivity and specificity values (currently \\(\\text{Se}=0.8\\), \\(\\text{Sp}=0.9\\));\nnumber of “good” indicators (currently two);\nnumber of dependent noise items (currently two);\nthe amount of local dependence (currently perfect dependence).\n\nIncluding an additional class can model this dependence. You can verify this by changing nclass = 2 to nclass = 3 above to see how results change. This may be a satisfactory solution there is no strong substantive reason to prefer a specific number of classes. For example, when mixture modeling is used as a density estimation technique, or when the analysis is exploratory. But you may not want to increase the number of classes when the latent classes are intended to have some predefined meaning, as is the case for our diagnostic testing example. In that case, we would like the two classes to signify “no disease” and “disease”, while possibly accounting for any local dependence.\n\nData from Uebersax (2009), https://www.john-uebersax.com/stat/condep.htm. These are data on four diagnostic tests for human HIV virus (Table 1) reported by Alvord et al. (1988).\n\nlibrary(tidyverse)\n\n# https://www.john-uebersax.com/stat/condep.htm\nuebersax <- read_table(\"../Examples/uebersax.tab\")\n\nuebersax_01 <- uebersax %>% \n  mutate(across(A:D, `-`, 1)) %>% \n  mutate(Freq = as.integer(Freq))\n\n# Convenience function to convert frequency data to full data \n#.  by replicating rows. This is necessary because poLCA does\n#.  not handle frequency data directly.\nfrequencies_to_fulldata <- function(df_freq) {\n  vnames <- names(df_freq)[-which(names(df_freq) == \"Freq\")]\n  \n  fulldata <- apply(df_freq, 1, function(row) {\n    if(row['Freq'] != 0)\n      t(replicate(row['Freq'], row[vnames], simplify = TRUE))\n    }) %>% Reduce(rbind, .) %>% as.data.frame\n  \n  names(fulldata) <- vnames\n\n  fulldata\n}\n\n# A dataset in which each row is replicated Freq number of \n#   times. Doing as.data.frame(table(uebersax_fulldata)) should\n#.  give back the orginal, uebersax again\nuebersax_fulldata <- frequencies_to_fulldata(uebersax)\n\n\n\nTest\nDescription\n\n\n\nA\nRadioimmunoassay of antigen ag121\n\n\nB\nRadioimmunoassay of HIV p24\n\n\nC\nRadioimmunoassay of HIV gp120\n\n\nD\nEnzyme-linked immunosorbent assay\n\n\n\n\nknitr::kable(uebersax_01)\n\n\n\nA\nB\nC\nD\nFreq\n\n\n\n0\n0\n0\n0\n170\n\n\n0\n0\n0\n1\n15\n\n\n0\n0\n1\n0\n0\n\n\n0\n0\n1\n1\n0\n\n\n0\n1\n0\n0\n6\n\n\n0\n1\n0\n1\n0\n\n\n0\n1\n1\n0\n0\n\n\n0\n1\n1\n1\n0\n\n\n1\n0\n0\n0\n4\n\n\n1\n0\n0\n1\n17\n\n\n1\n0\n1\n0\n0\n\n\n1\n0\n1\n1\n83\n\n\n1\n1\n0\n0\n1\n\n\n1\n1\n0\n1\n4\n\n\n1\n1\n1\n0\n0\n\n\n1\n1\n1\n1\n128\n\n\n\n\n\nFit the model using poLCA.\n\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n\n\n\n\n\n\n\n\n\nf_ueber <- cbind(A, B, C, D) ~ 1\nfit_ueber_polca <- poLCA(f_ueber, data = uebersax_fulldata)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$A\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.9703 0.0297\n\n$B\n           Pr(1)  Pr(2)\nclass 1:  0.4290 0.5710\nclass 2:  0.9644 0.0356\n\n$C\n           Pr(1)  Pr(2)\nclass 1:  0.0871 0.9129\nclass 2:  1.0000 0.0000\n\n$D\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.9195 0.0805\n\nEstimated class population shares \n 0.5401 0.4599 \n \nPredicted class memberships (by modal posterior prob.) \n 0.5421 0.4579 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 428 \nnumber of estimated parameters: 9 \nresidual degrees of freedom: 6 \nmaximum log-likelihood: -629.8827 \n \nAIC(2): 1277.765\nBIC(2): 1314.297\nG^2(2): 16.22724 (Likelihood ratio/deviance statistic) \nX^2(2): 17.1146 (Chi-square goodness of fit)"
  },
  {
    "objectID": "local-dependence.html#detecting-local-dependence",
    "href": "local-dependence.html#detecting-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Detecting local dependence",
    "text": "Detecting local dependence\nBivariate residuals\nWe first load a few convenience functions that work with poLCA objects from the poLCA.extras package. You may need to install this using remotes::install_github(\"daob/poLCA.extras\").\n\n# remotes::install_github(\"daob/poLCA.extras\")\n\nlibrary(poLCA.extras)\n\n\nbvr_ueber <- bvr(fit_ueber_polca) \nbvr_ueber |> round(4) \n\n       A      B      C\nB 0.0243              \nC 0.0026 4.0734       \nD 0.0308 0.0528 0.0094\n\n\nIndicators B and C appear to exhibit local dependence. That is the same conclusion reached by Uebersax. However, the BVRs are only approximately chi-square distributed, so they cannot be directly referred to a chi-square distribution. Instead we use a parametric bootstrap. The resulting bootstrapped \\(p\\)-values are:\n\npvals_boot <- bootstrap_bvr_pvals(f_ueber, \n                                  data = uebersax_fulldata,\n                                  fit_polca = fit_ueber_polca,\n                                  nclass = 2, nrep = 3)\n\npvals_boot\n\n      A     B     C\nB 0.610            \nC 0.520 0.000      \nD 0.265 0.560 0.240\n\n\nSo, the parametric bootstrap of our BVR values confirms there appears to be a local dependence between indicators B and C.\nNow let’s look at the bivariate residuals for our extreme earlier example, with perfect error dependence of two noise variables.\n\nbvr(fit_polca)\n\n         noise1   noise2    good1\nnoise2  0.00200                  \ngood1   0.00000  0.00000         \ngood2   0.00000  0.00000 40.44858\n\n# The bootstrap is not really necessary, and gives the \n#   expected result. If you wished to confirm this, you could \n#   uncomment the code below:\n#bootstrap_bvr_pvals(cbind(noise1, noise2, good1, good2) ~ 1, \n#                                  data = made_up_data,\n#                                  fit_polca = fit_polca,\n#                                  nclass = 2, nrep = 5)\n\nNote that the BVR detects local dependence, but the wrong pair of variables is singled out! This is because the latent class variable in the above, extreme, solution has taken over the role of the error dependence, while the “error dependence” is actually the substantively interesting disease status. While this is probably an extreme situation that is not particularly plausible in many applications. Still, it serves as an important warning that error dependencies found might not correspond to the “true” dependencies."
  },
  {
    "objectID": "local-dependence.html#modeling-local-dependence",
    "href": "local-dependence.html#modeling-local-dependence",
    "title": "Local dependence LCA in R",
    "section": "Modeling local dependence",
    "text": "Modeling local dependence\nNow that we know:\n\nThere is strong local dependence, and\nThe local dependence can make a large difference to the results;\n\nwhat can we do about it? As mentioned above, the simplest solution is always to increase the number of classes. But when this is not desired there are some ways of keeping the number of classes the same, but allowing for dependence within those classes.\n\nlibrary(flexmix)\n\nJoint item method\n\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> BC\n  X --> D\n\n\n\n\n\n\n\n\nFirst we reproduce the independence model, this time using flexmix.\n\nfit_fm <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax_01, \n                  model = FLXMCmvbinary())\n\nround(parameters(fit_fm), 4)\n\n         Comp.1 Comp.2\ncenter.A 1.0000 0.0297\ncenter.B 0.5710 0.0356\ncenter.C 0.9128 0.0000\ncenter.D 1.0000 0.0805\n\nBIC(fit_fm)\n\n[1] 1314.298\n\n\nNext, we model the indicators B and C jointly, using a multinomial model. The same could be achieved by combining the two items into a single indicator, but here we have done that using the interaction() function within the model formula.\n\nfit_fm_ld <- flexmix(cbind(A, B, C, D) ~ 1, k = 2, \n                  weights = ~Freq,\n                  data = uebersax_01, \n                  model = list(\n                    FLXMCmvbinary(A ~ 1),\n                    FLXMRmultinom(I(interaction(B, C)) ~ .),\n                    FLXMCmvbinary(D ~ 1))\n)\n\nparameters(fit_fm_ld)\n\n[[1]]\nComp.1.center Comp.2.center \n   0.02762408    1.00000000 \n\n[[2]]\n          Comp.1    Comp.2\ncoef1  -3.295787 -1.426241\ncoef2 -13.344558  1.610088\ncoef3 -13.344558  2.043280\n\n[[3]]\nComp.1.center Comp.2.center \n   0.07853393    0.99999989 \n\nBIC(fit_fm_ld)\n\n[1] 1313.246\n\n\nItem conditional probabilities can still be calculated by summing over the joint crosstable.\n\nest <- fitted(fit_fm_ld)\n\nindices <- with(uebersax_01, \n     str_split(levels(interaction(B, C)), \"\\\\.\", \n               simplify = TRUE) |>\n       apply(2, as.numeric))\n\ncbind(\n  B1 = tapply(est$Comp.1[1, 2:5], indices[, 1], sum),\n  B2 = tapply(est$Comp.2[1, 2:5], indices[, 1], sum),\n  C1 = tapply(est$Comp.1[1, 2:5], indices[, 2], sum),\n  C2 = tapply(est$Comp.2[1, 2:5], indices[, 2], sum)\n) |> round(4)\n\n      B1     B2 C1     C2\n0 0.9643 0.4301  1 0.0888\n1 0.0357 0.5699  0 0.9112\n\n\nDirect effect method\nWith local dependence as a direct effect (Hagenaars), equal across classes\n\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n  C --> B\n\n\n\n\n\n\n\n\n\nfit_fm_ld_direct <- \n  flexmix(~1, data = uebersax_01, k = 2, \n          weights = ~Freq,\n          model = list(\n            FLXMCmvbinary(A ~ 1),\n            FLXMRglmfix(formula = cbind(B, 1-B) ~ 1, \n                        nested = list(k = 2, formula = ~ C),\n                        family = \"binomial\"), \n            FLXMCmvbinary(C ~ 1),\n            FLXMCmvbinary(D ~ 1)))\n\nsummary(fit_fm_ld_direct)\n\n\nCall:\nflexmix(formula = ~1, data = uebersax_01, k = 2, model = list(FLXMCmvbinary(A ~ \n    1), FLXMRglmfix(formula = cbind(B, 1 - B) ~ 1, nested = list(k = 2, \n    formula = ~C), family = \"binomial\"), FLXMCmvbinary(C ~ 1), \n    FLXMCmvbinary(D ~ 1)), weights = ~Freq)\n\n       prior size post>0 ratio\nComp.1 0.459  196    217 0.903\nComp.2 0.541  232    232 1.000\n\n'log Lik.' -623.2972 (df=10)\nAIC: 1266.594   BIC: 1307.186 \n\nparameters(fit_fm_ld_direct) |> lapply(round, 4)\n\n[[1]]\nComp.1.center Comp.2.center \n       0.0276        1.0000 \n\n[[2]]\n                  Comp.1  Comp.2\ncoef.C            1.8594  1.8594\ncoef.(Intercept) -3.2958 -1.4263\n\n[[3]]\nComp.1.center Comp.2.center \n       0.0000        0.9112 \n\n[[4]]\nComp.1.center Comp.2.center \n       0.0785        1.0000 \n\n\nWe can again calculate a conditional probability in each class for B, this time by summing over values of C. Because the model is conditional on C, this time we weight by the marginal of C, i.e. \\(P(B | X) = \\sum_C P(B | X, C) P(C)\\).\n\nP_B_given_XC <- predict(fit_fm_ld_direct, \n                        newdata = data.frame(C=0:1))\n\nP_C <- xtabs(Freq~C, data = uebersax_01) |> prop.table()\n\nc(Comp.1.avg=sum(P_B_given_XC[[1]][, 2] * P_C), \n  Comp.2.avg=sum(P_B_given_XC[[2]][, 2] * P_C))\n\nComp.1.avg Comp.2.avg \n 0.1128125  0.3972642 \n\n\nLoglinear formulation\nWe can use the excellent cvam package to create a loglinear latent class model. This allows for full flexibility, including the addition of local dependence parameters that do not require an arbitrary choice of “dependent” observed variable.\n\n\n\n\n\nflowchart TD\n  X((Disease)) --> A\n  X --> B\n  X --> C\n  X --> D\n  C <--> B\n\n\n\n\n\n\n\n\nThis is probably the best solution, if you can make it work. It only tends to work for smaller examples since cvam has trouble with larger complete data cross-tables.\nIt works great for the small uebersax example.\n\nlibrary(cvam)\n\noptions(contrasts = c(\"contr.sum\", \"contr.linear\"))\n\ndf_freq <- uebersax %>% mutate_at(1:4, as.factor)\ndf_freq$X <- latentFactor(NROW(df_freq), 2)\n\nformula <- \n  paste(names(df_freq)[!names(df_freq) %in% c(\"Freq\", \"X\")],\n        collapse = \" + \") %>% \n  sprintf(\"~ X * (%s)\", .) %>%\n  as.formula()\n\nsystem.time(\n  fit_cvam <- cvam(formula, data = df_freq,\n                   freq = Freq,\n                   control = list(startValJitter = 0.1)\n))\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.029   0.001   0.031 \n\nsummary(fit_cvam)\n\n~ X * (A + B + C + D)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 428\nN from supplied data used in model fit = 428\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 16\n  cells in complete-data table = 32\ncells without latent variables = 16\n         structural zero cells =  0\n   parameters in Poisson model = 10\n                            df =  6\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 17\nGradient length = 0.000002\n\n  Final logP = 1535.422\nFinal loglik = 1535.422\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -12.8057 604.0550 -0.02 0.9831\nX1           -3.3879 604.0550 -0.01 0.9955\nA1           -4.0673 326.4914 -0.01 0.9901\nB1            0.7533   0.1018  7.40 0.0000\nC1            4.3829 370.1195  0.01 0.9906\nD1           -4.2866 348.2777 -0.01 0.9902\nX1:A1        -5.8097 326.4914 -0.02 0.9858\nX1:B1        -0.8964   0.1019 -8.80 0.0000\nX1:C1        -5.5574 370.1195 -0.02 0.9880\nX1:D1        -5.5040 348.2777 -0.02 0.9874\n\nwhat <- paste0(\"~\", LETTERS[1:4], \"|X\") |> sapply(as.formula)\nest_indep <- cvamEstimate(c(~X, what), fit_cvam)\nest_indep\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.5401 0.0242     0.4924     0.5870\n2 2 0.4599 0.0242     0.4130     0.5076\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.9703 0.0131     0.9304     0.9876\n4 2 2 0.0297 0.0131     0.0124     0.0696\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.4290 0.0327     0.3665     0.4938\n2 1 2 0.5710 0.0327     0.5062     0.6335\n3 2 1 0.9644 0.0132     0.9272     0.9829\n4 2 2 0.0356 0.0132     0.0171     0.0728\n~ C | X\n  X C   prob    SE prob.lower prob.upper\n1 1 1 0.0871 0.019     0.0564     0.1323\n2 1 2 0.9129 0.019     0.8677     0.9436\n3 2 1 1.0000 0.000     0.0000     1.0000\n4 2 2 0.0000 0.000     0.0000     1.0000\n~ D | X\n  X D   prob   SE prob.lower prob.upper\n1 1 1 0.0000 0.00     0.0000     1.0000\n2 1 2 1.0000 0.00     0.0000     1.0000\n3 2 1 0.9195 0.02     0.8706     0.9509\n4 2 2 0.0805 0.02     0.0491     0.1294\n\n\n(Note that the Hessian-based se’s cannot be trusted. We can look at the estimated se’s in the marginal probability tables above, or use cvam’s MCMC option to obtain standard errors on the loglinear parmeters.)\nNow we update the model with the local dependence \\(B \\times C\\), held equal across classes.\n\nformula_ld <- update(formula, ~ . + B:C)\n\nsystem.time(\n  fit_cvam_ld <- \n    cvam(formula_ld, data = df_freq, freq = Freq,\n         control = list(startValJitter = 0.05)\n))\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.014   0.000   0.016 \n\nsummary(fit_cvam_ld)\n\n~ X + A + B + C + D + X:A + X:B + X:C + X:D + B:C\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 428\nN from supplied data used in model fit = 428\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 16\n  cells in complete-data table = 32\ncells without latent variables = 16\n         structural zero cells =  0\n   parameters in Poisson model = 11\n                            df =  5\n\nStarting values:\ndefault, center\njitter SD = 0.050000\n\nEM algorithm:\nConverged at iteration 15\nGradient length = 0.000003\n\n  Final logP = 1542.008\nFinal loglik = 1542.008\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -12.6997 590.7805 -0.02 0.9828\nX1            3.6793 590.7805  0.01 0.9950\nA1           -4.0579 339.0420 -0.01 0.9905\nB1            0.7157   0.1025  6.98 0.0000\nC1            4.1125 345.8069  0.01 0.9905\nD1           -4.3085 338.3633 -0.01 0.9898\nX1:A1         5.8384 339.0420  0.02 0.9863\nX1:B1         0.4674   0.1702  2.75 0.0060\nX1:C1         5.3824 345.8069  0.02 0.9876\nX1:D1         5.5397 338.3633  0.02 0.9869\nB1:C1         0.4649   0.1444  3.22 0.0013\n\nest_locdep <- cvamEstimate(c(~X, what), fit_cvam_ld)\nest_locdep\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4589 0.0241     0.4121     0.5065\n2 2 0.5411 0.0241     0.4935     0.5879\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.9724 0.0122     0.9354     0.9885\n2 1 2 0.0276 0.0122     0.0115     0.0646\n3 2 1 0.0000 0.0000     0.0000     1.0000\n4 2 2 1.0000 0.0000     0.0000     1.0000\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.9643 0.0133     0.9270     0.9829\n2 1 2 0.0357 0.0133     0.0171     0.0730\n3 2 1 0.4301 0.0326     0.3677     0.4947\n4 2 2 0.5699 0.0326     0.5053     0.6323\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 1.0000 0.0000     0.0000     1.0000\n2 1 2 0.0000 0.0000     0.0000     1.0000\n3 2 1 0.0888 0.0189     0.0581     0.1335\n4 2 2 0.9112 0.0189     0.8665     0.9419\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.9215 0.0195     0.8738     0.9521\n2 1 2 0.0785 0.0195     0.0479     0.1262\n3 2 1 0.0000 0.0000     0.0000     1.0000\n4 2 2 1.0000 0.0000     0.0000     1.0000\n\nanova(fit_cvam, fit_cvam_ld)\n\nModel 1: ~ X * (A + B + C + D)\nModel 2: ~ X + A + B + C + D + X:A + X:B + X:C + X:D + B:C\n  resid.df -2*loglik df change\n1        6   -3070.8          \n2        5   -3084.0  1 13.171\n\n\nThe local dependence model fits better, but the estimated (conditional) probabilities do not change much."
  },
  {
    "objectID": "loglinear-LCA.html",
    "href": "loglinear-LCA.html",
    "title": "Loglinear LCA",
    "section": "",
    "text": "The loglinear formulation of LCA is very powerful. It only works for categorical data, but, in addition to the “plain vanilla” kind of locally independent LCA, it allows for:\n\nBuilt-in handling of missing data (everything is a missing data problem);\nNMAR (“unseen data-dependent”) models;\nMultiple latent class variables, unlocking arbitrary modelling with latent variables, i.e. “categorical SEM”;\n“Linear by linear” and “linear by nominal” effects, making for more parsimonious models, unlocking:\nDiscretized, “nonparametric” versions of IRT models (“DFactor models” in Latent Gold)\nCovariates/concomitant variables, including “measurement invariance” models;\nFacilities for complex sampling designs, i.e. weighting, clustering, and stratification;\nand more.\n\nThe largest drawback is that, as implemented in most software (including the excellent cvam package in R), it is extremely intensive on computer memory. This means that most models that run easily in other software will likely refuse to run on your laptop, giving an “out of memory” error.\nThe loglinear formulation of LCA is the basis of the powerful Latent Gold software, as well as its predecessor, the still-popular LEM program (https://jeroenvermunt.nl/). Latent Gold uses many optimizations, which mostly allow it to circumvent the “small models only” problem. Here, we will use cvam, whose implementation is very similar to LEM.\nTo demonstrate the uses of loglinear LCA, we use the carcinoma data from the poLCA package.\n\n\nlibrary(tidyverse)\nlibrary(poLCA)\nlibrary(poLCA.extras)\n\nset.seed(202303)\n\ndata(carcinoma)\nhead(carcinoma %>% sample_n(10))\n\n  A B C D E F G\n1 1 1 1 1 1 1 1\n2 2 2 2 2 2 2 2\n3 1 1 1 1 1 1 1\n4 2 2 1 1 2 1 2\n5 2 2 2 2 2 2 2\n6 1 1 1 1 1 1 1\n\n\n\nf_carcinoma <- cbind(A, B, C, D, E, F, G) ~ 1\nfit_polca <- poLCA(f_carcinoma, \n                   nclass = 2,\n                   data = carcinoma, \n                   nrep = 10,\n                   verbose = FALSE)\n\nfit_polca\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$A\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.8835 0.1165\n\n$B\n           Pr(1)  Pr(2)\nclass 1:  0.0169 0.9831\nclass 2:  0.6456 0.3544\n\n$C\n           Pr(1)  Pr(2)\nclass 1:  0.2391 0.7609\nclass 2:  1.0000 0.0000\n\n$D\n           Pr(1)  Pr(2)\nclass 1:  0.4589 0.5411\nclass 2:  1.0000 0.0000\n\n$E\n           Pr(1)  Pr(2)\nclass 1:  0.0214 0.9786\nclass 2:  0.7771 0.2229\n\n$F\n           Pr(1)  Pr(2)\nclass 1:  0.5773 0.4227\nclass 2:  1.0000 0.0000\n\n$G\n           Pr(1)  Pr(2)\nclass 1:  0.0000 1.0000\nclass 2:  0.8835 0.1165\n\nEstimated class population shares \n 0.5012 0.4988 \n \nPredicted class memberships (by modal posterior prob.) \n 0.5 0.5 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 118 \nnumber of estimated parameters: 15 \nresidual degrees of freedom: 103 \nmaximum log-likelihood: -317.2568 \n \nAIC(2): 664.5137\nBIC(2): 706.0739\nG^2(2): 62.36543 (Likelihood ratio/deviance statistic) \nX^2(2): 92.64814 (Chi-square goodness of fit) \n \n\n\nFrom the poLCA model, using the bivariate residual (BVR) functionality in the poLCA.extras package, we can see that there are some considerable local dependencies.\n\nbvr(fit_polca) |> round(1)\n\n    A   B   C   D   E   F\nB 1.9                    \nC 0.5 4.1                \nD 0.5 1.2 1.5            \nE 0.6 8.3 0.6 9.3        \nF 0.5 1.2 1.9 8.2 0.6    \nG 7.1 5.7 1.5 1.0 1.9 0.9\n\nbootstrap_bvr_pvals(f_carcinoma, \n                    fit_polca = fit_polca, \n                    data = carcinoma, R = 200)\n\n      A     B     C     D     E     F\nB 0.205                              \nC 0.190 0.090                        \nD 0.105 0.360 0.150                  \nE 0.645 0.000 0.590 0.065            \nF 0.080 0.290 0.095 0.000 0.450      \nG 0.005 0.010 0.035 0.020 0.170 0.015\n\n\n\n\nlibrary(cvam)\n\noptions(contrasts = rep(\"contr.sum\", 2))\n\ndat <- carcinoma %>% mutate_all(as.factor)\ndf_freq <- table(dat, useNA = \"ifany\") |> as.data.frame()\n\n# Create a new variable that is completely missing (and has 2 cats)\ndf_freq$X <- latentFactor(NROW(df_freq), 2)\n\n# Create formula\nformula <- \n  paste(names(df_freq)[!names(df_freq) %in% c(\"Freq\", \"X\")],\n        collapse = \" + \") %>% \n  sprintf(\"~ X * (%s)\", .) %>%\n  as.formula()\n\nsystem.time(\n  fit_cvam <- cvam(formula, data = df_freq,\n                   freq = Freq,\n                   control = list(startValJitter = 0.1)\n))\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.067   0.001   0.069 \n\nsummary(fit_cvam)\n\n~ X * (A + B + C + D + E + F + G)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 118\nN from supplied data used in model fit = 118\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 128\n  cells in complete-data table = 256\ncells without latent variables = 128\n         structural zero cells =   0\n   parameters in Poisson model =  16\n                            df = 112\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 42\nGradient length = 0.000007\n\n  Final logP = 127.6839\nFinal loglik = 127.6839\n\nEstimates from EM, with Hessian-based SEs\n                coef       SE zstat   pval\n(Intercept) -23.4100 669.5679 -0.03 0.9721\nX1            3.3833 669.5680  0.01 0.9960\nA1           -3.8298 315.4106 -0.01 0.9903\nB1           -0.8658   0.2612 -3.31 0.0009\nC1            4.2032 261.6161  0.02 0.9872\nD1            4.4529 266.4354  0.02 0.9867\nE1           -0.6439   0.2572 -2.50 0.0123\nF1            4.5816 266.0340  0.02 0.9863\nG1           -4.0925 372.3337 -0.01 0.9912\nX1:A1        -4.8428 315.4106 -0.02 0.9877\nX1:B1        -1.1657   0.2614 -4.46 0.0000\nX1:C1        -4.7819 261.6161 -0.02 0.9854\nX1:D1        -4.5352 266.4354 -0.02 0.9864\nX1:E1        -1.2683   0.2590 -4.90 0.0000\nX1:F1        -4.4257 266.0340 -0.02 0.9867\nX1:G1        -5.1055 372.3337 -0.01 0.9891\n\nwhat <- paste0(\"~\", LETTERS[1:7], \"|X\") |> sapply(as.formula)\nest_indep <- cvamEstimate(c(~X, what), fit_cvam)\nest_indep\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.5012 0.0463     0.4113     0.5910\n2 2 0.4988 0.0463     0.4090     0.5887\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.8835 0.0429     0.7702     0.9449\n4 2 2 0.1165 0.0429     0.0551     0.2298\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.0169 0.0168     0.0024     0.1105\n2 1 2 0.9831 0.0168     0.8895     0.9976\n3 2 1 0.6456 0.0627     0.5156     0.7572\n4 2 2 0.3544 0.0627     0.2428     0.4844\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 0.2391 0.0561     0.1466     0.3650\n2 1 2 0.7609 0.0561     0.6350     0.8534\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.4589 0.0651     0.3367     0.5863\n2 1 2 0.5411 0.0651     0.4137     0.6633\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ E | X\n  X E   prob     SE prob.lower prob.upper\n1 1 1 0.0214 0.0206     0.0032     0.1305\n2 1 2 0.9786 0.0206     0.8695     0.9968\n3 2 1 0.7771 0.0545     0.6530     0.8659\n4 2 2 0.2229 0.0545     0.1341     0.3470\n~ F | X\n  X F   prob     SE prob.lower prob.upper\n1 1 1 0.5773 0.0644     0.4488     0.6961\n2 1 2 0.4227 0.0644     0.3039     0.5512\n3 2 1 1.0000 0.0000     0.0000     1.0000\n4 2 2 0.0000 0.0000     0.0000     1.0000\n~ G | X\n  X G   prob     SE prob.lower prob.upper\n1 1 1 0.0000 0.0000     0.0000     1.0000\n2 1 2 1.0000 0.0000     0.0000     1.0000\n3 2 1 0.8835 0.0429     0.7702     0.9449\n4 2 2 0.1165 0.0429     0.0551     0.2298\n\n\n(Note that the Hessian-based se’s cannot be trusted. We can look at the estimated se’s in the marginal probability tables above, or use cvam’s MCMC option to obtain standard errors on the loglinear parmeters.)\nNow we update the model with the local dependences, held equal across classes.\n\n# formula_ld <- update(formula, ~ . + D:F + A:G + B:E)\nformula_ld <- update(formula, ~ . + (A+B+D+E+F+G)^2)\n\nsystem.time(\n  fit_cvam_ld <- \n    cvam(formula_ld, data = df_freq, freq = Freq,\n         control = list(startValJitter = 0.05, iterMaxEM = 1000),\n         prior = cvam::cvamPrior(ridge = 0.1)\n))\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\n\n   user  system elapsed \n  0.154   0.001   0.156 \n\nsummary(fit_cvam_ld)\n\n~ X + A + B + C + D + E + F + G + X:A + X:B + X:C + X:D + X:E + X:F + X:G + A:B + A:D + A:E + A:F + A:G + B:D + B:E + B:F + B:G + D:E + D:F + D:G + E:F + E:G + F:G\n\nPrior:\n      Flattening frequency = 0.0\nTotal nuggets + flattening = 0.0\n              Ridge factor = 0.1\n          Intensity factor = 1.0\n\nSample size:\n              total N in supplied data = 118\nN from supplied data used in model fit = 118\n           prior effective sample size =   0\n\nDegrees of freedom:\n    patterns of coarsened data = 128\n  cells in complete-data table = 256\ncells without latent variables = 128\n         structural zero cells =   0\n   parameters in Poisson model =  31\n                            df =  97\n\nStarting values:\ndefault, center\njitter SD = 0.050000\n\nEM algorithm:\nConverged at iteration 48\nGradient length = 0.000007\n\n  Final logP = 156.3212\nFinal loglik = 156.3619\n\nEstimates from EM, with Hessian-based SEs\n                coef     SE zstat   pval\n(Intercept) -7.44766 1.2413 -6.00 0.0000\nX1           0.05773 1.1782  0.05 0.9609\nA1          -1.07054 0.8586 -1.25 0.2124\nB1          -0.99729 0.6410 -1.56 0.1198\nC1           0.91826 0.4892  1.88 0.0605\nD1           1.37380 0.6926  1.98 0.0473\nE1          -0.63117 0.6675 -0.95 0.3444\nF1           1.44479 0.6807  2.12 0.0338\nG1          -0.61377 0.9487 -0.65 0.5177\nX1:A1       -1.15492 0.5704 -2.02 0.0429\nX1:B1        0.86834 0.5993  1.45 0.1473\nX1:C1       -1.80735 0.4922 -3.67 0.0002\nX1:D1       -0.43269 0.4615 -0.94 0.3484\nX1:E1       -1.20903 0.6867 -1.76 0.0783\nX1:F1       -0.90714 0.9970 -0.91 0.3629\nX1:G1       -1.15465 0.6863 -1.68 0.0925\nA1:B1        0.46370 0.2411  1.92 0.0544\nA1:D1        0.54873 0.5507  1.00 0.3190\nA1:E1        0.02503 0.2238  0.11 0.9109\nA1:F1        0.05476 0.7841  0.07 0.9443\nA1:G1        0.26642 0.2274  1.17 0.2413\nB1:D1        0.39565 0.5548  0.71 0.4758\nB1:E1        0.63904 0.2244  2.85 0.0044\nB1:F1        0.27186 0.5824  0.47 0.6407\nB1:G1        0.97343 0.5155  1.89 0.0590\nD1:E1       -0.42058 0.4911 -0.86 0.3917\nD1:F1        0.37588 0.1552  2.42 0.0154\nD1:G1        0.64085 0.5849  1.10 0.2732\nE1:F1        0.15256 0.7192  0.21 0.8320\nE1:G1        0.47018 0.2358  1.99 0.0462\nF1:G1       -0.05171 0.8287 -0.06 0.9502\n\nest_locdep <- cvamEstimate(c(~X, what), fit_cvam_ld)\nest_locdep\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4443 0.0502     0.3493     0.5436\n2 2 0.5557 0.0502     0.4564     0.6507\n~ A | X\n  X A   prob     SE prob.lower prob.upper\n1 1 1 0.0050 0.0097     0.0001     0.1889\n2 1 2 0.9950 0.0097     0.8111     0.9999\n3 2 1 0.7905 0.0582     0.6545     0.8826\n4 2 2 0.2095 0.0582     0.1174     0.3455\n~ B | X\n  X B   prob     SE prob.lower prob.upper\n1 1 1 0.0226 0.0203     0.0038     0.1232\n2 1 2 0.9774 0.0203     0.8768     0.9962\n3 2 1 0.5794 0.0646     0.4503     0.6984\n4 2 2 0.4206 0.0646     0.3016     0.5497\n~ C | X\n  X C   prob     SE prob.lower prob.upper\n1 1 1 0.1445 0.0629     0.0587     0.3141\n2 1 2 0.8555 0.0629     0.6859     0.9413\n3 2 1 0.9957 0.0081     0.8501     0.9999\n4 2 2 0.0043 0.0081     0.0001     0.1499\n~ D | X\n  X D   prob     SE prob.lower prob.upper\n1 1 1 0.4202 0.0710     0.2905     0.5619\n2 1 2 0.5798 0.0710     0.4381     0.7095\n3 2 1 0.9720 0.0263     0.8391     0.9957\n4 2 2 0.0280 0.0263     0.0043     0.1609\n~ E | X\n  X E   prob     SE prob.lower prob.upper\n1 1 1 0.0048 0.0096     0.0001     0.1938\n2 1 2 0.9952 0.0096     0.8062     0.9999\n3 2 1 0.7146 0.0617     0.5805     0.8192\n4 2 2 0.2854 0.0617     0.1808     0.4195\n~ F | X\n  X F   prob     SE prob.lower prob.upper\n1 1 1 0.5242 0.0718     0.3852     0.6596\n2 1 2 0.4758 0.0718     0.3404     0.6148\n3 2 1 0.9948 0.0108     0.7542     0.9999\n4 2 2 0.0052 0.0108     0.0001     0.2458\n~ G | X\n  X G   prob     SE prob.lower prob.upper\n1 1 1 0.0046 0.0091     0.0001     0.1882\n2 1 2 0.9954 0.0091     0.8118     0.9999\n3 2 1 0.7905 0.0583     0.6543     0.8827\n4 2 2 0.2095 0.0583     0.1173     0.3457\n\nanova(fit_cvam, fit_cvam_ld, method = \"BIC\")\n\nModel 1: ~ X * (A + B + C + D + E + F + G)\nModel 2: ~ X + A + B + C + D + E + F + G + X:A + X:B + X:C + X:D + X:E + X:F + X:G + A:B + A:D + A:E + A:F + A:G + B:D + B:E + B:F + B:G + D:E + D:F + D:G + E:F + E:G + F:G\n  resid.df -2*loglik     BIC rank\n1      112   -255.37 -179.04    1\n2       97   -312.72 -164.83    2\n\n\nThe local dependence model fits better.\n\n\n\nExample from Oberski (2016), available at https://doi.org/10.1007/s11634-015-0211-0 (open access).\n\nlibrary(readr)\nlibrary(cvam)\noptions(contrasts = rep(\"contr.sum\", 2))\n\nData are from the LISS panel. People were asked 5 times if they had voted in the last parliamentary election. This pertained to two separate elections. The substantively inspired model is as shown.\n\n\n\n\n\nflowchart TD\n  X1((Voted 2006)) ---> A[2008]\n  X1 ---> B[2009]\n  X1 ---> C[2010]\n  X2((Voted 2010)) ---> D[2011]\n  X2 ---> E[2012]\n  X1 --> X2\n\n\n\n\n\n\n\n\nRead in the data.\n\npath <- \"https://daob.nl/files/lca/vote-LISS.dat.gz\"\nvote <- readr::read_table(path, na = \".\")\n\nrmarkdown::paged_table(vote)\n\n\n\n  \n\n\n\nWe transform the data into frequencies (including the missing values). We also rename the variables A-E to write smaller formulas.\n\ndf_freq <- table(vote[, -1], useNA = \"ifany\") |> as.data.frame()\nnames(df_freq)[1:5] <- LETTERS[1:5]\n\nWe now formulate the model. It includes two different latent variables X1 and X2, which are meant to signify really voting in 2006 and 2010, respectively.\n\n# Create a new variable that is completely missing (and has 2 cats)\ndf_freq$X1 <- latentFactor(NROW(df_freq), 2)\ndf_freq$X2 <- latentFactor(NROW(df_freq), 2)\n\n# Create formula\nformula <- ~ X1 * (A + B + C) + X2 * (D + E) + X1:X2\n\nWe use cvam to fit the model.\n\nfit_cvam <- cvam(formula, data = df_freq, freq = Freq,\n                 control = list(startValJitter = 0.1))\n\nSome results of interest.\n\nsummary(fit_cvam)\n\n~ X1 * (A + B + C) + X2 * (D + E) + X1:X2\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 9510\nN from supplied data used in model fit = 9510\n           prior effective sample size =    0\n\nDegrees of freedom:\n    patterns of coarsened data = 243\n  cells in complete-data table = 128\ncells without latent variables =  32\n         structural zero cells =   0\n   parameters in Poisson model =  14\n                            df =  18\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 206\nGradient length = 0.000005\n\n  Final logP = 68648.1\nFinal loglik = 68648.1\n\nEstimates from EM, with Hessian-based SEs\n               coef      SE  zstat   pval\n(Intercept) -0.1313 0.08044  -1.63 0.1027\nX11          0.7904 0.11156   7.08 0.0000\nA1          -0.7223 0.04392 -16.45 0.0000\nB1          -0.4948 0.05053  -9.79 0.0000\nC1          -0.1910 0.04447  -4.29 0.0000\nX21         -0.2248 0.11662  -1.93 0.0539\nD1          -0.6126 0.04945 -12.39 0.0000\nE1          -0.2831 0.06674  -4.24 0.0000\nX11:A1       1.2421 0.04424  28.08 0.0000\nX11:B1       1.3693 0.04807  28.49 0.0000\nX11:C1       1.2343 0.04326  28.54 0.0000\nX21:D1      -1.2459 0.04699 -26.51 0.0000\nX21:E1      -1.4374 0.06316 -22.76 0.0000\nX11:X21     -1.0906 0.04178 -26.10 0.0000\n\nwhat <- paste0(\"~\", LETTERS[1:3], \"|X1\") |> sapply(as.formula)\nwhat <- what %>% c(paste0(\"~\", LETTERS[4:5], \"|X2\") |> sapply(as.formula))\nwhat <- c(~X1, ~X2, ~X2 | X1, what)\n\nest_indep <- cvamEstimate(what, fit_cvam)\nest_indep\n\nEstimates and SE's from EM, linearized\n~ X1\n  X1   prob     SE prob.lower prob.upper\n1  1 0.1726 0.0057     0.1618     0.1841\n2  2 0.8274 0.0057     0.8159     0.8382\n~ X2\n  X2   prob     SE prob.lower prob.upper\n1  1 0.8383 0.0063     0.8256     0.8503\n2  2 0.1617 0.0063     0.1497     0.1744\n~ X2 | X1\n  X1 X2   prob     SE prob.lower prob.upper\n1  1  1 0.2448 0.0214     0.2052     0.2892\n2  1  2 0.7552 0.0214     0.7108     0.7948\n3  2  1 0.9622 0.0049     0.9513     0.9707\n4  2  2 0.0378 0.0049     0.0293     0.0487\n~ A | X1\n  X1 A   prob     SE prob.lower prob.upper\n1  1 0 0.7388 0.0204     0.6969     0.7767\n2  1 1 0.2612 0.0204     0.2233     0.3031\n3  2 0 0.0193 0.0027     0.0147     0.0253\n4  2 1 0.9807 0.0027     0.9747     0.9853\n~ B | X1\n  X1 B   prob     SE prob.lower prob.upper\n1  1 0 0.8518 0.0178     0.8135     0.8834\n2  1 1 0.1482 0.0178     0.1166     0.1865\n3  2 0 0.0235 0.0032     0.0180     0.0305\n4  2 1 0.9765 0.0032     0.9695     0.9820\n~ C | X1\n  X1 C   prob     SE prob.lower prob.upper\n1  1 0 0.8896 0.0151     0.8563     0.9159\n2  1 1 0.1104 0.0151     0.0841     0.1437\n3  2 0 0.0547 0.0043     0.0467     0.0638\n4  2 1 0.9453 0.0043     0.9362     0.9533\n~ D | X2\n  X2 D   prob     SE prob.lower prob.upper\n1  1 0 0.0237 0.0032     0.0182     0.0308\n2  1 1 0.9763 0.0032     0.9692     0.9818\n3  2 0 0.7801 0.0233     0.7310     0.8225\n4  2 1 0.2199 0.0233     0.1775     0.2690\n~ E | X2\n  X2 E   prob     SE prob.lower prob.upper\n1  1 0 0.0310 0.0043     0.0237     0.0405\n2  1 1 0.9690 0.0043     0.9595     0.9763\n3  2 0 0.9096 0.0179     0.8677     0.9391\n4  2 1 0.0904 0.0179     0.0609     0.1323\n\n\nAs in the paper, we can also include two local dependencies by updating the formula and refitting.\n\n# Update formula\nformula_ld <- update(formula, ~ . + A:B + A:E)\n\nfit_cvam_ld <- cvam(formula_ld, data = df_freq, freq = Freq,\n                 control = list(startValJitter = 0.1))\n\nThe models are nested, so we can use the LRT to compare them.\n\nanova(fit_cvam, fit_cvam_ld)\n\nModel 1: ~ X1 * (A + B + C) + X2 * (D + E) + X1:X2\nModel 2: ~ X1 + A + B + C + X2 + D + E + X1:A + X1:B + X1:C + X2:D + X2:E + X1:X2 + A:B + A:E\n  resid.df -2*loglik df change\n1       18   -137296          \n2       16   -137364  2  67.86\n\n\nThe actual estimates are not too different.\n\nest_locdep <- cvamEstimate(what, fit_cvam_ld)\nest_locdep\n\nEstimates and SE's from EM, linearized\n~ X1\n  X1   prob     SE prob.lower prob.upper\n1  1 0.1851 0.0075     0.1709     0.2003\n2  2 0.8149 0.0075     0.7997     0.8291\n~ X2\n  X2   prob     SE prob.lower prob.upper\n1  1 0.1674 0.0069     0.1544     0.1813\n2  2 0.8326 0.0069     0.8187     0.8456\n~ X2 | X1\n  X1 X2   prob     SE prob.lower prob.upper\n1  1  1 0.7248 0.0277     0.6673     0.7756\n2  1  2 0.2752 0.0277     0.2244     0.3327\n3  2  1 0.0408 0.0058     0.0309     0.0537\n4  2  2 0.9592 0.0058     0.9463     0.9691\n~ A | X1\n  X1 A   prob     SE prob.lower prob.upper\n1  1 0 0.6550 0.0248     0.6049     0.7020\n2  1 1 0.3450 0.0248     0.2980     0.3951\n3  2 0 0.0272 0.0036     0.0210     0.0351\n4  2 1 0.9728 0.0036     0.9649     0.9790\n~ B | X1\n  X1 B   prob     SE prob.lower prob.upper\n1  1 0 0.7671 0.0248     0.7150     0.8121\n2  1 1 0.2329 0.0248     0.1879     0.2850\n3  2 0 0.0295 0.0040     0.0226     0.0384\n4  2 1 0.9705 0.0040     0.9616     0.9774\n~ C | X1\n  X1 C   prob     SE prob.lower prob.upper\n1  1 0 0.9210 0.0189     0.8752     0.9509\n2  1 1 0.0790 0.0189     0.0491     0.1248\n3  2 0 0.0351 0.0062     0.0248     0.0494\n4  2 1 0.9649 0.0062     0.9506     0.9752\n~ D | X2\n  X2 D   prob     SE prob.lower prob.upper\n1  1 0 0.7733 0.0239     0.7231     0.8167\n2  1 1 0.2267 0.0239     0.1833     0.2769\n3  2 0 0.0200 0.0035     0.0141     0.0281\n4  2 1 0.9800 0.0035     0.9719     0.9859\n~ E | X2\n  X2 E   prob     SE prob.lower prob.upper\n1  1 0 0.8879 0.0208     0.8401     0.9227\n2  1 1 0.1121 0.0208     0.0773     0.1599\n3  2 0 0.0298 0.0044     0.0223     0.0398\n4  2 1 0.9702 0.0044     0.9602     0.9777\n\n\n\nFirst consider the four-category indicators as nominal.\n\ndata(\"election\")\n\ndf_freq <- election[, 1:5] %>% table() %>% as.data.frame()\ndf_freq$X <- latentFactor(NROW(df_freq), 2)\n\n# Create formula\nformula <- ~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\n\nfit_cvam <- cvam(formula, data = df_freq, freq = Freq,\n                 control = list(startValJitter = 0.1))\n\nsummary(fit_cvam)\n\n~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 1495\nN from supplied data used in model fit = 1495\n           prior effective sample size =    0\n\nDegrees of freedom:\n    patterns of coarsened data = 1024\n  cells in complete-data table = 2048\ncells without latent variables = 1024\n         structural zero cells =    0\n   parameters in Poisson model =   32\n                            df =  992\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 115\nGradient length = 0.000034\n\n  Final logP = 1178.373\nFinal loglik = 1178.373\n\nEstimates from EM, with Hessian-based SEs\n                coef      SE  zstat   pval\n(Intercept) -3.63815 0.15757 -23.09 0.0000\nX1           1.13778 0.24287   4.68 0.0000\nMORALG1      0.16551 0.12671   1.31 0.1915\nMORALG2      1.35204 0.09074  14.90 0.0000\nMORALG3     -0.21237 0.13418  -1.58 0.1135\nCARESG1     -0.82327 0.21057  -3.91 0.0001\nCARESG2      1.03761 0.09673  10.73 0.0000\nCARESG3      0.44928 0.11499   3.91 0.0001\nKNOWG1       0.51791 0.10565   4.90 0.0000\nKNOWG2       1.59075 0.08528  18.65 0.0000\nKNOWG3      -0.39963 0.14737  -2.71 0.0067\nLEADG1      -0.75474 0.20225  -3.73 0.0002\nLEADG2       1.10371 0.10844  10.18 0.0000\nLEADG3       0.72692 0.11187   6.50 0.0000\nDISHONG1    -1.11446 0.10390 -10.73 0.0000\nDISHONG2    -0.08549 0.06760  -1.26 0.2060\nDISHONG3     0.76925 0.05154  14.93 0.0000\nX1:MORALG1  -1.54191 0.11903 -12.95 0.0000\nX1:MORALG2  -0.53811 0.09313  -5.78 0.0000\nX1:MORALG3   0.86393 0.13451   6.42 0.0000\nX1:CARESG1  -1.75411 0.20513  -8.55 0.0000\nX1:CARESG2  -0.60193 0.09661  -6.23 0.0000\nX1:CARESG3   0.94726 0.10984   8.62 0.0000\nX1:KNOWG1   -1.24453 0.10332 -12.05 0.0000\nX1:KNOWG2   -0.37086 0.08936  -4.15 0.0000\nX1:KNOWG3    0.80897 0.15394   5.25 0.0000\nX1:LEADG1   -1.73558 0.20081  -8.64 0.0000\nX1:LEADG2   -0.67058 0.10758  -6.23 0.0000\nX1:LEADG3    0.74112 0.11295   6.56 0.0000\nX1:DISHONG1  0.73923 0.10896   6.78 0.0000\nX1:DISHONG2  0.37220 0.07144   5.21 0.0000\nX1:DISHONG3 -0.22209 0.05838  -3.80 0.0001\n\nwhat <- c(~X, ~MORALG | X, ~CARESG | X, ~KNOWG | X, \n          ~LEADG | X, ~DISHONG | X)\ncvamEstimate(what, fit_cvam)\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4482 0.0218     0.4058     0.4912\n2 2 0.5518 0.0218     0.5088     0.5942\n~ MORALG | X\n  X            MORALG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0473 0.0103     0.0307     0.0722\n2 1      2 Quite well 0.4224 0.0236     0.3769     0.4693\n3 1    3 Not too well 0.3591 0.0214     0.3184     0.4020\n4 1 4 Not well at all 0.1712 0.0159     0.1423     0.2047\n5 2  1 Extremely well 0.4392 0.0204     0.3996     0.4796\n6 2      2 Quite well 0.5273 0.0194     0.4891     0.5651\n7 2    3 Not too well 0.0271 0.0078     0.0154     0.0475\n8 2 4 Not well at all 0.0064 0.0036     0.0021     0.0191\n~ CARESG | X\n  X            CARESG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0098 0.0051     0.0035     0.0272\n2 1      2 Quite well 0.1990 0.0240     0.1561     0.2501\n3 1    3 Not too well 0.5201 0.0227     0.4755     0.5644\n4 1 4 Not well at all 0.2711 0.0197     0.2343     0.3114\n5 2  1 Extremely well 0.3012 0.0182     0.2668     0.3379\n6 2      2 Quite well 0.6117 0.0184     0.5752     0.6471\n7 2    3 Not too well 0.0722 0.0134     0.0499     0.1032\n8 2 4 Not well at all 0.0149 0.0054     0.0073     0.0303\n~ KNOWG | X\n  X             KNOWG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0836 0.0122     0.0627     0.1108\n2 1      2 Quite well 0.5858 0.0210     0.5440     0.6263\n3 1    3 Not too well 0.2604 0.0185     0.2258     0.2984\n4 1 4 Not well at all 0.0701 0.0103     0.0525     0.0932\n5 2  1 Extremely well 0.4375 0.0203     0.3982     0.4776\n6 2      2 Quite well 0.5340 0.0193     0.4961     0.5715\n7 2    3 Not too well 0.0224 0.0077     0.0114     0.0438\n8 2 4 Not well at all 0.0061 0.0031     0.0022     0.0164\n~ LEADG | X\n  X             LEADG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0107 0.0052     0.0041     0.0276\n2 1      2 Quite well 0.1985 0.0230     0.1573     0.2473\n3 1    3 Not too well 0.5588 0.0223     0.5148     0.6019\n4 1 4 Not well at all 0.2320 0.0184     0.1979     0.2701\n5 2  1 Extremely well 0.2774 0.0177     0.2442     0.3133\n6 2      2 Quite well 0.6133 0.0184     0.5766     0.6488\n7 2    3 Not too well 0.1026 0.0153     0.0762     0.1367\n8 2 4 Not well at all 0.0067 0.0037     0.0023     0.0197\n~ DISHONG | X\n  X           DISHONG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.1569 0.0152     0.1294     0.1890\n2 1      2 Quite well 0.3041 0.0195     0.2674     0.3436\n3 1    3 Not too well 0.3946 0.0213     0.3537     0.4371\n4 1 4 Not well at all 0.1443 0.0159     0.1159     0.1784\n5 2  1 Extremely well 0.0217 0.0054     0.0132     0.0353\n6 2      2 Quite well 0.0875 0.0111     0.0681     0.1119\n7 2    3 Not too well 0.3728 0.0189     0.3367     0.4105\n8 2 4 Not well at all 0.5179 0.0200     0.4787     0.5570\n\n\nNow consider them “ordinal” using an adjacent-category logit model, a.k.a. “nominal-by-linear” model in Goodman’s loglinear terminology.\n\nscale_01 <- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\nfactor_to_numeric_01 <- function(x) {\n  x_num <- seq_along(levels(x))[x]\n  scale_01(x_num)\n}\n\nX <- fit_cvam$modelMatrix\nX <- X %>% as_tibble() %>% \n  # Remove nominal interaction terms\n  select_if(!grepl(\"X.:.+\", names(.))) \n# Now include linear interaction terms by hand\nX$`X1:MORALG` <- X$X1 * factor_to_numeric_01(fit_cvam$mfTrue$MORALG)\nX$`X1:CARESG` <- X$X1 * factor_to_numeric_01(fit_cvam$mfTrue$CARESG)\nX$`X1:KNOWG` <- X$X1 * factor_to_numeric_01(fit_cvam$mfTrue$KNOWG)\nX$`X1:LEADG` <- X$X1 * factor_to_numeric_01(fit_cvam$mfTrue$LEADG)\nX$`X1:DISHONG` <- X$X1 * factor_to_numeric_01(fit_cvam$mfTrue$DISHONG)\n\nrmarkdown::paged_table(X)\n\n\n\n  \n\n\nX <- as.matrix(X)\n\nWe can now fit the model with ordinal indicators by passing our custom design matrix X to cvam.\n\nfit_cvam_ord <- cvam(formula, data = df_freq, \n                     freq = Freq, modelMatrix = X, \n                     control = list(startValJitter = 0.1))\n\nNote: Estimate at or near boundary\nEstimated variances may be unreliable\n\nsummary(fit_cvam_ord)\n\n~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\n\nPrior:\n      Flattening frequency = 0\nTotal nuggets + flattening = 0\n              Ridge factor = 0\n          Intensity factor = 1\n\nSample size:\n              total N in supplied data = 1495\nN from supplied data used in model fit = 1495\n           prior effective sample size =    0\n\nDegrees of freedom:\n    patterns of coarsened data = 1024\n  cells in complete-data table = 2048\ncells without latent variables = 1024\n         structural zero cells =    0\n   parameters in Poisson model =   22\n                            df = 1002\n\nStarting values:\ndefault, center\njitter SD = 0.100000\n\nEM algorithm:\nConverged at iteration 102\nGradient length = 0.000028\n\n  Final logP = 1163.216\nFinal loglik = 1163.216\n\nEstimates from EM, with Hessian-based SEs\n                coef      SE  zstat   pval\n(Intercept) -4.17560 0.14364 -29.07 0.0000\nX1          -4.70561 0.23787 -19.78 0.0000\nMORALG1      0.19249 0.07959   2.42 0.0156\nMORALG2      1.48030 0.08811  16.80 0.0000\nMORALG3      0.07357 0.06576   1.12 0.2632\nCARESG1     -0.80496 0.10068  -8.00 0.0000\nCARESG2      1.26607 0.09138  13.86 0.0000\nCARESG3      0.74189 0.07953   9.33 0.0000\nKNOWG1       0.60969 0.07515   8.11 0.0000\nKNOWG2       1.68829 0.07947  21.25 0.0000\nKNOWG3      -0.10932 0.07033  -1.55 0.1201\nLEADG1      -0.82379 0.09712  -8.48 0.0000\nLEADG2       1.22339 0.07733  15.82 0.0000\nLEADG3       0.86062 0.07474  11.51 0.0000\nDISHONG1    -1.22892 0.08710 -14.11 0.0000\nDISHONG2    -0.04606 0.05561  -0.83 0.4076\nDISHONG3     0.78925 0.05224  15.11 0.0000\nX1:MORALG    3.46023 0.25312  13.67 0.0000\nX1:CARESG    4.15955 0.29922  13.90 0.0000\nX1:KNOWG     2.70613 0.21085  12.83 0.0000\nX1:LEADG     3.85675 0.25308  15.24 0.0000\nX1:DISHONG  -1.75815 0.12500 -14.07 0.0000\n\ncvamEstimate(what, fit_cvam_ord)\n\nEstimates and SE's from EM, linearized\n~ X\n  X   prob     SE prob.lower prob.upper\n1 1 0.4492 0.0204     0.4097     0.4893\n2 2 0.5508 0.0204     0.5107     0.5903\n~ MORALG | X\n  X            MORALG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0385 0.0071     0.0267     0.0552\n2 1      2 Quite well 0.4421 0.0201     0.4032     0.4817\n3 1    3 Not too well 0.3432 0.0196     0.3059     0.3825\n4 1 4 Not well at all 0.1762 0.0158     0.1474     0.2092\n5 2  1 Extremely well 0.4471 0.0199     0.4086     0.4862\n6 2      2 Quite well 0.5114 0.0172     0.4777     0.5449\n7 2    3 Not too well 0.0395 0.0069     0.0279     0.0556\n8 2 4 Not well at all 0.0020 0.0007     0.0010     0.0040\n~ CARESG | X\n  X            CARESG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0066 0.0019     0.0037     0.0117\n2 1      2 Quite well 0.2103 0.0220     0.1704     0.2567\n3 1    3 Not too well 0.4981 0.0212     0.4566     0.5396\n4 1 4 Not well at all 0.2850 0.0197     0.2479     0.3252\n5 2  1 Extremely well 0.3043 0.0178     0.2705     0.3403\n6 2      2 Quite well 0.6033 0.0177     0.5681     0.6374\n7 2    3 Not too well 0.0893 0.0136     0.0659     0.1198\n8 2 4 Not well at all 0.0032 0.0011     0.0016     0.0064\n~ KNOWG | X\n  X             KNOWG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0825 0.0105     0.0641     0.1055\n2 1      2 Quite well 0.5980 0.0166     0.5650     0.6301\n3 1    3 Not too well 0.2442 0.0166     0.2132     0.2781\n4 1 4 Not well at all 0.0752 0.0103     0.0574     0.0981\n5 2  1 Extremely well 0.4391 0.0195     0.4014     0.4776\n6 2      2 Quite well 0.5239 0.0165     0.4915     0.5561\n7 2    3 Not too well 0.0352 0.0058     0.0255     0.0484\n8 2 4 Not well at all 0.0018 0.0006     0.0009     0.0034\n~ LEADG | X\n  X             LEADG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.0077 0.0020     0.0046     0.0129\n2 1      2 Quite well 0.2154 0.0210     0.1771     0.2593\n3 1    3 Not too well 0.5419 0.0209     0.5007     0.5825\n4 1 4 Not well at all 0.2351 0.0180     0.2017     0.2721\n5 2  1 Extremely well 0.2803 0.0171     0.2481     0.3150\n6 2      2 Quite well 0.6004 0.0174     0.5659     0.6338\n7 2    3 Not too well 0.1155 0.0140     0.0908     0.1459\n8 2 4 Not well at all 0.0038 0.0011     0.0022     0.0068\n~ DISHONG | X\n  X           DISHONG   prob     SE prob.lower prob.upper\n1 1  1 Extremely well 0.1638 0.0144     0.1375     0.1940\n2 1      2 Quite well 0.2976 0.0166     0.2660     0.3311\n3 1    3 Not too well 0.3818 0.0142     0.3543     0.4100\n4 1 4 Not well at all 0.1568 0.0138     0.1316     0.1859\n5 2  1 Extremely well 0.0158 0.0029     0.0110     0.0226\n6 2      2 Quite well 0.0925 0.0087     0.0768     0.1110\n7 2    3 Not too well 0.3833 0.0137     0.3568     0.4105\n8 2 4 Not well at all 0.5084 0.0180     0.4732     0.5436\n\n\nThe ordinal model is more parsimonious, using 10 fewer parameters.\n\nanova(fit_cvam_ord, fit_cvam)\n\nModel 1: ~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\nModel 2: ~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\n  resid.df -2*loglik df change\n1     1002   -2326.4          \n2      992   -2356.8 10 30.316\n\n\n\nanova(fit_cvam_ord, fit_cvam, method = \"BIC\")\n\nModel 1: ~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\nModel 2: ~ X * (MORALG + CARESG + KNOWG + LEADG + DISHONG)\n  resid.df -2*loglik     BIC rank\n1     1002   -2326.4 -2165.6    1\n2      992   -2356.8 -2122.8    2\n\n\n\n\n\n\noptions(contrasts = rep(\"contr.sum\", 2))\n\nvarnames <- LETTERS[1:5]\nsum_vars <- paste(varnames, collapse = \"+\")\n\nformula <- sprintf(\"Freq ~ X * (%s)\", sum_vars)\n# formula <- sprintf(\"Freq ~ X * (%s) + B:E + G:A + D:F + B:G + G:D\", sum_vars)\n\ndf_freq <- carcinoma[, varnames] |> table() |> as.data.frame()\nn <- nrow(df_freq)\ndf_freq$patnum <- 1:n\n\ndf_expanded <- rbind(df_freq, df_freq)\ndf_expanded$X <- rep(0:1, each = n)\npost_start <- runif(n)\ndf_expanded$post <- c(post_start, 1-post_start)\n\nsuppressWarnings( # LCAs often have boundary values within classes\n  for(i in 1:200) {\n    # M-step\n    # Loglinear model\n    fit_glm <- glm(formula, \n                   data = df_expanded, weights = post, \n                   family = \"poisson\")\n    \n    # E-step\n    eta.X <- predict(fit_glm) # Linear predictor given X\n    eta.X <- matrix(eta.X, nrow = n) |> t()\n    n.X <- sum(exp(eta.X)) # Sample size given X \n    P_YX <- exp(eta.X)/n.X # Probability of each pattern, joint (X, Y)\n    \n    P_Y <- colSums(P_YX)\n    P_X.Y <- t(P_YX) / P_Y # Posterior of X given Y\n    \n    df_expanded$post <- as.vector(P_X.Y)\n})\n\nsummary(fit_glm)\n\n\nCall:\nglm(formula = formula, family = \"poisson\", data = df_expanded, \n    weights = post)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-2.27223  -0.00021   0.00000   0.00006   2.32773  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -20.7518  3878.9737  -0.005   0.9957    \nX              9.5193  3997.5153   0.002   0.9981    \nA1             1.0887     0.2304   4.726 2.29e-06 ***\nB1             0.3282     0.1401   2.343   0.0191 *  \nC1            11.0176  2854.0327   0.004   0.9969    \nD1            10.9489  2626.9629   0.004   0.9967    \nE1             0.6686     0.1651   4.050 5.11e-05 ***\nX:A1         -11.0505   966.2770  -0.011   0.9909    \nX:B1          -2.3191     0.5229  -4.435 9.22e-06 ***\nX:C1         -11.5198  2854.0327  -0.004   0.9968    \nX:D1         -10.9899  2626.9629  -0.004   0.9967    \nX:E1          -2.5160     0.4704  -5.349 8.83e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 346.375  on 63  degrees of freedom\nResidual deviance:  31.418  on 52  degrees of freedom\nAIC: 98.345\n\nNumber of Fisher Scoring iterations: 17\n\nP_X <- rowSums(P_YX) # Prior\nP_Y.X <- P_YX/P_X    # Conditional of Y given X\n\nP_Y.X_marginal <- sapply(varnames, function(v) {\n  apply(P_Y.X, 1, function(x) tapply(x, df_freq[, v], sum))\n})\n\nP_Y.X_marginal |> round(3)\n\n         A     B     C    D     E\n[1,] 0.898 0.658 1.000 1.00 0.792\n[2,] 0.102 0.342 0.000 0.00 0.208\n[3,] 0.000 0.018 0.268 0.48 0.024\n[4,] 1.000 0.982 0.732 0.52 0.976\n\n# fit_polca$probs |> lapply(round, 3)\n\nN <- sum(df_freq$Freq)\n\nexpected <- P_Y * N\nobserved <- df_freq$Freq\n\nloglik <- sum(observed * log(P_Y))\ndeviance <- -2*loglik\np <- length(coef(fit_glm))\nbic_deviance <- deviance + p*log(N)\nbic_deviance\n\n[1] 556.776\n\nX2 <- sum((observed - expected)^2/expected)\nG2 <- 2*sum(observed * log(observed/expected), na.rm = TRUE)\n\ndata.frame(Chisq=c(X2, fit_polca$Chisq), Gsqp=c(G2, fit_polca$Gsq), method=c(\"loglinear\", \"poLCA\"))\n\n     Chisq     Gsqp    method\n1 27.48417 27.98881 loglinear\n2 92.64814 62.36543     poLCA\n\n\n\nThis does appear to work as well. It requires more hand-holding than cvam.\n\nlibrary(gllm)\n\noptions(contrasts = rep(\"contr.treatment\", 2))\n\nK <- 3\n\ndf_expanded <- Reduce(rbind, replicate(K, df_freq, simplify = FALSE))\ndf_expanded$X <- factor(rep(seq(K), each = n))\n\nformula_gllm <- ~ X * (A + B + C + D + E)\nX <- model.matrix(formula_gllm, data = df_expanded)\ns <- replicate(K, 1:nrow(df_freq))\n\nres <- emgllm(y = df_freq$Freq, s = s, X = X)\nres\n\n$deviance\n[1] 28.16023\n\n$observed.values\n [1] 34  2  7  3  0  0  0  0  0  0  0  1  0  0  0  0  2  0  9 10  0  1  0 18  0\n[26]  0  0  5  0  0  0 26\n\n$fitted.values\n [1] 2.755131e+01 2.760242e+00 1.386034e+01 1.558156e+00 1.409730e-02\n [6] 9.989355e-03 8.454280e-03 4.817056e-01 1.084389e-02 4.451493e-03\n[11] 5.989757e-03 1.892922e-01 3.258625e-05 9.464652e-03 1.519161e-03\n[16] 5.304967e-01 6.896560e+00 8.201101e-01 3.489994e+00 7.632804e+00\n[21] 4.566682e-03 3.656668e-01 6.030415e-02 2.047734e+01 3.121613e-03\n[26] 1.436234e-01 2.433266e-02 8.035526e+00 1.153064e-03 4.029088e-01\n[31] 6.455638e-02 2.258447e+01\n\n$full.table\n [1] 2.755131e+01 2.757187e+00 1.385986e+01 1.387020e+00 1.407245e-02\n [6] 1.408294e-03 7.079230e-03 7.084511e-04 1.083403e-02 1.084211e-03\n[11] 5.450125e-03 5.454192e-04 5.533722e-06 5.537851e-07 2.783773e-06\n[16] 2.785850e-07 6.896190e+00 6.901336e-01 3.469171e+00 3.471759e-01\n[21] 3.522383e-03 3.525011e-04 1.771956e-03 1.773278e-04 2.711796e-03\n[26] 2.713819e-04 1.364186e-03 1.365203e-04 1.385110e-06 1.386144e-07\n[31] 6.967882e-07 6.973081e-08 4.363061e-06 1.526518e-03 2.445662e-04\n[36] 8.556714e-02 1.226294e-05 4.290473e-03 6.873842e-04 2.404973e-01\n[41] 4.812064e-06 1.683612e-03 2.697345e-04 9.437287e-02 1.352492e-05\n[46] 4.732006e-03 7.581231e-04 2.652469e-01 1.857467e-04 6.498778e-02\n[51] 1.041181e-02 3.642812e+00 5.220646e-04 1.826564e-01 2.926371e-02\n[56] 1.023859e+01 2.048619e-04 7.167568e-02 1.148329e-02 4.017695e+00\n[61] 5.757904e-04 2.014536e-01 3.227524e-02 1.129224e+01 4.363061e-06\n[66] 1.526518e-03 2.445662e-04 8.556714e-02 1.226294e-05 4.290473e-03\n[71] 6.873842e-04 2.404973e-01 4.812064e-06 1.683612e-03 2.697345e-04\n[76] 9.437287e-02 1.352492e-05 4.732006e-03 7.581231e-04 2.652469e-01\n[81] 1.857467e-04 6.498778e-02 1.041181e-02 3.642812e+00 5.220646e-04\n[86] 1.826564e-01 2.926371e-02 1.023859e+01 2.048619e-04 7.167568e-02\n[91] 1.148329e-02 4.017695e+00 5.757904e-04 2.014536e-01 3.227524e-02\n[96] 1.129224e+01\n\nwith(res, sum((fitted.values - observed.values)^2/fitted.values))\n\n[1] 28.49572\n\nwith(res, 2*sum(observed.values * log(observed.values/fitted.values), na.rm = TRUE))\n\n[1] 28.16023"
  },
  {
    "objectID": "project-reproduce-LCA.html",
    "href": "project-reproduce-LCA.html",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "",
    "text": "In this project, you will work on reading and reproducing the following paper:\n  Beller, J. (2021). Morbidity profiles in Europe and Israel: International comparisons\n          from 20 countries using biopsychosocial indicators of health via latent class analysis.\n          Journal of Public Health. https://doi.org/10.1007/s10389-021-01673-0\nYou can download a copy of the paper here: https://daob.nl/files/lca/beller-2021.pdf\nThe data used in this study were from the European Social Survey, round 7 (2014). You can find these (and more recent) data here: https://www.europeansocialsurvey.org/data/. You will need to register to download the data. Registration is free and should be instantaneous."
  },
  {
    "objectID": "project-reproduce-LCA.html#assignment",
    "href": "project-reproduce-LCA.html#assignment",
    "title": "PROJECT - Reproducing a published LCA",
    "section": "Assignment",
    "text": "Assignment\n\nObtain the data\nCreate the dataset as indicated in the article. You should end up with 16 indicators, (excluding any covariates such as country, age, gender, or education)\n\nWhich steps taken in the paper could you criticize? Do you think they will have a large impact on the final conclusions?\nCreate two different versions of the data, one of which is as close as possible to the paper, the other differing only on the aspect of data wrangling that you believe will be the most influential.\nCreate a smaller dataset, selecting only one country of your choice. You will use this smaller dataset to initially debug the subsequent analyses. From the list of covariates in table 4, select a maximum of two or three that you find of interest.\nFor each recode, double-check your recode by creating a before/after cross-table, or by calculating means within categories for dichotomized variables. Did everything go according to your plan?\nPerform a sanity check on your data. Pay attention to Roger Peng’s EDA advice:\n\nRead in your data : Are the names of the variables correct, concise, and unambiguous?\nCheck the packaging : Are the number of rows and columns as expected? Are the types of your variables as expected? Do your variables contain weird values (such as -99)? Are some variables all-missing or constant?\nLook at the top and the bottom of your data : use head() and tail() or some other method to check the top and bottom.\nCheck your “n”s : do the sample sizes correspond to the documentation? To the paper?\n\nValidate with at least one external data source : check descriptives of your data against those in the paper (small differences may occur). Are distributions of study variables (e.g. depression) and background variables (e.g. age, gender, education) plausible? (you may want to look at official statistics for your chosen country)\nMake a plot, look at descriptives : you are free to make sensible choices of “checks” here. Examples could include checking that correlations between closely related variables are not negative, scatterplots of continuous variables or dotplots/boxplots of continuous/categorical variabels to check for outliers, etc.\n\n\nUse poLCA to estimate the LCA with 1, 2, 3, 4, 5, and 6 classes on your small dataset. (hint: it is always a good idea to start off with a small number of indicators to check that things are going OK, before increasing the model size)\n\nCheck: Did you specify everything correctly?\n\nDo a sanity check on the results. Pay attention to:\n\nReported sample sizes\nUnexpected direction of associations\nForgotten indicators, or inadvertently included covariates as indicators\n\nRerun your analysis with multiple random starts, and compare the best log-likelihood, ensuring your solution did not end up in a local maximum\nModel evaluation:\n\nCompare loglikelihood, BIC and AIC among the 6 models. Use a scree plot to select the number of classes.\nLook at bivariate residuals (BVRs). Are there any local dependencies? Is it better to increase the number of classes, or fit a model with fewer classes but local dependence?\n(BONUS) Perform a parametric bootstrap-likelihood ration test of your selected model. (hint: package flexmix allows parametric bootstrapping of the LRT via the function LR_test.)\n\nModel interpretation:\n\nLook at probability profiles. Without looking at the Beller (2021) paper, create a description for yourself of the profiles you have created.\nCreate a table of the estimated class sizes. Are any classes too small to be of interest?\nCreate a classification table and calculate the entropy \\(R^2\\). Which classes are well-separated?\nLook at the results for the prediction of class membership from covariates. Are the effects in the expected direction? What are the confidence intervals of the parameter estimates? (BONUS:) Create a plot of each covariate versus the probability to belong to each class.\n\n\nRepeat the analysis and interpretation steps with a larger model, using all countries.\nCompare the results from your two datasets from part 2(c) above.\nHow does your analysis compare to the results in Beller (2021)? Go through each of the steps in the previous question and report any similarities/differences.\nWhat do you conclude about profiles of health status in the ESS?\nBONUS: Bootstrap (empirically) the standard errors of the model and compare with the standard se’s given in poCLA (hint: packages flexmix and BayesLCA allow bootstrapping. To get bootstrap se’s using blca, use argument method = “em”, and blca.boot\nBONUS: Do the analysis with a newer ESS dataset and compare the results."
  },
  {
    "objectID": "EM-categorical.html",
    "href": "EM-categorical.html",
    "title": "EM: categorical indicators",
    "section": "",
    "text": "Below you will find code to simulate data from a mixture of conditionally independent binary indicators, and to estimate that mixture (LCA model) using the EM algorithm. The code is intended to be easy to understand and as simple as possible, while still doing the job. You can copy code into your R environment by clicking the copy icon in the top right of each code block."
  },
  {
    "objectID": "EM-categorical.html#exercises",
    "href": "EM-categorical.html#exercises",
    "title": "EM: categorical indicators",
    "section": "Exercises",
    "text": "Exercises\n\nRead the simulation code. Do you have any questions?\nRead the EM loop. Do you understand all steps?\nCode understanding check:\n\nIn the simulation code, explain why the subscripts 1 and 2 are used respectively in P_Y.X_true[[1]][2, X].\nWhich values would you change if you wanted to implement random starts?\nSuppose the model said that the variables do not come from a binomial (Bernoulli) distribution, but from some other distribution (for example a Beta one). Which lines would you need to change?\n\n\nTry reversing the starting values, so, Y1 = c(0.4, 0.6) becomes Y1 = c(0.6, 0.4), and similarly for the other two variables. What happens to the estimates? How do these compare to the true values now?\nSet the number of iterations of the EM algorithm to a large number, such as maxiter = 200. What happens to the estimates?\nTry out different values of the prior, the profile probabilities, and the sample size. Report any interesting observations.\nFit the same model using poLCA (or otherwise). (Remember that you can directly analyze df_samp.) Do the results agree with our own EM implementation?\n\nBONUS: Calculate the log-likelihood of the model.\n\nBONUS: Investigate the entropy \\(R^2\\) of the posterior classification as a function of (a) the profile probabilities and (b) prior.\n\nSimulate data\n\nset.seed(202303)\n\nn <- 1000L # Sample size\n\nP_X_true <- 0.4 # True pi (will be class size of X=2)\n\n# Sample class memberships:\nX <- sample(1:2, size = n, replace = TRUE, \n            prob = c(1 - P_X_true, P_X_true))\n\n# True profiles:\nP_Y.X_true <- list(\n  Y1 = matrix(c(0.9, 0.2,\n                0.1, 0.8), byrow = TRUE, nrow = 2),\n  Y2 = matrix(c(0.7, 0.2,\n                0.3, 0.8), byrow = TRUE, nrow = 2),\n  Y3 = matrix(c(0.95, 0.4,\n                0.05, 0.6), byrow = TRUE, nrow = 2)\n)\n\nThe conditional (profile) probabilities \\(P(Y_j | X)\\) are:\n\nprint(P_Y.X_true)\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nWe now sample some data using the conditional probabilities and the values of X.\n\n# Sample observed indicators from binomials (Bernoullis):\nY1 <- rbinom(n, size = 1, prob = P_Y.X_true[[1]][2, X])\nY2 <- rbinom(n, size = 1, prob = P_Y.X_true[[2]][2, X])\nY3 <- rbinom(n, size = 1, prob = P_Y.X_true[[3]][2, X])\n\ndf_samp <- data.frame(Y1, Y2, Y3) # For other analyses\n\nFitting the model with our very EM algorithm\nWe will take as parameters the probabilities of a “1” response on each of the three indicators, given \\(X=1\\) or \\(X=2\\), respectively. And of course the class size \\(\\pi = P(X = 2)\\). So there are 7 parameters in total. Since there are \\(2^3 = 8\\) observeed patterns, but only 7 independent ones, the degrees of freedom for this model equals zero.\n\n# As usual, we start by guessing parameter values\nguess_PY.X <- list(\n  Y1 = c(0.4, 0.6),\n  Y2 = c(0.4, 0.6),\n  Y3 = c(0.4, 0.6)\n)\n# We will take PX (pi) to be P(X = 2)\nguess_PX <- 0.5\n\n# Number of EM iterations\nmaxiter <- 15\n\n# Start the EM algorithm!\nfor(it in 1:maxiter) {\n  # Just some output \n  if(it == 1) # A trick to make Quarto output this line correctly\n    cat(\"It:\\t(X=2)\\tY1|X=1\\tY1|X=2\\tY2|X=1\\tY2|X=2\\tY3|X=1\\tY3|X=2\\n\")\n  cat(sprintf(\"%03d\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\t%1.3f\\n\", it,\n      guess_PX, \n      guess_PY.X$Y1[1], guess_PY.X$Y1[2],\n      guess_PY.X$Y2[1], guess_PY.X$Y2[2],\n      guess_PY.X$Y3[1], guess_PY.X$Y3[2]))\n\n  # E-step\n  # ------------------\n  # For clarity purposes I am not using a loop over the three variables. \n  #  In practice, you will probably want to do that. \n\n  # The probability of observing that value if X were X=1 or X=2\n  \n  # Here we use the assumption that each value is ~ Bernoulli\n  #. In practice you would work with logs, but here we ignore that\n  P_Y1.X1 <- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[1])\n  P_Y1.X2 <- dbinom(Y1, size = 1, prob = guess_PY.X$Y1[2])\n  \n  P_Y2.X1 <- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[1])\n  P_Y2.X2 <- dbinom(Y2, size = 1, prob = guess_PY.X$Y2[2])\n  \n  P_Y3.X1 <- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[1])\n  P_Y3.X2 <- dbinom(Y3, size = 1, prob = guess_PY.X$Y3[2])\n  \n  # Now we use the conditional independence assumption \n  #.  to get the probability of the whole pattern (df_samp[i, ])\n  # (In practice you will want to takes a sum of logs instead)\n  P_Y_X1 <-  P_Y1.X1 * P_Y2.X1 * P_Y3.X1\n  P_Y_X2 <-  P_Y1.X2 * P_Y2.X2 * P_Y3.X2\n  \n  # Now we use the mixture assumption to get the marginal probability of the pattern:\n  P_Y <- (1 - guess_PX)*P_Y_X1 + guess_PX*P_Y_X2\n  \n  # Finally we are ready to apply Bayes rule to get the posterior \n  #. P(X = 2 | Y = y)\n  post_X2 <- guess_PX*P_Y_X2 / P_Y\n  \n  # M-step \n  # ------------------\n  # Now we have the posterior it is easy to calculate the probabilities we need\n  \n  # M-step for 'priors' / class size of X=2\n  guess_PX <- mean(post_X2)\n  \n  # M-step for profiles\n  guess_PY.X$Y1[1] <- weighted.mean(Y1, w = (1 - post_X2))\n  guess_PY.X$Y1[2] <- weighted.mean(Y1, w = post_X2)\n  \n  guess_PY.X$Y2[1] <- weighted.mean(Y2, w = (1 - post_X2))\n  guess_PY.X$Y2[2] <- weighted.mean(Y2, w = post_X2)\n  \n  guess_PY.X$Y3[1] <- weighted.mean(Y3, w = (1 - post_X2))\n  guess_PY.X$Y3[2] <- weighted.mean(Y3, w = post_X2)\n}\n\nIt: (X=2)   Y1|X=1  Y1|X=2  Y2|X=1  Y2|X=2  Y3|X=1  Y3|X=2\n001 0.500   0.400   0.600   0.400   0.600   0.400   0.600\n002 0.426   0.228   0.538   0.341   0.647   0.145   0.420\n003 0.423   0.167   0.623   0.289   0.720   0.092   0.495\n004 0.415   0.125   0.692   0.256   0.775   0.057   0.552\n005 0.406   0.106   0.732   0.247   0.798   0.042   0.584\n006 0.399   0.099   0.753   0.250   0.804   0.037   0.601\n007 0.393   0.098   0.765   0.255   0.804   0.036   0.611\n008 0.389   0.098   0.773   0.259   0.804   0.035   0.618\n009 0.385   0.099   0.778   0.262   0.805   0.036   0.624\n010 0.381   0.100   0.782   0.264   0.806   0.037   0.628\n011 0.378   0.101   0.785   0.266   0.808   0.037   0.631\n012 0.376   0.102   0.788   0.267   0.810   0.038   0.633\n013 0.374   0.103   0.790   0.268   0.811   0.039   0.636\n014 0.371   0.105   0.792   0.269   0.813   0.040   0.638\n015 0.370   0.106   0.794   0.270   0.814   0.041   0.640\n\n\nResults\nHere are the resulting estimates of the conditional probabilities (profiles).\n\nguess_PY.X |> \n  lapply(function(x) rbind(1-x, x)) |>\n  print(digits = 3)\n\n$Y1\n   [,1]  [,2]\n  0.894 0.204\nx 0.106 0.796\n\n$Y2\n  [,1]  [,2]\n  0.73 0.184\nx 0.27 0.816\n\n$Y3\n    [,1]  [,2]\n  0.9588 0.359\nx 0.0412 0.641\n\n\nCompare these to the true profiles, which were:\n\nP_Y.X_true\n\n$Y1\n     [,1] [,2]\n[1,]  0.9  0.2\n[2,]  0.1  0.8\n\n$Y2\n     [,1] [,2]\n[1,]  0.7  0.2\n[2,]  0.3  0.8\n\n$Y3\n     [,1] [,2]\n[1,] 0.95  0.4\n[2,] 0.05  0.6\n\n\nThe estimated class sizes are\n\nc(1 - guess_PX, guess_PX) |> \n  print(digits = 3)\n\n[1] 0.632 0.368\n\n\nCompare these to the “priors” (class sizes), which were:\n\nc(1 - P_X_true, P_X_true) |> \n  print(digits = 3)\n\n[1] 0.6 0.4"
  },
  {
    "objectID": "antireli.html",
    "href": "antireli.html",
    "title": "Anti-religious speech",
    "section": "",
    "text": "library(tidyverse)\nlibrary(broom)\nlibrary(poLCA)\n\nRead the data from the General Social Survey 1987. It’s not old, it’s a classic!\n\nantireli <- read.csv(\"https://daob.nl/files/lca/antireli_data.csv\")\n\nhead(antireli)\n\n  Y1 Y2 Y3\n1  1  1  1\n2  1  1  1\n3  1  1  1\n4  1  1  1\n5  1  1  1\n6  1  1  1\n\n\nShow the data as pattern frequencies.\n\ntable(antireli) |> knitr::kable()\n\n\n\nY1\nY2\nY3\nFreq\n\n\n\n1\n1\n1\n696\n\n\n2\n1\n1\n34\n\n\n1\n2\n1\n275\n\n\n2\n2\n1\n125\n\n\n1\n1\n2\n68\n\n\n2\n1\n2\n19\n\n\n1\n2\n2\n130\n\n\n2\n2\n2\n366\n\n\n\n\n\nFit the model using poLCA.\n\nfit <- poLCA(cbind(Y1, Y2, Y3) ~ 1, data = antireli, nclass = 2)\n\nConditional item response (column) probabilities,\n by outcome variable, for each class (row) \n \n$Y1\n           Pr(1)  Pr(2)\nclass 1:  0.2284 0.7716\nclass 2:  0.9601 0.0399\n\n$Y2\n           Pr(1)  Pr(2)\nclass 1:  0.0429 0.9571\nclass 2:  0.7424 0.2576\n\n$Y3\n           Pr(1)  Pr(2)\nclass 1:  0.2395 0.7605\nclass 2:  0.9166 0.0834\n\nEstimated class population shares \n 0.3795 0.6205 \n \nPredicted class memberships (by modal posterior prob.) \n 0.3736 0.6264 \n \n========================================================= \nFit for 2 latent classes: \n========================================================= \nnumber of observations: 1713 \nnumber of estimated parameters: 7 \nresidual degrees of freedom: 0 \nmaximum log-likelihood: -2795.376 \n \nAIC(2): 5604.751\nBIC(2): 5642.873\nG^2(2): 4.683779e-10 (Likelihood ratio/deviance statistic) \nX^2(2): 4.375393e-10 (Chi-square goodness of fit) \n \n\n\nHere is the default plot given by polCA.\n\nplot(fit)\n\n\n\n\nIn this case the default plot is still somewhat readable, but in practice it is not the best as data visualizations go. A simple line plot does a better job (in my personal & completely subjective opinion!) and allows you to display confidence intervals to boot. We use tidy from the broom package to extract the results and ggplot to plot.\n\ntidy(fit) %>% \n  filter(outcome == 2) %>% \n  mutate(class = as.factor(class)) %>%\n  ggplot(aes(variable, estimate, group = class, color = class)) +\n  geom_point() + geom_line() + \n  geom_errorbar(aes(ymin = estimate - 2*std.error, \n                    ymax = estimate + 2*std.error), width = 0.2) +\n  theme_bw() +  scale_color_brewer(palette = \"Set2\")\n\n\n\n\nYou can play around with the implied probabilities in the Excel file https://daob.nl/files/lca/antirel2.xlsx (thanks to Jeroen Vermunt)."
  },
  {
    "objectID": "clustering-distance.html",
    "href": "clustering-distance.html",
    "title": "Hierarchical and k-means clustering",
    "section": "",
    "text": "Introduction\nWe use the following packages:\n\nlibrary(MASS) # make sure to load mass before tidyverse to avoid conflicts!\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(ggdendro)\n\nIn this practical, we will apply hierarchical and k-means clustering to two synthetic datasets. The data can be generated by running the code below.\n\nTry to understand what is happening as you run each line of the code below.\n\n\n# randomly generate bivariate normal data\nset.seed(123)\nsigma      <- matrix(c(1, .5, .5, 1), 2, 2)\nsim_matrix <- mvrnorm(n = 100, mu = c(5, 5), Sigma = sigma)\ncolnames(sim_matrix) <- c(\"x1\", \"x2\")\n\n# change to a data frame (tibble) and add a cluster label column\nsim_df <- \n  sim_matrix %>% \n  as_tibble() %>%\n  mutate(class = sample(c(\"A\", \"B\", \"C\"), size = 100, replace = TRUE))\n\n# Move the clusters to generate separation\nsim_df_small <- \n  sim_df %>%\n  mutate(x2 = case_when(class == \"A\" ~ x2 + .5,\n                        class == \"B\" ~ x2 - .5,\n                        class == \"C\" ~ x2 + .5),\n         x1 = case_when(class == \"A\" ~ x1 - .5,\n                        class == \"B\" ~ x1 - 0,\n                        class == \"C\" ~ x1 + .5))\nsim_df_large <- \n  sim_df %>%\n  mutate(x2 = case_when(class == \"A\" ~ x2 + 2.5,\n                        class == \"B\" ~ x2 - 2.5,\n                        class == \"C\" ~ x2 + 2.5),\n         x1 = case_when(class == \"A\" ~ x1 - 2.5,\n                        class == \"B\" ~ x1 - 0,\n                        class == \"C\" ~ x1 + 2.5))\n\n\nPrepare two unsupervised datasets by removing the class feature.\n\n\ndf_s <- sim_df_small %>% select(-class)\ndf_l <- sim_df_large %>% select(-class)\n\n\nFor each of these datasets, create a scatterplot. Combine the two plots into a single frame (look up the “patchwork” package to see how to do this!) What is the difference between the two datasets?\n\n\n# patchwork defines the \"+\" operator to combine entire ggplots!\ndf_s %>% ggplot(aes(x = x1, y = x2)) + geom_point() + ggtitle(\"Small\") +\ndf_l %>% ggplot(aes(x = x1, y = x2)) + geom_point() + ggtitle(\"Large\")\n\n\n\n# df_s has a lot of class overlap, df_l has very little overlap\n\n\n\nHierarchical clustering\n\nRun a hierarchical clustering on these datasets and display the result as dendrograms. Use euclidian distances and the complete agglomeration method. Make sure the two plots have the same y-scale. What is the difference between the dendrograms? (Hint: functions you’ll need are hclust, ggdendrogram, and ylim)\n\n\ndist_s <- dist(df_s, method = \"euclidian\")\ndist_l <- dist(df_l, method = \"euclidian\")\n\nres_s <- hclust(dist_s, method = \"complete\")\nres_l <- hclust(dist_l, method = \"complete\")\n\nggdendrogram(res_s, labels = FALSE) + ggtitle(\"Small\") + ylim(0, 10) +\nggdendrogram(res_l, labels = FALSE) + ggtitle(\"Large\") + ylim(0, 10)\n\n\n\n# the dataset with large differences segments into 3 classes much higher up.\n# Interestingly, the microstructure (lower splits) is almost exactly the same\n# because within the three clusters there is no difference between the datasets\n\n\nFor the dataset with small differences, also run a complete agglomeration hierarchical cluster with manhattan distance.\n\n\ndist_s2 <- dist(df_s, method = \"manhattan\")\nres_s2  <- hclust(dist_s2, method = \"complete\")\n\n\nUse the cutree() function to obtain the cluster assignments for three clusters and compare the cluster assignments to the 3-cluster euclidian solution. Do this comparison by creating two scatter plots with cluster assignment mapped to the colour aesthetic. Which difference do you see?\n\n\nclus_1 <- as_factor(cutree(res_s, 3))\nclus_2 <- as_factor(cutree(res_s2, 3))\n\np1 <- df_s %>% \n  ggplot(aes(x = x1, y = x2, colour = clus_1)) + \n  geom_point() + \n  ggtitle(\"Euclidian\") + \n  theme(legend.position = \"n\") +\n  coord_fixed()\n\np2 <- df_s %>% \n  ggplot(aes(x = x1, y = x2, colour = clus_2)) + \n  geom_point() + \n  ggtitle(\"Manhattan\") + \n  theme(legend.position = \"n\") +\n  coord_fixed()\n\np1 + p2\n\n\n\n# The manhattan distance clustering prefers more rectangular classes, whereas\n# the euclidian distance clustering prefers circular classes. The difference is\n# most prominent in the very center of the plot and for the top right cluster\n\n\n\nK-means clustering\n\nCreate k-means clusterings with 2, 3, 4, and 6 classes on the large difference data. Again, create coloured scatter plots for these clusterings.\n\n\n# I set the seed for reproducibility\nset.seed(45)\n# we can do it in a single pipeline and with faceting \n# (of course there are many ways to do this, though)\ndf_l %>% \n  mutate(\n    class_2 = as_factor(kmeans(df_l, 2)$cluster),\n    class_3 = as_factor(kmeans(df_l, 3)$cluster),\n    class_4 = as_factor(kmeans(df_l, 4)$cluster),\n    class_6 = as_factor(kmeans(df_l, 6)$cluster)\n  ) %>% \n  pivot_longer(cols = c(class_2, class_3, class_4, class_6), \n               names_to = \"class_num\", values_to = \"cluster\") %>% \n  ggplot(aes(x = x1, y = x2, colour = cluster)) +\n  geom_point() +\n  scale_colour_brewer(type = \"qual\") + # use easy to distinguish scale\n  facet_wrap(~class_num)\n\n\n\n\n\nDo the same thing again a few times. Do you see the same results every time? where do you see differences?\n\n\n# I set the seed for reproducibility\nset.seed(46)\ndf_l %>% \n  mutate(\n    class_2 = as_factor(kmeans(df_l, 2)$cluster),\n    class_3 = as_factor(kmeans(df_l, 3)$cluster),\n    class_4 = as_factor(kmeans(df_l, 4)$cluster),\n    class_6 = as_factor(kmeans(df_l, 6)$cluster)\n  ) %>% \n  pivot_longer(cols = c(class_2, class_3, class_4, class_6), \n               names_to = \"class_num\", values_to = \"cluster\") %>% \n  ggplot(aes(x = x1, y = x2, colour = cluster)) +\n  geom_point() +\n  scale_colour_brewer(type = \"qual\") + # use easy to distinguish scale\n  facet_wrap(~class_num)\n\n\n\n# there is label switching in all plots. There is a different result altogether\n# in the class_4 solution in my case.\n\n\nFind a way online to perform bootstrap stability assessment for the 3 and 6-cluster solutions.\n\n\n# I decided to use the function clusterboot from the fpc package\n# NB: this package needs to be installed first!\n# install.packages(\"fpc\")\nlibrary(fpc)\n\n# you can read the documentation ?clusterboot to figure out how to use this \n# function. This can take a while but is something you will need to do a lot in\n# the real world!\nboot_3 <- clusterboot(df_l, B = 1000, clustermethod = kmeansCBI, k = 3, \n                      count = FALSE)\nboot_6 <- clusterboot(df_l, B = 1000, clustermethod = kmeansCBI, k = 6, \n                      count = FALSE)\n\n# the average stability is much lower for 6 means than for 3 means:\nboot_3$bootmean\n\n[1] 0.9844165 0.9730219 0.9739694\n\nboot_6$bootmean\n\n[1] 0.7844248 0.5383414 0.7593547 0.7230086 0.6897734 0.7091287"
  },
  {
    "objectID": "antireli-assignment.html",
    "href": "antireli-assignment.html",
    "title": "Anti-religious speech",
    "section": "",
    "text": "Exercises\n\nUsing poLCA, fit a two-class LCA to these data.\nCreate a profile plot.\nHow would you label the classes?\nWhat can you say about the estimated class sizes? What does this mean for the prevalence of the attitudes you labeled under (2)?\nModel fit\n\nHow many parameters are there?\nHow many unique data patterns are there (fixing the sample size \\(n=1713\\))?\nCan you explain the number of degrees of freedom?\nCan you explain the value of the G^2 (\\(G^2\\)) and X^2 (\\(\\chi^2\\)) statistics?\n\n\nData\n\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(poLCA)\n\nRead the data from the General Social Survey 1987. It’s not old, it’s a classic!\n\nantireli <- read.csv(\"https://daob.nl/files/lca/antireli_data.csv\")\n\nhead(antireli)\n\n  Y1 Y2 Y3\n1  1  1  1\n2  1  1  1\n3  1  1  1\n4  1  1  1\n5  1  1  1\n6  1  1  1\n\n\nShow the data as pattern frequencies.\n\ntable(antireli) |> knitr::kable()\n\n\n\nY1\nY2\nY3\nFreq\n\n\n\n1\n1\n1\n696\n\n\n2\n1\n1\n34\n\n\n1\n2\n1\n275\n\n\n2\n2\n1\n125\n\n\n1\n1\n2\n68\n\n\n2\n1\n2\n19\n\n\n1\n2\n2\n130\n\n\n2\n2\n2\n366"
  },
  {
    "objectID": "ESS-assignment.html",
    "href": "ESS-assignment.html",
    "title": "Attitudes towards climate change in Europe",
    "section": "",
    "text": "Read in the ESS round 10 (2020) climate change attitudes data (see below under “Data”).\nIn order not to spend most of your precious time waiting, filter the data to only include one country of your choice.\nPerform any exploratory data analyses you find necessary.\nUsing poLCA, fit LCA models in which the seven participation items are used as indicators (so, exclude agea, gndr, and eisced from the analysis for now). Try models with a different number of classes. Advice: try 1–6.\nUse appropriate global fit measures, or any other criteria you prefer, to select the number of classes. Explain your choice.\nLook at local fit measures to assess the fit of your selected model.\nCreate a profile plot for your selected model. (Hint: You can use the adjusted plotting code below.)\nInterpret your selected model by looking at the profiles. How would you label the classes?\nCreate a classification table.\nCalculate the classification error and entropy \\(R^2\\).\nRefit your selected model, now while predicting class membership from agea, the square of agea, gndr, and eisced.\nUse the effects library to plot the probability of each class as a function of agea, gndr, and eisced, according to your model. What do you conclude? (Hint: if effects does not work, see the code below.)\n\nBONUS: Investigate the distribution of classes over countries by redoing the analyses using all countries in the ess dataset\n\nBONUS: Deal more appropriately with missing data, for example by using mice. You will need the original data from ESS.\n\n\nset.seed(202303)\n\nlibrary(tidyverse)\nlibrary(broom) \nlibrary(haven)\nlibrary(poLCA)\n\n\nRead the data from the European Social Survey, round 10 (2020).\nAn easy to read codebook copied from ESS is here: https://daob.nl/files/lca/ESS10-codebook.html. The full documentation is here: https://ess-search.nsd.no/en/study/172ac431-2a06-41df-9dab-c1fd8f3877e7.\n\n\nccnthum - Climate change caused by natural processes, human activity, or both\n\nccrdprs - To what extent feel personal responsibility to reduce climate change\n\nwrclmch - How worried about climate change\n\ntestic37 - Imagine large numbers of people limit energy use, how likely reduce climate change\n\ntestic38 - How likely, large numbers of people limit energy use\n\ntestic39 - How likely, governments in enough countries take action to reduce climate change\n\ngndr - Gender\n\nagea - Age of respondent, calculated\n\neisced - Highest level of education, ES - ISCED\n\n\nNote: The data have been preprocessed by ruthlessly subjecting them to na.omit. I have also recoded eisced to be missing except for values 1-7. Otherwise, the data are as-is from the ESS website.\n\ness10_climate <- read_csv(\"https://daob.nl/files/lca/ess10_climate.csv.gz\") \n\ness10_climate |> rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\nBecause the assignment differs from the example in that this is polytomous data, and the number of categories differ, here is some (hopefully) helpful code to create profile plots.\n```{r}\ntidy(fit) %>% # from `broom` package\n    mutate(class = as.factor(class), outcome = as.factor(outcome)) %>%\n    ggplot(aes(outcome, estimate, group = class, color = class)) +\n    geom_point() + geom_line() + facet_wrap(~variable, scales = \"free_x\")+\n    geom_errorbar(aes(ymin = estimate - 2*std.error, \n                      ymax = estimate + 2*std.error), width = 0.2) +\n    theme_bw() + scale_color_brewer(palette = \"Set2\")\n```\n\nUnfortunately, effects does not appear to function properly for this type of model. The code below could be helpful to create effects plots by hand. It assumes that the right-hand side of formula used was agea + I(agea^2) + gndr + eisced.\n\n\n\nThe code below creates a dataframe with the “effects” of the various covariates based on the model estimates from fit. This is also how effects works and demonstrated within the poLCA help file.\n\nage_levels <- with(ess10_climate_it, {\n  seq(min(agea), max(agea), length = 20)\n})\ngndr_levels <- 1:2\neisced_levels <- 1:7\n\npidmat <- expand.grid(age_levels, gndr_levels, eisced_levels)\npidmat <- cbind(1, pidmat[,1], pidmat[,1]^2, pidmat[,2], pidmat[,3])\ncolnames(pidmat) <- rownames(coef(fit))\nexb <- exp(pidmat %*% fit$coeff)\n\nclass_probs <- cbind(1, exb) / (1 + rowSums(exb))\ncolnames(class_probs) <- paste0(\"X\", 1:ncol(class_probs))\n\ndf_effects <- cbind(pidmat[, -c(1,3)], class_probs) %>% \n  as_tibble %>%\n  pivot_longer(-(1:ncol(class_probs)), names_to = \"Class\") \n\ndf_effects\n\n# A tibble: 840 × 5\n    agea  gndr eisced Class value\n   <dbl> <dbl>  <dbl> <chr> <dbl>\n 1  15       1      1 X1    0.363\n 2  15       1      1 X2    0.255\n 3  15       1      1 X3    0.382\n 4  18.9     1      1 X1    0.368\n 5  18.9     1      1 X2    0.252\n 6  18.9     1      1 X3    0.380\n 7  22.9     1      1 X1    0.372\n 8  22.9     1      1 X2    0.251\n 9  22.9     1      1 X3    0.378\n10  26.8     1      1 X1    0.375\n# … with 830 more rows\n\n\nExample plot for agea.\n```{r}\ndf_effects %>%\n  group_by(agea, Class) %>% \n  summarize(pr = mean(value)) %>% \n  ggplot(aes(agea, pr, color = Class)) + \n  geom_line() + \n  scale_color_brewer(palette = \"Set1\") + \n  theme_bw()\n```"
  }
]